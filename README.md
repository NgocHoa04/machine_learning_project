# ğŸŒ¤ï¸ Hanoi Weather Forecast - Machine Learning Project

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Machine Learning](https://img.shields.io/badge/ML-Time%20Series%20Forecasting-orange.svg)](https://github.com)

Dá»± Ã¡n dá»± bÃ¡o thá»i tiáº¿t HÃ  Ná»™i sá»­ dá»¥ng Machine Learning vá»›i dá»¯ liá»‡u lá»‹ch sá»­ tá»« Visual Crossing Weather API. MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n nhiá»‡t Ä‘á»™ tÆ°Æ¡ng lai dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng thá»i tiáº¿t nhÆ° nhiá»‡t Ä‘á»™, Ä‘á»™ áº©m, hÆ°á»›ng giÃ³, lÆ°á»£ng mÆ°a, bá»©c xáº¡ máº·t trá»i vÃ  cÃ¡c yáº¿u tá»‘ khÃ­ tÆ°á»£ng khÃ¡c.

---

## ğŸ“‹ Má»¥c Lá»¥c

- [Tá»•ng Quan Dá»± Ãn](#-tá»•ng-quan-dá»±-Ã¡n)
- [Dá»¯ Liá»‡u](#-dá»¯-liá»‡u)
- [Cáº¥u TrÃºc ThÆ° Má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)
- [Quy TrÃ¬nh PhÃ¡t Triá»ƒn](#-quy-trÃ¬nh-phÃ¡t-triá»ƒn)
- [Feature Engineering](#-feature-engineering)
- [MÃ´ HÃ¬nh Machine Learning](#-mÃ´-hÃ¬nh-machine-learning)
- [CÃ i Äáº·t vÃ  Sá»­ Dá»¥ng](#-cÃ i-Ä‘áº·t-vÃ -sá»­-dá»¥ng)
- [Káº¿t Quáº£](#-káº¿t-quáº£)
- [CÃ´ng Nghá»‡ Sá»­ Dá»¥ng](#-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [TÃ¡c Giáº£](#-tÃ¡c-giáº£)

---

## ğŸ¯ Tá»•ng Quan Dá»± Ãn

### Má»¥c TiÃªu
XÃ¢y dá»±ng há»‡ thá»‘ng dá»± bÃ¡o nhiá»‡t Ä‘á»™ chÃ­nh xÃ¡c cho thÃ nh phá»‘ HÃ  Ná»™i, giÃºp:
- Dá»± Ä‘oÃ¡n nhiá»‡t Ä‘á»™ trong tÆ°Æ¡ng lai dá»±a trÃªn dá»¯ liá»‡u lá»‹ch sá»­
- PhÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ áº£nh hÆ°á»Ÿng Ä‘áº¿n biáº¿n Ä‘á»•i nhiá»‡t Ä‘á»™
- Cung cáº¥p insight vá» khÃ­ háº­u HÃ  Ná»™i qua cÃ¡c mÃ¹a trong nÄƒm

### PhÆ°Æ¡ng PhÃ¡p
- **Time Series Forecasting** vá»›i cÃ¡c thuáº­t toÃ¡n Ensemble Learning
- **Feature Engineering** toÃ n diá»‡n bao gá»“m lag features, rolling statistics, vÃ  seasonal patterns
- **Data Preprocessing** chuyÃªn sÃ¢u vá»›i outlier handling vÃ  feature scaling
- **Model Evaluation** sá»­ dá»¥ng Cross-Validation vÃ  cÃ¡c metrics chuáº©n (RMSE, MAE, RÂ²)

---

## ğŸ“Š Dá»¯ Liá»‡u

### Nguá»“n Dá»¯ Liá»‡u
- **API**: Visual Crossing Weather API
- **Vá»‹ trÃ­**: HÃ  Ná»™i, Viá»‡t Nam
- **Thá»i gian**: Dá»¯ liá»‡u lá»‹ch sá»­ vÃ  theo giá»

### Dataset Files
- **`Hanoi Daily.csv`**: Dá»¯ liá»‡u thá»i tiáº¿t theo ngÃ y
- **`Hanoi Hourly.csv`**: Dá»¯ liá»‡u thá»i tiáº¿t theo giá»
- **`train.xlsx`**: Táº­p huáº¥n luyá»‡n Ä‘Ã£ xá»­ lÃ½ (3,051 samples)
- **`test.xlsx`**: Táº­p kiá»ƒm tra (786 samples)

### CÃ¡c Biáº¿n ChÃ­nh
| Biáº¿n | MÃ´ Táº£ | ÄÆ¡n Vá»‹ |
|------|-------|--------|
| `temp` | Nhiá»‡t Ä‘á»™ | Â°C |
| `tempmax` | Nhiá»‡t Ä‘á»™ cao nháº¥t | Â°C |
| `tempmin` | Nhiá»‡t Ä‘á»™ tháº¥p nháº¥t | Â°C |
| `humidity` | Äá»™ áº©m tÆ°Æ¡ng Ä‘á»‘i | % |
| `dew` | Äiá»ƒm sÆ°Æ¡ng | Â°C |
| `precip` | LÆ°á»£ng mÆ°a | mm |
| `precipprob` | XÃ¡c suáº¥t mÆ°a | % |
| `precipcover` | Pháº¡m vi phá»§ mÆ°a | % |
| `windspeed` | Tá»‘c Ä‘á»™ giÃ³ | km/h |
| `winddir` | HÆ°á»›ng giÃ³ | Ä‘á»™ (0-360Â°) |
| `solarradiation` | Bá»©c xáº¡ máº·t trá»i | W/mÂ² |
| `cloudcover` | Äá»™ che phá»§ mÃ¢y | % |
| `sunrise` | Giá» máº·t trá»i má»c | timestamp |
| `sunset` | Giá» máº·t trá»i láº·n | timestamp |

### Äáº·c Äiá»ƒm KhÃ­ Háº­u HÃ  Ná»™i
- **GiÃ³ mÃ¹a ÄÃ´ng Báº¯c (NE)**: 20-80Â° - MÃ¹a Ä‘Ã´ng/xuÃ¢n, láº¡nh vÃ  áº©m
- **GiÃ³ mÃ¹a TÃ¢y Nam (SW)**: 200-260Â° - MÃ¹a hÃ¨, nÃ³ng áº©m vá»›i giÃ´ng bÃ£o
- **Äiá»ƒm sÆ°Æ¡ng cao**: Äáº·c trÆ°ng khÃ­ háº­u áº©m nhiá»‡t Ä‘á»›i giÃ³ mÃ¹a

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
Final project/
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ raw/                      # Dá»¯ liá»‡u gá»‘c
â”‚   â”‚   â”œâ”€â”€ Hanoi Daily.csv       # Dá»¯ liá»‡u ngÃ y
â”‚   â”‚   â””â”€â”€ Hanoi Hourly.csv      # Dá»¯ liá»‡u giá»
â”‚   â””â”€â”€ processed/                # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚
â”œâ”€â”€ data/                         # Dá»¯ liá»‡u train/test
â”‚   â”œâ”€â”€ train.xlsx                # Training set
â”‚   â””â”€â”€ test.xlsx                 # Testing set
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter Notebooks
â”‚   â”œâ”€â”€ data_understanding.ipynb  # EDA vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u
â”‚   â”œâ”€â”€ data_processing.ipynb     # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ feature_engineering_GBDT.ipynb  # FE vá»›i GBDT
â”‚   â””â”€â”€ project.ipynb             # Notebook chÃ­nh
â”‚
â”œâ”€â”€ scripts/                      # Python scripts
â”‚   â”œâ”€â”€ data_preprocessing.py     # Preprocessing pipeline
â”‚   â””â”€â”€ FE.py                     # Feature engineering class
â”‚
â””â”€â”€ README.md                     # TÃ i liá»‡u dá»± Ã¡n
```

---

## ğŸ”„ Quy TrÃ¬nh PhÃ¡t Triá»ƒn

### 1. Data Understanding (`data_understanding.ipynb`)
- **Exploratory Data Analysis (EDA)**
  - PhÃ¢n tÃ­ch phÃ¢n phá»‘i cá»§a cÃ¡c biáº¿n
  - Correlation matrix vÃ  heatmap
  - PhÃ¡t hiá»‡n missing values vÃ  outliers
  - Visualize xu hÆ°á»›ng theo thá»i gian

- **Insights chÃ­nh**:
  - Äiá»ƒm sÆ°Æ¡ng (`dew`) tÆ°Æ¡ng quan máº¡nh vá»›i nhiá»‡t Ä‘á»™
  - Äá»™ áº©m cao Ä‘áº·c trÆ°ng khÃ­ háº­u HÃ  Ná»™i
  - Seasonal patterns rÃµ rá»‡t giá»¯a cÃ¡c mÃ¹a

### 2. Data Preprocessing (`data_preprocessing.py`)
- **Xá»­ lÃ½ Missing Values**: Imputation cho cÃ¡c giÃ¡ trá»‹ thiáº¿u
- **Outlier Detection & Handling**: 
  - Log transformation cho `precip` (lÆ°á»£ng mÆ°a)
  - Statistical methods cho cÃ¡c biáº¿n khÃ¡c
- **Feature Scaling**:
  - `StandardScaler` cho cÃ¡c biáº¿n sá»‘ há»c
  - `MinMaxScaler` cho humidity, cloudcover, precipcover
  - Custom scaling cho solar radiation
- **Remove Low Variance Features**: Loáº¡i bá» features khÃ´ng Ä‘Ã³ng gÃ³p thÃ´ng tin

**Classes chÃ­nh**:
```python
- VarianceThresholdSelector: Loáº¡i bá» features variance tháº¥p
- ConstantAndDuplicateRemover: XÃ³a constants vÃ  duplicates
- remove_low_variance_pipeline: Pipeline tá»•ng há»£p
```

### 3. Feature Engineering (`FE.py`, `project.ipynb`)
Táº¡o 200+ features má»›i tá»« dá»¯ liá»‡u gá»‘c (xem chi tiáº¿t pháº§n [Feature Engineering](#-feature-engineering))

### 4. Model Training & Evaluation (`project.ipynb`)
- **Train/Test Split**: Time-based split Ä‘á»ƒ trÃ¡nh data leakage
- **Model Selection**: So sÃ¡nh nhiá»u thuáº­t toÃ¡n
- **Hyperparameter Tuning**: Grid Search, Random Search
- **Cross-Validation**: Time Series CV
- **Model Evaluation**: RMSE, MAE, RÂ², visualizations

---

## ğŸ”§ Feature Engineering

### Class: `HanoiWeatherFE`

Feature Engineering class Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho dá»¯ liá»‡u thá»i tiáº¿t HÃ  Ná»™i vá»›i **229 features** tá»« 18 features gá»‘c.

#### 1. **Monsoon & Wind Features**
PhÃ¢n loáº¡i vÃ  mÃ£ hÃ³a giÃ³ mÃ¹a Ä‘áº·c trÆ°ng HÃ  Ná»™i:

```python
monsoon_zone(deg):
  - NE (20-80Â°): GiÃ³ mÃ¹a ÄÃ´ng Báº¯c
  - SW (200-260Â°): GiÃ³ mÃ¹a TÃ¢y Nam  
  - Other: CÃ¡c hÆ°á»›ng khÃ¡c
```

**Features táº¡o ra**:
- `monsoon`: Category (NE/SW/Other)
- `monsoon_NE`, `monsoon_SW`, `monsoon_Other`: One-hot encoding
- `winddir_sin`, `winddir_cos`: Chu ká»³ hÃ³a hÆ°á»›ng giÃ³
- `u_wind`, `v_wind`: Vector giÃ³ (phÃ¢n tÃ­ch thÃ nh pháº§n)
- `is_calm`: Cá» giÃ³ láº·ng (speed â‰¤ 0.5)

#### 2. **Temporal Features**
TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng thá»i gian chu ká»³:

- **NgÃ y trong nÄƒm**: `dayofyear_sin`, `dayofyear_cos`
- **ThÃ¡ng**: `month_sin`, `month_cos`
- **NgÃ y trong tuáº§n**: `dayofweek_sin`, `dayofweek_cos`
- **QuÃ½**: `quarter`
- **MÃ¹a**: `season` (Spring/Summer/Autumn/Winter)
- **Äá»™ dÃ i ban ngÃ y**: `daylength_hours`
- **Vá»‹ trÃ­ máº·t trá»i**: `sun_position` (sunrise/sunset relative)

#### 3. **Lag Features**
Táº¡o lag features cho cÃ¡c biáº¿n quan trá»ng Ä‘á»ƒ capture temporal dependencies:

**Lag days**: 1, 2, 3, 7 ngÃ y

**Biáº¿n Ã¡p dá»¥ng lag**:
- `humidity_scale__humidity`
- `scale_num__windspeed`
- `log_outliers__precip`
- `solarradition_scale__solarradiation`
- `minmax_num__cloudcover`
- `minmax_num__precipcover`
- `daylength_hours`

**VÃ­ dá»¥**: `humidity_scale__humidity_lag_1`, `windspeed_lag_7`

#### 4. **Rolling Window Statistics**
Rolling aggregations Ä‘á»ƒ capture xu hÆ°á»›ng ngáº¯n/dÃ i háº¡n:

**Windows**: 3, 7, 14, 21, 30, 60, 90 ngÃ y

**Aggregations**: mean, std, min, max

**VÃ­ dá»¥**:
- `humidity_roll_7_mean`: Äá»™ áº©m trung bÃ¬nh 7 ngÃ y
- `precip_roll_30_std`: Äá»™ lá»‡ch chuáº©n lÆ°á»£ng mÆ°a 30 ngÃ y
- `temp_roll_14_max`: Nhiá»‡t Ä‘á»™ max trong 14 ngÃ y

**ğŸ”’ No Data Leakage**: Táº¥t cáº£ rolling features Ä‘Æ°á»£c shift(1) trÆ°á»›c khi tÃ­nh toÃ¡n

#### 5. **Interaction Features**
TÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c biáº¿n:

- `temp_humidity_interaction`: temp Ã— humidity
- `wind_precip_interaction`: windspeed Ã— precip
- `solar_cloud_interaction`: solar radiation Ã— (1 - cloudcover)

#### 6. **Domain-Specific Features**

**Heat Index**:
```python
heat_index = temp + 0.5555 Ã— (vapor_pressure - 10)
```

**Precipitation Ratio**:
```python
precip_ratio = precipcover / precipprob (when precipprob > 0)
```

**Wind Chill Effect**: Hiá»‡u á»©ng lÃ m láº¡nh cá»§a giÃ³

---

## ğŸ¤– MÃ´ HÃ¬nh Machine Learning

### Thuáº­t ToÃ¡n Sá»­ Dá»¥ng

#### 1. **Random Forest Regressor**
```python
RandomForestRegressor(
    n_estimators=200,
    max_depth=15,
    min_samples_split=5,
    random_state=42
)
```
- **Æ¯u Ä‘iá»ƒm**: Robust vá»›i outliers, feature importance rÃµ rÃ ng
- **Sá»­ dá»¥ng**: Baseline model, feature selection

#### 2. **XGBoost**
```python
XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=7,
    eval_metric="rmse"
)
```
- **Æ¯u Ä‘iá»ƒm**: Performance cao, regularization tá»‘t
- **Sá»­ dá»¥ng**: Main production model

#### 3. **LightGBM**
```python
lgb.LGBMRegressor(
    n_estimators=500,
    learning_rate=0.05,
    num_leaves=31
)
```
- **Æ¯u Ä‘iá»ƒm**: Nhanh, hiá»‡u quáº£ vá»›i large dataset
- **Sá»­ dá»¥ng**: Alternative model, ensemble

#### 4. **CatBoost**
```python
cb.CatBoostRegressor(
    iterations=500,
    learning_rate=0.05,
    depth=7
)
```
- **Æ¯u Ä‘iá»ƒm**: Xá»­ lÃ½ categorical features tá»‘t
- **Sá»­ dá»¥ng**: Ensemble component

#### 5. **Gradient Boosting**
```python
GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=5
)
```
- **Æ¯u Ä‘iá»ƒm**: Stable, interpretable
- **Sá»­ dá»¥ng**: Baseline comparison

### Evaluation Metrics

| Metric | CÃ´ng Thá»©c | Ã NghÄ©a |
|--------|-----------|---------|
| **RMSE** | $\sqrt{\frac{1}{n}\sum(y_i - \hat{y}_i)^2}$ | Root Mean Squared Error - pháº¡t lá»—i lá»›n |
| **MAE** | $\frac{1}{n}\sum\|y_i - \hat{y}_i\|$ | Mean Absolute Error - robust vá»›i outliers |
| **RÂ²** | $1 - \frac{SS_{res}}{SS_{tot}}$ | Coefficient of determination - goodness of fit |
| **MAPE** | $\frac{100\%}{n}\sum\|\frac{y_i - \hat{y}_i}{y_i}\|$ | Mean Absolute Percentage Error |

---

## ğŸš€ CÃ i Äáº·t vÃ  Sá»­ Dá»¥ng

### Prerequisites
```bash
Python >= 3.8
```

### Installation

1. **Clone repository**:
```bash
git clone https://github.com/NgocHoa04/machine_learning_project.git
cd machine_learning_project
```

2. **Táº¡o virtual environment** (khuyáº¿n nghá»‹):
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **CÃ i Ä‘áº·t dependencies**:
```bash
pip install pandas numpy scikit-learn
pip install xgboost lightgbm catboost
pip install matplotlib seaborn
pip install jupyter notebook
pip install openpyxl  # Äá»ƒ Ä‘á»c .xlsx files
```

### Quick Start

#### 1. Cháº¡y toÃ n bá»™ pipeline:
```bash
jupyter notebook project.ipynb
```

#### 2. Sá»­ dá»¥ng Feature Engineering:
```python
from FE import HanoiWeatherFE

# Khá»Ÿi táº¡o
fe = HanoiWeatherFE(
    date_col="datetime",
    lag_days=(1, 2, 3, 7),
    roll_windows=(3, 7, 14, 21, 30, 60, 90)
)

# Transform data
df_engineered = fe.transform(df_preprocessed)
print(f"Original: {df.shape} -> Engineered: {df_engineered.shape}")
```

#### 3. Train model:
```python
from xgboost import XGBRegressor

# Prepare data
X_train = train_fe.drop(columns=['target_temp'])
y_train = train_fe['target_temp']

# Train
model = XGBRegressor(n_estimators=500, learning_rate=0.05)
model.fit(X_train, y_train)

# Predict
predictions = model.predict(X_test)
```

---

## ğŸ“ˆ Káº¿t Quáº£

### Model Performance

| Model | RMSE | MAE | RÂ² Score |
|-------|------|-----|----------|
| Random Forest | TBD | TBD | TBD |
| **XGBoost** | **TBD** | **TBD** | **TBD** |
| LightGBM | TBD | TBD | TBD |
| CatBoost | TBD | TBD | TBD |
| Gradient Boosting | TBD | TBD | TBD |

*Note: Cáº­p nháº­t metrics sau khi cháº¡y Ä‘áº§y Ä‘á»§ experiments*

### Feature Importance

Top 10 features quan trá»ng nháº¥t (tá»« XGBoost):
1. `temp_lag_1` - Nhiá»‡t Ä‘á»™ ngÃ y hÃ´m trÆ°á»›c
2. `temp_roll_7_mean` - Nhiá»‡t Ä‘á»™ trung bÃ¬nh 7 ngÃ y
3. `dew` - Äiá»ƒm sÆ°Æ¡ng
4. `humidity_scale__humidity` - Äá»™ áº©m
5. `dayofyear_sin/cos` - Chu ká»³ nÄƒm
6. `solarradiation_scale__solarradiation` - Bá»©c xáº¡ máº·t trá»i
7. `monsoon_NE/SW` - GiÃ³ mÃ¹a
8. `daylength_hours` - Äá»™ dÃ i ban ngÃ y
9. `temp_roll_30_mean` - Trend dÃ i háº¡n
10. `precip_roll_7_mean` - LÆ°á»£ng mÆ°a gáº§n Ä‘Ã¢y

### Visualizations

CÃ¡c biá»ƒu Ä‘á»“ quan trá»ng trong notebook:
- ğŸ“Š Correlation Heatmap
- ğŸ“ˆ Temperature Trends over Time
- ğŸŒ¡ï¸ Actual vs Predicted Temperature
- ğŸ“‰ Residual Analysis
- ğŸ¯ Feature Importance Plot
- ğŸ“… Seasonal Patterns

---

## ğŸ› ï¸ CÃ´ng Nghá»‡ Sá»­ Dá»¥ng

### Core Libraries
- **Pandas** - Data manipulation
- **NumPy** - Numerical computing
- **Scikit-learn** - ML algorithms & preprocessing
- **XGBoost** - Gradient boosting
- **LightGBM** - Fast gradient boosting
- **CatBoost** - Categorical boosting

### Visualization
- **Matplotlib** - Plotting
- **Seaborn** - Statistical visualization

### Development Tools
- **Jupyter Notebook** - Interactive development
- **Git** - Version control
- **Python 3.8+** - Programming language

---

## ğŸ‘¥ TÃ¡c Giáº£

**NgocHoa04**
- GitHub: [@NgocHoa04](https://github.com/NgocHoa04)
- Repository: [machine_learning_project](https://github.com/NgocHoa04/machine_learning_project)

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Visual Crossing Weather API** - Cung cáº¥p dá»¯ liá»‡u thá»i tiáº¿t
- **Scikit-learn Community** - ML frameworks
- **XGBoost/LightGBM/CatBoost Teams** - Advanced boosting algorithms

---

## ğŸ“ Contact & Support

Náº¿u báº¡n cÃ³ cÃ¢u há»i hoáº·c gáº·p váº¥n Ä‘á», vui lÃ²ng:
1. Má»Ÿ [Issue](https://github.com/NgocHoa04/machine_learning_project/issues) trÃªn GitHub
2. LiÃªn há»‡ qua GitHub profile

---

## ğŸ”® Future Work

- [ ] ThÃªm dá»± bÃ¡o cho cÃ¡c biáº¿n khÃ¡c (humidity, precipitation)
- [ ] Triá»ƒn khai web application vá»›i Flask/FastAPI
- [ ] TÃ­ch há»£p real-time data tá»« API
- [ ] Thá»­ nghiá»‡m Deep Learning models (LSTM, GRU)
- [ ] Multi-step forecasting (dá»± bÃ¡o nhiá»u ngÃ y)
- [ ] Deploy model lÃªn cloud (AWS, Azure, GCP)

---