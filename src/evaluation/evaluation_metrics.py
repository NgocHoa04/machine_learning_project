from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import numpy as np
import warnings
warnings.filterwarnings('ignore')


def evaluate_model(y_true, y_pred, dataset_name="Dataset"):
    """
    ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh vá»›i cÃ¡c metrics phá»• biáº¿n
    
    Parameters:
    -----------
    y_true : array-like
        GiÃ¡ trá»‹ thá»±c táº¿
    y_pred : array-like
        GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n
    dataset_name : str
        TÃªn cá»§a dataset (Train/Test)
        
    Returns:
    --------
    metrics : dict
        Dictionary chá»©a cÃ¡c metrics
    """
    
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # MAPE (Mean Absolute Percentage Error)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    metrics = {
        'RMSE': rmse,
        'MAE': mae,
        'R2': r2,
        'MAPE': mape
    }
    
    print(f"\nğŸ“Š {dataset_name} Performance:")
    print(f"   RMSE: {rmse:.4f}Â°C")
    print(f"   MAE:  {mae:.4f}Â°C")
    print(f"   RÂ²:   {r2:.4f}")
    print(f"   MAPE: {mape:.2f}%")
    
    return metrics

print("Evaluation function defined!")

def plot_predictions(y_true, y_pred, model_name="Model", dataset_name="Test"):
    """
    Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh giá»¯a giÃ¡ trá»‹ thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n
    
    Parameters:
    -----------
    y_true : array-like
        GiÃ¡ trá»‹ thá»±c táº¿
    y_pred : array-like
        GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n
    model_name : str
        TÃªn mÃ´ hÃ¬nh
    dataset_name : str
        TÃªn dataset
    """
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # Plot 1: Actual vs Predicted scatter
    axes[0].scatter(y_true, y_pred, alpha=0.5, s=20)
    axes[0].plot([y_true.min(), y_true.max()], 
                 [y_true.min(), y_true.max()], 
                 'r--', lw=2, label='Perfect Prediction')
    axes[0].set_xlabel('Actual Temperature (Â°C)', fontsize=12)
    axes[0].set_ylabel('Predicted Temperature (Â°C)', fontsize=12)
    axes[0].set_title(f'{model_name} - {dataset_name} Set\nActual vs Predicted', fontsize=13, fontweight='bold')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Plot 2: Residual plot
    residuals = y_true - y_pred
    axes[1].scatter(y_pred, residuals, alpha=0.5, s=20)
    axes[1].axhline(y=0, color='r', linestyle='--', lw=2)
    axes[1].set_xlabel('Predicted Temperature (Â°C)', fontsize=12)
    axes[1].set_ylabel('Residuals (Â°C)', fontsize=12)
    axes[1].set_title(f'{model_name} - {dataset_name} Set\nResidual Plot', fontsize=13, fontweight='bold')
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Residual statistics
    print(f"\nğŸ“Š Residual Statistics:")
    print(f"   Mean:   {residuals.mean():.4f}Â°C")
    print(f"   Std:    {residuals.std():.4f}Â°C")
    print(f"   Min:    {residuals.min():.4f}Â°C")
    print(f"   Max:    {residuals.max():.4f}Â°C")

print("Visualization function defined!")

