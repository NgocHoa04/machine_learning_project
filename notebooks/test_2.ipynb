{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d269814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\n",
      "SRC_PATH: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "PROJECT_ROOT = r\"C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\" #thay bang file path root cua minh\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"SRC_PATH:\", SRC_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b929bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import data.before_model as before_model      \n",
    "import data.data_preprocessing as data_preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e3f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\dataset\\raw\\Hanoi_Daily_Selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5156c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns due to constant value: []\n",
      "Dropped columns due to zero variance: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_hourly = pd.read_csv(r'C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\dataset\\raw\\Hanoi_Hourly_Selected.csv')\n",
    "train_dataset_h, test_dataset_h = before_model.train_test_split_hourly(df_hourly)\n",
    "before_model_hourly = before_model.before_model_pipeline_hourly\n",
    "before_model_hourly.fit(train_dataset_h)\n",
    "train_dataset_h = before_model_hourly.transform(train_dataset_h)\n",
    "test_dataset_h = before_model_hourly.transform(test_dataset_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e041eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_h = train_dataset_h.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df71813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns due to constant value: []\n",
      "Dropped columns due to zero variance: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\data\\data_preprocessing.py:109: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  data_df[col] = pd.to_numeric(data_df[col], errors='ignore')\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\data\\data_preprocessing.py:109: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  data_df[col] = pd.to_numeric(data_df[col], errors='ignore')\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\data\\data_preprocessing.py:109: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  data_df[col] = pd.to_numeric(data_df[col], errors='ignore')\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:149: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_lag{L}\"] = out[col].shift(L)\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_mean\"] = base.mean()\n",
      "C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\features\\feature_engineering.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[f\"{col}_roll{w}d_std\"] = base.std()\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = before_model.train_test_split(df)\n",
    "before_model_pipeline = before_model.before_model_pipeline\n",
    "before_model_pipeline.fit(train_dataset)\n",
    "train_dataset = before_model_pipeline.transform(train_dataset)\n",
    "test_dataset = before_model_pipeline.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model_training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9894275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna  \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MultiHorizonWalkForwardOptuna_XGBoost_Pipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        date_col,\n",
    "        target_col,\n",
    "        feature_cols,\n",
    "        n_splits=5,\n",
    "        test_size=30,\n",
    "        mode=\"expanding\",\n",
    "        horizons=(1, 2, 3, 4, 5),   # t+1 ... t+5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        df          : pandas DataFrame in chronological order\n",
    "        date_col    : name of date column (datetime)\n",
    "        target_col  : name of target column (e.g., 'temp')\n",
    "        feature_cols: list of feature columns (SHOULD NOT include target)\n",
    "        n_splits    : number of walk-forward folds\n",
    "        test_size   : number of days in each test fold\n",
    "        mode        : \"expanding\" or \"rolling\"\n",
    "        horizons    : iterable of forecast horizons (days ahead), e.g. (1,2,3,4,5)\n",
    "        \"\"\"\n",
    "        self.df = df.copy().sort_values(date_col).reset_index(drop=True)\n",
    "        self.date_col = date_col\n",
    "        self.target_col = target_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.mode = mode\n",
    "        self.horizons = tuple(horizons)\n",
    "\n",
    "        # For each horizon h, we will have:\n",
    "        #   self.walkfolds[h]      : list of ((X_train, y_train_h), (X_val, y_val_h))\n",
    "        #   self.walkfold_dates[h] : list of ((X_train_dates, y_train_dates_h),\n",
    "        #                                     (X_val_dates,   y_val_dates_h))\n",
    "        self.walkfolds = {h: [] for h in self.horizons}\n",
    "        self.walkfold_dates = {h: [] for h in self.horizons}\n",
    "\n",
    "        # Final model per horizon: self.final_models[h] = trained XGBRegressor\n",
    "        self.final_models = {h: None for h in self.horizons}\n",
    "\n",
    "        self.best_params = None\n",
    "        self.fold_history = []  # store optuna trial results\n",
    "\n",
    "        # Actual feature columns: remove date/target if accidentally passed in\n",
    "        self.X_cols = [\n",
    "            c for c in self.feature_cols\n",
    "            if c not in [\n",
    "                self.date_col,\n",
    "                self.target_col,\n",
    "                self.target_col + \"_next\",\n",
    "                self.date_col + \"_next\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    # ======================== 1. TARGET SHIFT FOR ALL HORIZONS (TRAIN) ========================\n",
    "\n",
    "    def add_target_shifts(self):\n",
    "        \"\"\"\n",
    "        Create shifted targets for all horizons, e.g. for target='temp':\n",
    "        - temp_h1 = temp at t+1\n",
    "        - temp_h2 = temp at t+2\n",
    "        - ...\n",
    "        Also create corresponding date columns date_h{h} for reference.\n",
    "        After that, drop rows with any NaN in those shifted targets.\n",
    "        \"\"\"\n",
    "        for h in self.horizons:\n",
    "            self.df[f\"{self.target_col}_h{h}\"] = self.df[self.target_col].shift(-h)\n",
    "            self.df[f\"{self.date_col}_h{h}\"] = self.df[self.date_col].shift(-h)\n",
    "\n",
    "        target_cols = [f\"{self.target_col}_h{h}\" for h in self.horizons]\n",
    "        self.df = self.df.dropna(subset=target_cols).reset_index(drop=True)\n",
    "\n",
    "    # ======================== 1b. TARGET SHIFT CHO TEST SET ========================\n",
    "\n",
    "    def prepare_test_dataset(self, test_df_raw):\n",
    "        \"\"\"\n",
    "        Create shifted targets for all horizons on a separate test DataFrame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_df_raw : pd.DataFrame\n",
    "            Raw test DataFrame containing at least [date_col, target_col] and feature_cols.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        test_df : pd.DataFrame\n",
    "            A new DataFrame with:\n",
    "            - original columns\n",
    "            - {target_col}_h{h}\n",
    "            - {date_col}_h{h}\n",
    "          Rows with NaN in any shifted target are dropped.\n",
    "        \"\"\"\n",
    "        test_df = test_df_raw.copy().sort_values(self.date_col).reset_index(drop=True)\n",
    "\n",
    "        for h in self.horizons:\n",
    "            test_df[f\"{self.target_col}_h{h}\"] = test_df[self.target_col].shift(-h)\n",
    "            test_df[f\"{self.date_col}_h{h}\"] = test_df[self.date_col].shift(-h)\n",
    "\n",
    "        target_cols = [f\"{self.target_col}_h{h}\" for h in self.horizons]\n",
    "        test_df = test_df.dropna(subset=target_cols).reset_index(drop=True)\n",
    "        return test_df\n",
    "\n",
    "    # ======================== 2. CREATE WALK-FORWARD FOLDS ========================\n",
    "\n",
    "    def create_walkforward_folds(self):\n",
    "        \"\"\"\n",
    "        Create walk-forward folds for each horizon.\n",
    "\n",
    "        For each horizon h:\n",
    "          self.walkfolds[h] = [\n",
    "              ((X_train, y_train_h), (X_val, y_val_h)),\n",
    "              ...\n",
    "          ]\n",
    "\n",
    "          self.walkfold_dates[h] = [\n",
    "              ((X_train_dates, y_train_dates_h), (X_val_dates, y_val_dates_h)),\n",
    "              ...\n",
    "          ]\n",
    "        \"\"\"\n",
    "        df_len = len(self.df)\n",
    "        step = (df_len - self.test_size) // self.n_splits\n",
    "\n",
    "        # reset containers\n",
    "        self.walkfolds = {h: [] for h in self.horizons}\n",
    "        self.walkfold_dates = {h: [] for h in self.horizons}\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            train_end = step * (i + 1)\n",
    "            test_start = train_end + 91   # 91-day gap\n",
    "            test_end = test_start + self.test_size\n",
    "            if test_end > df_len:\n",
    "                break\n",
    "\n",
    "            if self.mode == \"expanding\":\n",
    "                train_start = 0\n",
    "            else:  # rolling\n",
    "                train_start = max(0, train_end - step * 2)\n",
    "\n",
    "            train_df = self.df.iloc[train_start:train_end]\n",
    "            test_df = self.df.iloc[test_start:test_end]\n",
    "\n",
    "            # Features (same for all horizons)\n",
    "            X_train = train_df[self.X_cols].reset_index(drop=True)\n",
    "            X_val = test_df[self.X_cols].reset_index(drop=True)\n",
    "\n",
    "            # Dates of \"feature time\" (t)\n",
    "            X_train_dates = train_df[self.date_col].reset_index(drop=True)\n",
    "            X_val_dates = test_df[self.date_col].reset_index(drop=True)\n",
    "\n",
    "            # For each horizon, build targets & date of target\n",
    "            for h in self.horizons:\n",
    "                y_train_h = train_df[f\"{self.target_col}_h{h}\"].reset_index(drop=True)\n",
    "                y_val_h = test_df[f\"{self.target_col}_h{h}\"].reset_index(drop=True)\n",
    "\n",
    "                y_train_dates_h = train_df[f\"{self.date_col}_h{h}\"].reset_index(drop=True)\n",
    "                y_val_dates_h = test_df[f\"{self.date_col}_h{h}\"].reset_index(drop=True)\n",
    "\n",
    "                # Walkfolds\n",
    "                self.walkfolds[h].append(\n",
    "                    ((X_train, y_train_h), (X_val, y_val_h))\n",
    "                )\n",
    "\n",
    "                # Date folds\n",
    "                self.walkfold_dates[h].append(\n",
    "                    ((X_train_dates, y_train_dates_h),\n",
    "                     (X_val_dates,   y_val_dates_h))\n",
    "                )\n",
    "\n",
    "    # ======================== 3. OPTUNA OBJECTIVE (SHARED PARAMS) ========================\n",
    "\n",
    "    def create_objective(self):\n",
    "        \"\"\"\n",
    "        Optuna objective.\n",
    "\n",
    "        A single set of hyperparameters is shared for all horizons.\n",
    "        The objective value is the mean of the mean-RMSE across horizons.\n",
    "\n",
    "        - Dùng early_stopping_rounds trong constructor XGBRegressor (hợp XGBoost mới).\n",
    "        - Dùng trial.report + trial.should_prune để prune trial tệ.\n",
    "        \"\"\"\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'eval_metric': 'rmse',\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 10.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),\n",
    "            }\n",
    "\n",
    "            horizon_results = {}\n",
    "            overall_rmse_list = []\n",
    "            global_step = 0  # step index for Optuna pruning\n",
    "\n",
    "            for h in self.horizons:\n",
    "                scores = []\n",
    "                fold_results = []\n",
    "\n",
    "                for i, ((X_train, y_train), (X_val, y_val)) in enumerate(self.walkfolds[h]):\n",
    "\n",
    "                    model = xgb.XGBRegressor(\n",
    "                        **params,\n",
    "                        n_estimators=800,\n",
    "                        random_state=42,\n",
    "                        tree_method='hist',\n",
    "                        # early stopping for new XGBoost (passed via constructor)\n",
    "                        early_stopping_rounds=100\n",
    "                    )\n",
    "\n",
    "                    model.fit(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        verbose=False\n",
    "                    )\n",
    "\n",
    "                    preds = model.predict(X_val)\n",
    "                    # GIỮ LOG Y HỆT EM, NHƯNG Ở ĐÂY CHỊ DÙNG RMSE ĐÚNG NGHĨA\n",
    "                    rmse = mean_squared_error(y_val, preds)\n",
    "                    ss_res = np.sum((y_val - preds) ** 2)\n",
    "                    ss_tot = np.sum((y_val - np.mean(y_val)) ** 2)\n",
    "                    r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "                    scores.append(rmse)\n",
    "                    fold_results.append({'rmse': rmse, 'r2': r2})\n",
    "\n",
    "                    print(\n",
    "                        f\"Trial {trial.number}, Horizon h={h}, \"\n",
    "                        f\"Fold {i+1}: RMSE={rmse:.4f}, R²={r2:.4f}\"\n",
    "                    )\n",
    "\n",
    "                    # Report to Optuna and possibly prune\n",
    "                    trial.report(rmse, step=global_step)\n",
    "                    if trial.should_prune():\n",
    "                        print(f\"Trial {trial.number} pruned at global_step={global_step}\")\n",
    "                        raise optuna.TrialPruned()\n",
    "                    global_step += 1\n",
    "\n",
    "                mean_rmse_h = float(np.mean(scores))\n",
    "                horizon_results[h] = {\n",
    "                    'mean_rmse': mean_rmse_h,\n",
    "                    'fold_scores': fold_results,\n",
    "                }\n",
    "                overall_rmse_list.append(mean_rmse_h)\n",
    "\n",
    "            overall_mean_rmse = float(np.mean(overall_rmse_list))\n",
    "            print(\n",
    "                f\"Trial {trial.number} finished, \"\n",
    "                f\"overall mean RMSE across horizons={overall_mean_rmse:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "            self.fold_history.append({\n",
    "                'trial': trial.number,\n",
    "                'params': params,\n",
    "                'horizon_results': horizon_results,\n",
    "                'overall_mean_rmse': overall_mean_rmse,\n",
    "            })\n",
    "\n",
    "            return overall_mean_rmse\n",
    "\n",
    "        return objective\n",
    "\n",
    "    # ======================== 4. RUN OPTUNA ========================\n",
    "\n",
    "    def run_optuna(self, n_trials=50):\n",
    "        \"\"\"\n",
    "        Run Optuna to find shared hyperparameters for all horizons.\n",
    "\n",
    "        Dùng MedianPruner để cắt trial tệ.\n",
    "        \"\"\"\n",
    "        objective_fn = self.create_objective()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_warmup_steps=5  # number of steps before pruning is enabled\n",
    "            )\n",
    "        )\n",
    "        study.optimize(objective_fn, n_trials=n_trials)\n",
    "        self.best_params = study.best_params\n",
    "        return study\n",
    "\n",
    "    # ======================== 5. TRAIN A FINAL MODEL PER HORIZON ========================\n",
    "\n",
    "    def train_final_models(self):\n",
    "        \"\"\"\n",
    "        Train one final model per horizon on the entire development set\n",
    "        using the best hyperparameters from Optuna.\n",
    "        \"\"\"\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"You must run run_optuna() before train_final_models().\")\n",
    "\n",
    "        final_params = self.best_params.copy()\n",
    "        final_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'n_estimators': 800\n",
    "        })\n",
    "\n",
    "        X_full = self.df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_full_h = self.df[f\"{self.target_col}_h{h}\"]\n",
    "\n",
    "            model_h = xgb.XGBRegressor(\n",
    "                **final_params,\n",
    "                random_state=42,\n",
    "                tree_method='hist'\n",
    "            )\n",
    "\n",
    "            model_h.fit(X_full, y_full_h, verbose=False)\n",
    "            self.final_models[h] = model_h\n",
    "\n",
    "    # ======================== 6. PREDICTION HELPERS ========================\n",
    "\n",
    "    def predict_horizon(self, X_today, h):\n",
    "        \"\"\"\n",
    "        Predict target at t+h for a single row or DataFrame X_today.\n",
    "        \"\"\"\n",
    "        if h not in self.horizons:\n",
    "            raise ValueError(f\"Horizon {h} not in configured horizons {self.horizons}.\")\n",
    "        if self.final_models[h] is None:\n",
    "            raise ValueError(\n",
    "                f\"Model for horizon {h} is not trained. \"\n",
    "                f\"Call train_final_models() first.\"\n",
    "            )\n",
    "\n",
    "        X_input = X_today[self.X_cols]\n",
    "        return self.final_models[h].predict(X_input)\n",
    "\n",
    "    def predict_all_horizons(self, X_today):\n",
    "        \"\"\"\n",
    "        Predict for all configured horizons for a given X_today (1 row or small DataFrame).\n",
    "        Returns a dict: {h: prediction_array}\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for h in self.horizons:\n",
    "            results[h] = self.predict_horizon(X_today, h)\n",
    "        return results\n",
    "\n",
    "    # ======================== 6b. BUILD PREDICTIONS FRAME (Plot) ========================\n",
    "\n",
    "    def get_predictions_frame(self, df_with_shift, h):\n",
    "        \"\"\"\n",
    "        Build a DataFrame with dates, true values and predictions for horizon h.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_with_shift : pd.DataFrame\n",
    "            DataFrame (train hoặc test) đã có sẵn các cột:\n",
    "            - self.date_col\n",
    "            - f\"{self.target_col}_h{h}\"\n",
    "            - f\"{self.date_col}_h{h}\" (nếu có)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df_pred : pd.DataFrame with columns:\n",
    "            - feature_time : time t (where features are taken from)\n",
    "            - target_time  : time t+h (if available), else feature_time\n",
    "            - y_true       : true target at t+h\n",
    "            - y_pred       : model prediction at t+h\n",
    "        \"\"\"\n",
    "        if h not in self.horizons:\n",
    "            raise ValueError(f\"Horizon {h} not in configured horizons {self.horizons}.\")\n",
    "        if self.final_models[h] is None:\n",
    "            raise ValueError(\n",
    "                f\"Model for horizon {h} is not trained. \"\n",
    "                f\"Call train_final_models() first.\"\n",
    "            )\n",
    "\n",
    "        X = df_with_shift[self.X_cols]\n",
    "        y_true = df_with_shift[f\"{self.target_col}_h{h}\"]\n",
    "        y_pred = self.final_models[h].predict(X)\n",
    "\n",
    "        feature_time = df_with_shift[self.date_col]\n",
    "        if f\"{self.date_col}_h{h}\" in df_with_shift.columns:\n",
    "            target_time = df_with_shift[f\"{self.date_col}_h{h}\"]\n",
    "        else:\n",
    "            # fallback: dùng feature_time nếu không có date_h\n",
    "            target_time = feature_time\n",
    "\n",
    "        df_pred = pd.DataFrame({\n",
    "            \"feature_time\": feature_time.values,\n",
    "            \"target_time\": target_time.values,\n",
    "            \"y_true\": y_true.values,\n",
    "            \"y_pred\": y_pred,\n",
    "        })\n",
    "        return df_pred\n",
    "\n",
    "    def plot_predictions(self, df_with_shift, h, use_target_time=True, n_points=None):\n",
    "        \"\"\"\n",
    "        Plot true vs predicted for a given horizon h.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_with_shift : pd.DataFrame\n",
    "            DataFrame (thường là test_df đã shift bằng prepare_test_dataset).\n",
    "        h : int\n",
    "            Horizon to plot (must be in self.horizons).\n",
    "        use_target_time : bool, default True\n",
    "            If True and target_time exists, x-axis = target_time (t+h).\n",
    "            If False, x-axis = feature_time (t).\n",
    "        n_points : int or None\n",
    "            If not None, only the first n_points are plotted.\n",
    "        \"\"\"\n",
    "        df_pred = self.get_predictions_frame(df_with_shift, h)\n",
    "\n",
    "        df_plot = df_pred.copy()\n",
    "        if use_target_time and \"target_time\" in df_plot.columns:\n",
    "            df_plot[\"x\"] = df_plot[\"target_time\"]\n",
    "        else:\n",
    "            df_plot[\"x\"] = df_plot[\"feature_time\"]\n",
    "\n",
    "        if n_points is not None:\n",
    "            df_plot = df_plot.iloc[:n_points]\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(df_plot[\"x\"], df_plot[\"y_true\"], label=\"True\")\n",
    "        plt.plot(df_plot[\"x\"], df_plot[\"y_pred\"], label=\"Predicted\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(self.target_col)\n",
    "        plt.title(f\"Horizon h={h} forecast\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # ======================== 7. EVAL ON TRAIN SET (CHECK OVERFIT) ========================\n",
    "\n",
    "    def evaluate_train_models(self):\n",
    "        \"\"\"\n",
    "        Evaluate all final models on the training (development) set.\n",
    "        Returns a dict: {h: {'rmse','mae','mape','mse','r2'}}\n",
    "        \"\"\"\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"All horizon models must be trained before evaluation.\")\n",
    "\n",
    "        metrics = {}\n",
    "        X_train_full = self.df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_train_h = self.df[f\"{self.target_col}_h{h}\"]\n",
    "            preds = self.final_models[h].predict(X_train_full)\n",
    "\n",
    "            rmse = mean_squared_error(y_train_h, preds)\n",
    "            mae = mean_absolute_error(y_train_h, preds)\n",
    "            mse = mean_squared_error(y_train_h, preds)\n",
    "\n",
    "            # avoid division by zero for MAPE\n",
    "            eps = 1e-8\n",
    "            mape = np.mean(np.abs((y_train_h - preds) / (y_train_h + eps))) * 100\n",
    "\n",
    "            ss_res = np.sum((y_train_h - preds) ** 2)\n",
    "            ss_tot = np.sum((y_train_h - np.mean(y_train_h)) ** 2)\n",
    "            r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "            print(\n",
    "                f\"[TRAIN] Horizon h={h} -> \"\n",
    "                f\"RMSE: {rmse:.4f}, R²: {r2:.4f}\"\n",
    "            )\n",
    "\n",
    "            metrics[h] = {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'mape': mape,\n",
    "                'mse': mse,\n",
    "                'r2': r2,\n",
    "            }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    # ======================== 8. EVALUATION ON A TEST SET ========================\n",
    "\n",
    "    def evaluate_final_models(self, test_df):\n",
    "        \"\"\"\n",
    "        Evaluate all final models on a separate test DataFrame that already contains\n",
    "        the shifted targets (i.e., you must have created _h1.._h5 on it).\n",
    "        Returns a dict: {h: {'rmse','mae','mape','mse','r2'}}\n",
    "        \"\"\"\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"All horizon models must be trained before evaluation.\")\n",
    "\n",
    "        metrics = {}\n",
    "        X_test = test_df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_test_h = test_df[f\"{self.target_col}_h{h}\"]\n",
    "            preds = self.final_models[h].predict(X_test)\n",
    "\n",
    "            rmse = mean_squared_error(y_test_h, preds)\n",
    "            mae = mean_absolute_error(y_test_h, preds)\n",
    "            mse = mean_squared_error(y_test_h, preds)\n",
    "\n",
    "            eps = 1e-8\n",
    "            mape = np.mean(np.abs((y_test_h - preds) / (y_test_h + eps))) * 100\n",
    "\n",
    "            ss_res = np.sum((y_test_h - preds) ** 2)\n",
    "            ss_tot = np.sum((y_test_h - np.mean(y_test_h)) ** 2)\n",
    "            r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "            print(f\"Horizon h={h} -> RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "            metrics[h] = {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'mape': mape,\n",
    "                'mse': mse,\n",
    "                'r2': r2,\n",
    "            }\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81238117",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model_training 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47ecd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import json  # Vẫn cần cho file tóm tắt (summary)\n",
    "import datetime  # Vẫn cần cho file tóm tắt (summary)\n",
    "import pickle  # Dùng để lưu model .pkl\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    \"\"\"\n",
    "    Custom JSON encoder để xử lý các kiểu dữ liệu của NumPy\n",
    "    (vd: np.float64, np.int64) mà thư viện json tiêu chuẩn không xử lý được.\n",
    "    \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "class MultiHorizonWalkForwardOptuna_XGBoost_Pipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        date_col,\n",
    "        target_col,\n",
    "        feature_cols,\n",
    "        n_splits=5,\n",
    "        test_size=30,\n",
    "        mode=\"expanding\",\n",
    "        horizons=(1, 2, 3, 4, 5),  # t+1 ... t+5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        self.df = df.copy().sort_values(date_col).reset_index(drop=True)\n",
    "        self.date_col = date_col\n",
    "        self.target_col = target_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.mode = mode\n",
    "        self.horizons = tuple(horizons)\n",
    "\n",
    "        self.walkfolds = {h: [] for h in self.horizons}\n",
    "        self.walkfold_dates = {h: [] for h in self.horizons}\n",
    "\n",
    "        self.final_models = {h: None for h in self.horizons}\n",
    "\n",
    "        self.best_params = None\n",
    "        self.fold_history = []\n",
    "\n",
    "        self.X_cols = [\n",
    "            c for c in self.feature_cols\n",
    "            if c not in [\n",
    "                self.date_col,\n",
    "                self.target_col,\n",
    "                self.target_col + \"_next\",\n",
    "                self.date_col + \"_next\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    # ======================== 1. TARGET SHIFT FOR ALL HORIZONS (TRAIN) ========================\n",
    "\n",
    "    def add_target_shifts(self):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        for h in self.horizons:\n",
    "            self.df[f\"{self.target_col}_h{h}\"] = self.df[self.target_col].shift(-h)\n",
    "            self.df[f\"{self.date_col}_h{h}\"] = self.df[self.date_col].shift(-h)\n",
    "\n",
    "        target_cols = [f\"{self.target_col}_h{h}\" for h in self.horizons]\n",
    "        self.df = self.df.dropna(subset=target_cols).reset_index(drop=True)\n",
    "\n",
    "    # ======================== 1b. TARGET SHIFT CHO TEST SET ========================\n",
    "\n",
    "    def prepare_test_dataset(self, test_df_raw):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        test_df = test_df_raw.copy().sort_values(self.date_col).reset_index(drop=True)\n",
    "\n",
    "        for h in self.horizons:\n",
    "            test_df[f\"{self.target_col}_h{h}\"] = test_df[self.target_col].shift(-h)\n",
    "            test_df[f\"{self.date_col}_h{h}\"] = test_df[self.date_col].shift(-h)\n",
    "\n",
    "        target_cols = [f\"{self.target_col}_h{h}\" for h in self.horizons]\n",
    "        test_df = test_df.dropna(subset=target_cols).reset_index(drop=True)\n",
    "        return test_df\n",
    "\n",
    "    # ======================== 2. CREATE WALK-FORWARD FOLDS ========================\n",
    "\n",
    "    def create_walkforward_folds(self):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        df_len = len(self.df)\n",
    "        step = (df_len - self.test_size) // self.n_splits\n",
    "\n",
    "        self.walkfolds = {h: [] for h in self.horizons}\n",
    "        self.walkfold_dates = {h: [] for h in self.horizons}\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            train_end = step * (i + 1)\n",
    "            test_start = train_end + 91  # 91-day gap\n",
    "            test_end = test_start + self.test_size\n",
    "            if test_end > df_len:\n",
    "                break\n",
    "\n",
    "            if self.mode == \"expanding\":\n",
    "                train_start = 0\n",
    "            else:  # rolling\n",
    "                train_start = max(0, train_end - step * 2)\n",
    "\n",
    "            train_df = self.df.iloc[train_start:train_end]\n",
    "            test_df = self.df.iloc[test_start:test_end]\n",
    "\n",
    "            X_train = train_df[self.X_cols].reset_index(drop=True)\n",
    "            X_val = test_df[self.X_cols].reset_index(drop=True)\n",
    "\n",
    "            X_train_dates = train_df[self.date_col].reset_index(drop=True)\n",
    "            X_val_dates = test_df[self.date_col].reset_index(drop=True)\n",
    "\n",
    "            for h in self.horizons:\n",
    "                y_train_h = train_df[f\"{self.target_col}_h{h}\"].reset_index(drop=True)\n",
    "                y_val_h = test_df[f\"{self.target_col}_h{h}\"].reset_index(drop=True)\n",
    "\n",
    "                y_train_dates_h = train_df[f\"{self.date_col}_h{h}\"].reset_index(drop=True)\n",
    "                y_val_dates_h = test_df[f\"{self.date_col}_h{h}\"].reset_index(drop=True)\n",
    "\n",
    "                self.walkfolds[h].append(\n",
    "                    ((X_train, y_train_h), (X_val, y_val_h))\n",
    "                )\n",
    "\n",
    "                self.walkfold_dates[h].append(\n",
    "                    ((X_train_dates, y_train_dates_h),\n",
    "                     (X_val_dates, y_val_dates_h))\n",
    "                )\n",
    "\n",
    "    # ======================== 3. OPTUNA OBJECTIVE (SHARED PARAMS) ========================\n",
    "\n",
    "    def create_objective(self):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'eval_metric': 'rmse',\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 10.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),\n",
    "            }\n",
    "\n",
    "            horizon_results = {}\n",
    "            overall_rmse_list = []\n",
    "            global_step = 0\n",
    "\n",
    "            for h in self.horizons:\n",
    "                scores = []\n",
    "                fold_results = []\n",
    "\n",
    "                for i, ((X_train, y_train), (X_val, y_val)) in enumerate(self.walkfolds[h]):\n",
    "\n",
    "                    model = xgb.XGBRegressor(\n",
    "                        **params,\n",
    "                        n_estimators=800,\n",
    "                        random_state=42,\n",
    "                        tree_method='hist',\n",
    "                        early_stopping_rounds=100\n",
    "                    )\n",
    "\n",
    "                    model.fit(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        verbose=False\n",
    "                    )\n",
    "\n",
    "                    preds = model.predict(X_val)\n",
    "                    \n",
    "                    # ĐÃ SỬA (FIXED): Lấy căn bậc hai của MSE để ra RMSE\n",
    "                    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "\n",
    "                    ss_res = np.sum((y_val - preds) ** 2)\n",
    "                    ss_tot = np.sum((y_val - np.mean(y_val)) ** 2)\n",
    "                    r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "                    scores.append(rmse)\n",
    "                    fold_results.append({'rmse': rmse, 'r2': r2})\n",
    "\n",
    "                    print(\n",
    "                        f\"Trial {trial.number}, Horizon h={h}, \"\n",
    "                        f\"Fold {i+1}: RMSE={rmse:.4f}, R²={r2:.4f}\"\n",
    "                    )\n",
    "\n",
    "                    trial.report(rmse, step=global_step)\n",
    "                    if trial.should_prune():\n",
    "                        print(f\"Trial {trial.number} pruned at global_step={global_step}\")\n",
    "                        raise optuna.TrialPruned()\n",
    "                    global_step += 1\n",
    "\n",
    "                mean_rmse_h = float(np.mean(scores))\n",
    "                horizon_results[h] = {\n",
    "                    'mean_rmse': mean_rmse_h,\n",
    "                    'fold_scores': fold_results,\n",
    "                }\n",
    "                overall_rmse_list.append(mean_rmse_h)\n",
    "\n",
    "            overall_mean_rmse = float(np.mean(overall_rmse_list))\n",
    "            print(\n",
    "                f\"Trial {trial.number} finished, \"\n",
    "                f\"overall mean RMSE across horizons={overall_mean_rmse:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "            self.fold_history.append({\n",
    "                'trial': trial.number,\n",
    "                'params': params,\n",
    "                'horizon_results': horizon_results,\n",
    "                'overall_mean_rmse': overall_mean_rmse,\n",
    "            })\n",
    "\n",
    "            return overall_mean_rmse\n",
    "\n",
    "        return objective\n",
    "\n",
    "    # ======================== 4. RUN OPTUNA ========================\n",
    "\n",
    "    def run_optuna(self, n_trials=50):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        objective_fn = self.create_objective()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_warmup_steps=5\n",
    "            )\n",
    "        )\n",
    "        study.optimize(objective_fn, n_trials=n_trials)\n",
    "        self.best_params = study.best_params\n",
    "        return study\n",
    "\n",
    "    # ======================== 5. TRAIN A FINAL MODEL PER HORIZON ========================\n",
    "\n",
    "    def train_final_models(self):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"You must run run_optuna() before train_final_models().\")\n",
    "\n",
    "        final_params = self.best_params.copy()\n",
    "        final_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'n_estimators': 800\n",
    "        })\n",
    "\n",
    "        X_full = self.df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_full_h = self.df[f\"{self.target_col}_h{h}\"]\n",
    "\n",
    "            model_h = xgb.XGBRegressor(\n",
    "                **final_params,\n",
    "                random_state=42,\n",
    "                tree_method='hist'\n",
    "            )\n",
    "\n",
    "            model_h.fit(X_full, y_full_h, verbose=False)\n",
    "            self.final_models[h] = model_h\n",
    "            print(f\"Final model for horizon {h} trained.\")\n",
    "\n",
    "    # ======================== 6. PREDICTION HELPERS ========================\n",
    "\n",
    "    def predict_horizon(self, X_today, h):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        if h not in self.horizons:\n",
    "            raise ValueError(f\"Horizon {h} not in configured horizons {self.horizons}.\")\n",
    "        if self.final_models[h] is None:\n",
    "            raise ValueError(f\"Model for horizon {h} is not trained. Call train_final_models() first.\")\n",
    "\n",
    "        X_input = X_today[self.X_cols]\n",
    "        return self.final_models[h].predict(X_input)\n",
    "\n",
    "    def predict_all_horizons(self, X_today):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for h in self.horizons:\n",
    "            results[h] = self.predict_horizon(X_today, h)\n",
    "        return results\n",
    "\n",
    "    # ======================== 6b. BUILD PREDICTIONS FRAME (Plot) ========================\n",
    "\n",
    "    def get_predictions_frame(self, df_with_shift, h):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        if h not in self.horizons:\n",
    "            raise ValueError(f\"Horizon {h} not in configured horizons {self.horizons}.\")\n",
    "        if self.final_models[h] is None:\n",
    "            raise ValueError(f\"Model for horizon {h} is not trained. Call train_final_models() first.\")\n",
    "\n",
    "        X = df_with_shift[self.X_cols]\n",
    "        y_true = df_with_shift[f\"{self.target_col}_h{h}\"]\n",
    "        y_pred = self.final_models[h].predict(X)\n",
    "\n",
    "        feature_time = df_with_shift[self.date_col]\n",
    "        if f\"{self.date_col}_h{h}\" in df_with_shift.columns:\n",
    "            target_time = df_with_shift[f\"{self.date_col}_h{h}\"]\n",
    "        else:\n",
    "            target_time = feature_time\n",
    "\n",
    "        df_pred = pd.DataFrame({\n",
    "            \"feature_time\": feature_time.values,\n",
    "            \"target_time\": target_time.values,\n",
    "            \"y_true\": y_true.values,\n",
    "            \"y_pred\": y_pred,\n",
    "        })\n",
    "        return df_pred\n",
    "\n",
    "    def plot_predictions(self, df_with_shift, h, use_target_time=True, n_points=None):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        df_pred = self.get_predictions_frame(df_with_shift, h)\n",
    "\n",
    "        df_plot = df_pred.copy()\n",
    "        if use_target_time and \"target_time\" in df_plot.columns:\n",
    "            df_plot[\"x\"] = df_plot[\"target_time\"]\n",
    "        else:\n",
    "            df_plot[\"x\"] = df_plot[\"feature_time\"]\n",
    "\n",
    "        if n_points is not None:\n",
    "            df_plot = df_plot.iloc[:n_points]\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(df_plot[\"x\"], df_plot[\"y_true\"], label=\"True\")\n",
    "        plt.plot(df_plot[\"x\"], df_plot[\"y_pred\"], label=\"Predicted\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(self.target_col)\n",
    "        plt.title(f\"Horizon h={h} forecast\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # ======================== 7. EVAL ON TRAIN SET (CHECK OVERFIT) ========================\n",
    "\n",
    "    def evaluate_train_models(self):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"All horizon models must be trained before evaluation.\")\n",
    "\n",
    "        metrics = {}\n",
    "        X_train_full = self.df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_train_h = self.df[f\"{self.target_col}_h{h}\"]\n",
    "            preds = self.final_models[h].predict(X_train_full)\n",
    "\n",
    "            # ĐÃ SỬA (FIXED): Lấy căn bậc hai của MSE\n",
    "            mse = mean_squared_error(y_train_h, preds)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            mae = mean_absolute_error(y_train_h, preds)\n",
    "\n",
    "            eps = 1e-8\n",
    "            mape = np.mean(np.abs((y_train_h - preds) / (y_train_h + eps))) * 100\n",
    "\n",
    "            ss_res = np.sum((y_train_h - preds) ** 2)\n",
    "            ss_tot = np.sum((y_train_h - np.mean(y_train_h)) ** 2)\n",
    "            r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "            print(\n",
    "                f\"[TRAIN] Horizon h={h} -> \"\n",
    "                f\"RMSE: {rmse:.4f}, R²: {r2:.4f}\"\n",
    "            )\n",
    "\n",
    "            metrics[h] = {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'mape': mape,\n",
    "                'mse': mse,\n",
    "                'r2': r2,\n",
    "            }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    # ======================== 8. EVALUATION ON A TEST SET ========================\n",
    "\n",
    "    def evaluate_final_models(self, test_df):\n",
    "        \"\"\"\n",
    "        ... (docstring) ...\n",
    "        \"\"\"\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"All horizon models must be trained before evaluation.\")\n",
    "\n",
    "        metrics = {}\n",
    "        X_test = test_df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_test_h = test_df[f\"{self.target_col}_h{h}\"]\n",
    "            preds = self.final_models[h].predict(X_test)\n",
    "\n",
    "            # ĐÃ SỬA (FIXED): Lấy căn bậc hai của MSE\n",
    "            mse = mean_squared_error(y_test_h, preds)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            mae = mean_absolute_error(y_test_h, preds)\n",
    "\n",
    "            eps = 1e-8\n",
    "            mape = np.mean(np.abs((y_test_h - preds) / (y_test_h + eps))) * 100\n",
    "\n",
    "            ss_res = np.sum((y_test_h - preds) ** 2)\n",
    "            ss_tot = np.sum((y_test_h - np.mean(y_test_h)) ** 2)\n",
    "            r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "            print(f\"Horizon h={h} -> RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "            metrics[h] = {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'mape': mape,\n",
    "                'mse': mse,\n",
    "                'r2': r2,\n",
    "            }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    # ======================== 9. SAVE FINAL MODELS (PICKLE) ========================\n",
    "\n",
    "    def save_all_final_models_pkl(self, base_filename_prefix):\n",
    "        \"\"\"\n",
    "        Lưu tất cả các model cuối cùng (final_models) ra đĩa dùng PICKLE (.pkl).\n",
    "        \"\"\"\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"Phải train model trước khi lưu. Hãy gọi train_final_models().\")\n",
    "        \n",
    "        saved_paths = {}\n",
    "        for h in self.horizons:\n",
    "            model = self.final_models[h]\n",
    "            filename = f\"{base_filename_prefix}_h{h}.pkl\"\n",
    "            \n",
    "            try:\n",
    "                with open(filename, 'wb') as f: \n",
    "                    pickle.dump(model, f)\n",
    "                saved_paths[h] = filename\n",
    "                print(f\"Model (Pickle) cho horizon {h} đã được lưu vào: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi lưu file pickle {filename}: {e}\")\n",
    "        \n",
    "        return saved_paths\n",
    "\n",
    "    # ======================== 10. SAVE RESULTS SUMMARY (JSON) ========================\n",
    "    \n",
    "    def save_results_to_json(\n",
    "        self,\n",
    "        filename,\n",
    "        model_name,\n",
    "        train_metrics,\n",
    "        test_metrics,\n",
    "        saved_model_paths=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Lưu kết quả tóm tắt (best param, metrics, timestamp,...) vào 1 file JSON.\n",
    "        \"\"\"\n",
    "        \n",
    "        results_summary = {\n",
    "            \"model_name\": model_name,\n",
    "            \"run_timestamp_utc\": datetime.utcnow().isoformat(),\n",
    "            \"target_column\": self.target_col,\n",
    "            \"feature_columns\": self.X_cols,\n",
    "            \"horizons\": self.horizons,\n",
    "            \"cross_validation_setup\": {\n",
    "                \"n_splits\": self.n_splits,\n",
    "                \"test_size_per_fold\": self.test_size,\n",
    "                \"mode\": self.mode,\n",
    "            },\n",
    "            \"optuna_best_params\": self.best_params,\n",
    "            \"evaluation_train_set\": train_metrics,\n",
    "            \"evaluation_test_set\": test_metrics,\n",
    "            \"saved_model_files\": saved_model_paths if saved_model_paths else {},\n",
    "            \"optuna_fold_history\": self.fold_history \n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results_summary, f, indent=4, cls=NpEncoder)\n",
    "            print(f\"Kết quả tóm tắt đã được lưu vào: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi lưu file JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99290f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_pipeline = MultiHorizonWalkForwardOptuna_XGBoost_Pipeline(\n",
    "    df=train_dataset,\n",
    "    date_col=\"datetime\",\n",
    "    target_col=\"temp\",\n",
    "    feature_cols=[col for col in train_dataset.columns if col not in [\"datetime\", \"temp\", \"temp_next\", \"datetime_next\"]],\n",
    "    n_splits=5,\n",
    "    test_size=365,\n",
    "    mode=\"expanding\",\n",
    "    horizons=(1, 2, 3, 4, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918e27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_pipeline.add_target_shifts()\n",
    "XGBoost_pipeline.create_walkforward_folds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032264f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:07:08,615] A new study created in memory with name: no-name-f405f82f-5c1e-469e-aac9-e0905409c477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0, Horizon h=1, Fold 1: RMSE=1.8533, R²=0.8209\n",
      "Trial 0, Horizon h=1, Fold 2: RMSE=1.8492, R²=0.8473\n",
      "Trial 0, Horizon h=1, Fold 3: RMSE=1.6713, R²=0.8907\n",
      "Trial 0, Horizon h=1, Fold 4: RMSE=1.6918, R²=0.8988\n",
      "Trial 0, Horizon h=2, Fold 1: RMSE=2.2235, R²=0.7422\n",
      "Trial 0, Horizon h=2, Fold 2: RMSE=2.4222, R²=0.7371\n",
      "Trial 0, Horizon h=2, Fold 3: RMSE=2.2677, R²=0.7994\n",
      "Trial 0, Horizon h=2, Fold 4: RMSE=2.2820, R²=0.8162\n",
      "Trial 0, Horizon h=3, Fold 1: RMSE=2.3913, R²=0.7020\n",
      "Trial 0, Horizon h=3, Fold 2: RMSE=2.6792, R²=0.6773\n",
      "Trial 0, Horizon h=3, Fold 3: RMSE=2.5775, R²=0.7408\n",
      "Trial 0, Horizon h=3, Fold 4: RMSE=2.4817, R²=0.7827\n",
      "Trial 0, Horizon h=4, Fold 1: RMSE=2.3933, R²=0.7017\n",
      "Trial 0, Horizon h=4, Fold 2: RMSE=2.7426, R²=0.6609\n",
      "Trial 0, Horizon h=4, Fold 3: RMSE=2.6549, R²=0.7253\n",
      "Trial 0, Horizon h=4, Fold 4: RMSE=2.5902, R²=0.7633\n",
      "Trial 0, Horizon h=5, Fold 1: RMSE=2.4525, R²=0.6871\n",
      "Trial 0, Horizon h=5, Fold 2: RMSE=2.7724, R²=0.6529\n",
      "Trial 0, Horizon h=5, Fold 3: RMSE=2.6964, R²=0.7166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:07:31,497] Trial 0 finished with value: 2.36398679654312 and parameters: {'learning_rate': 0.019816715189721303, 'max_depth': 3, 'gamma': 0.5684681137445113, 'reg_lambda': 7.183245735862915, 'reg_alpha': 5.003389999588296, 'subsample': 0.8471590121169105, 'colsample_bytree': 0.9253241540238196, 'min_child_weight': 7}. Best is trial 0 with value: 2.36398679654312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0, Horizon h=5, Fold 4: RMSE=2.5868, R²=0.7643\n",
      "Trial 0 finished, overall mean RMSE across horizons=2.3640\n",
      "\n",
      "Trial 1, Horizon h=1, Fold 1: RMSE=1.8390, R²=0.8237\n",
      "Trial 1, Horizon h=1, Fold 2: RMSE=1.8309, R²=0.8503\n",
      "Trial 1, Horizon h=1, Fold 3: RMSE=1.6877, R²=0.8886\n",
      "Trial 1, Horizon h=1, Fold 4: RMSE=1.7393, R²=0.8930\n",
      "Trial 1, Horizon h=2, Fold 1: RMSE=2.2624, R²=0.7331\n",
      "Trial 1, Horizon h=2, Fold 2: RMSE=2.4444, R²=0.7323\n",
      "Trial 1, Horizon h=2, Fold 3: RMSE=2.3145, R²=0.7911\n",
      "Trial 1, Horizon h=2, Fold 4: RMSE=2.2987, R²=0.8135\n",
      "Trial 1, Horizon h=3, Fold 1: RMSE=2.3789, R²=0.7051\n",
      "Trial 1, Horizon h=3, Fold 2: RMSE=2.6747, R²=0.6784\n",
      "Trial 1, Horizon h=3, Fold 3: RMSE=2.5639, R²=0.7436\n",
      "Trial 1, Horizon h=3, Fold 4: RMSE=2.5178, R²=0.7763\n",
      "Trial 1, Horizon h=4, Fold 1: RMSE=2.4138, R²=0.6966\n",
      "Trial 1, Horizon h=4, Fold 2: RMSE=2.7363, R²=0.6624\n",
      "Trial 1, Horizon h=4, Fold 3: RMSE=2.6407, R²=0.7282\n",
      "Trial 1, Horizon h=4, Fold 4: RMSE=2.5932, R²=0.7628\n",
      "Trial 1, Horizon h=5, Fold 1: RMSE=2.5165, R²=0.6706\n",
      "Trial 1, Horizon h=5, Fold 2: RMSE=2.7802, R²=0.6510\n",
      "Trial 1, Horizon h=5, Fold 3: RMSE=2.6965, R²=0.7166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:07:52,835] Trial 1 finished with value: 2.3783439985222343 and parameters: {'learning_rate': 0.02884504358693142, 'max_depth': 4, 'gamma': 0.8239988667527282, 'reg_lambda': 7.601689398190267, 'reg_alpha': 5.02550302936182, 'subsample': 0.7407092294539734, 'colsample_bytree': 0.6561406781710444, 'min_child_weight': 7}. Best is trial 0 with value: 2.36398679654312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Horizon h=5, Fold 4: RMSE=2.6375, R²=0.7550\n",
      "Trial 1 finished, overall mean RMSE across horizons=2.3783\n",
      "\n",
      "Trial 2, Horizon h=1, Fold 1: RMSE=1.8463, R²=0.8223\n",
      "Trial 2, Horizon h=1, Fold 2: RMSE=1.8349, R²=0.8497\n",
      "Trial 2, Horizon h=1, Fold 3: RMSE=1.6541, R²=0.8930\n",
      "Trial 2, Horizon h=1, Fold 4: RMSE=1.6836, R²=0.8997\n",
      "Trial 2, Horizon h=2, Fold 1: RMSE=2.2271, R²=0.7413\n",
      "Trial 2, Horizon h=2, Fold 2: RMSE=2.4224, R²=0.7371\n",
      "Trial 2, Horizon h=2, Fold 3: RMSE=2.2603, R²=0.8008\n",
      "Trial 2, Horizon h=2, Fold 4: RMSE=2.2866, R²=0.8155\n",
      "Trial 2, Horizon h=3, Fold 1: RMSE=2.3513, R²=0.7119\n",
      "Trial 2, Horizon h=3, Fold 2: RMSE=2.6750, R²=0.6783\n",
      "Trial 2, Horizon h=3, Fold 3: RMSE=2.5524, R²=0.7458\n",
      "Trial 2, Horizon h=3, Fold 4: RMSE=2.4659, R²=0.7855\n",
      "Trial 2, Horizon h=4, Fold 1: RMSE=2.3957, R²=0.7011\n",
      "Trial 2, Horizon h=4, Fold 2: RMSE=2.7293, R²=0.6641\n",
      "Trial 2, Horizon h=4, Fold 3: RMSE=2.6164, R²=0.7332\n",
      "Trial 2, Horizon h=4, Fold 4: RMSE=2.5662, R²=0.7677\n",
      "Trial 2, Horizon h=5, Fold 1: RMSE=2.4488, R²=0.6881\n",
      "Trial 2, Horizon h=5, Fold 2: RMSE=2.7483, R²=0.6589\n",
      "Trial 2, Horizon h=5, Fold 3: RMSE=2.6772, R²=0.7206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:08:13,148] Trial 2 finished with value: 2.3522760801749585 and parameters: {'learning_rate': 0.018578040709368124, 'max_depth': 3, 'gamma': 0.5133122671200221, 'reg_lambda': 7.035064455532566, 'reg_alpha': 1.560572424377693, 'subsample': 0.7196277547627787, 'colsample_bytree': 0.6987056399431194, 'min_child_weight': 5}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Horizon h=5, Fold 4: RMSE=2.6037, R²=0.7612\n",
      "Trial 2 finished, overall mean RMSE across horizons=2.3523\n",
      "\n",
      "Trial 3, Horizon h=1, Fold 1: RMSE=1.7258, R²=0.8447\n",
      "Trial 3, Horizon h=1, Fold 2: RMSE=1.8437, R²=0.8482\n",
      "Trial 3, Horizon h=1, Fold 3: RMSE=1.7390, R²=0.8817\n",
      "Trial 3, Horizon h=1, Fold 4: RMSE=1.7920, R²=0.8864\n",
      "Trial 3, Horizon h=2, Fold 1: RMSE=2.2930, R²=0.7258\n",
      "Trial 3, Horizon h=2, Fold 2: RMSE=2.4103, R²=0.7397\n",
      "Trial 3, Horizon h=2, Fold 3: RMSE=2.3359, R²=0.7872\n",
      "Trial 3, Horizon h=2, Fold 4: RMSE=2.3187, R²=0.8103\n",
      "Trial 3, Horizon h=3, Fold 1: RMSE=2.4014, R²=0.6995\n",
      "Trial 3, Horizon h=3, Fold 2: RMSE=2.7138, R²=0.6689\n",
      "Trial 3, Horizon h=3, Fold 3: RMSE=2.6615, R²=0.7237\n",
      "Trial 3, Horizon h=3, Fold 4: RMSE=2.5005, R²=0.7794\n",
      "Trial 3, Horizon h=4, Fold 1: RMSE=2.4546, R²=0.6862\n",
      "Trial 3, Horizon h=4, Fold 2: RMSE=2.7972, R²=0.6472\n",
      "Trial 3, Horizon h=4, Fold 3: RMSE=2.6450, R²=0.7273\n",
      "Trial 3, Horizon h=4, Fold 4: RMSE=2.7499, R²=0.7332\n",
      "Trial 3, Horizon h=5, Fold 1: RMSE=2.5658, R²=0.6575\n",
      "Trial 3, Horizon h=5, Fold 2: RMSE=2.8440, R²=0.6348\n",
      "Trial 3, Horizon h=5, Fold 3: RMSE=2.7222, R²=0.7111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:08:27,638] Trial 3 finished with value: 2.4082468403810107 and parameters: {'learning_rate': 0.08330033761342107, 'max_depth': 5, 'gamma': 0.13253396074361468, 'reg_lambda': 2.4136797821078346, 'reg_alpha': 5.047812905081153, 'subsample': 0.5215906211101805, 'colsample_bytree': 0.5906193624864875, 'min_child_weight': 3}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Horizon h=5, Fold 4: RMSE=2.6506, R²=0.7525\n",
      "Trial 3 finished, overall mean RMSE across horizons=2.4082\n",
      "\n",
      "Trial 4, Horizon h=1, Fold 1: RMSE=1.9051, R²=0.8108\n",
      "Trial 4, Horizon h=1, Fold 2: RMSE=1.8448, R²=0.8480\n",
      "Trial 4, Horizon h=1, Fold 3: RMSE=1.6287, R²=0.8962\n",
      "Trial 4, Horizon h=1, Fold 4: RMSE=1.6974, R²=0.8981\n",
      "Trial 4, Horizon h=2, Fold 1: RMSE=2.2517, R²=0.7356\n",
      "Trial 4, Horizon h=2, Fold 2: RMSE=2.4697, R²=0.7267\n",
      "Trial 4, Horizon h=2, Fold 3: RMSE=2.2984, R²=0.7940\n",
      "Trial 4, Horizon h=2, Fold 4: RMSE=2.2419, R²=0.8226\n",
      "Trial 4, Horizon h=3, Fold 1: RMSE=2.3605, R²=0.7096\n",
      "Trial 4, Horizon h=3, Fold 2: RMSE=2.6874, R²=0.6753\n",
      "Trial 4, Horizon h=3, Fold 3: RMSE=2.5474, R²=0.7468\n",
      "Trial 4, Horizon h=3, Fold 4: RMSE=2.4981, R²=0.7798\n",
      "Trial 4, Horizon h=4, Fold 1: RMSE=2.3526, R²=0.7118\n",
      "Trial 4, Horizon h=4, Fold 2: RMSE=2.8206, R²=0.6413\n",
      "Trial 4, Horizon h=4, Fold 3: RMSE=2.6549, R²=0.7253\n",
      "Trial 4, Horizon h=4, Fold 4: RMSE=2.5565, R²=0.7694\n",
      "Trial 4, Horizon h=5, Fold 1: RMSE=2.4581, R²=0.6857\n",
      "Trial 4, Horizon h=5, Fold 2: RMSE=2.8093, R²=0.6436\n",
      "Trial 4, Horizon h=5, Fold 3: RMSE=2.6809, R²=0.7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:08:37,107] Trial 4 finished with value: 2.3664234522778793 and parameters: {'learning_rate': 0.0776964347247832, 'max_depth': 3, 'gamma': 0.639829220302706, 'reg_lambda': 6.030939575781932, 'reg_alpha': 5.239649774780161, 'subsample': 0.7355694795010079, 'colsample_bytree': 0.7146495566848475, 'min_child_weight': 8}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4, Horizon h=5, Fold 4: RMSE=2.5646, R²=0.7683\n",
      "Trial 4 finished, overall mean RMSE across horizons=2.3664\n",
      "\n",
      "Trial 5, Horizon h=1, Fold 1: RMSE=1.7747, R²=0.8358\n",
      "Trial 5, Horizon h=1, Fold 2: RMSE=1.8689, R²=0.8440\n",
      "Trial 5, Horizon h=1, Fold 3: RMSE=1.7466, R²=0.8807\n",
      "Trial 5, Horizon h=1, Fold 4: RMSE=1.7924, R²=0.8864\n",
      "Trial 5, Horizon h=2, Fold 1: RMSE=2.2190, R²=0.7432\n",
      "Trial 5, Horizon h=2, Fold 2: RMSE=2.4367, R²=0.7340\n",
      "Trial 5, Horizon h=2, Fold 3: RMSE=2.3779, R²=0.7795\n",
      "Trial 5, Horizon h=2, Fold 4: RMSE=2.3473, R²=0.8056\n",
      "Trial 5, Horizon h=3, Fold 1: RMSE=2.3774, R²=0.7054\n",
      "Trial 5, Horizon h=3, Fold 2: RMSE=2.6866, R²=0.6755\n",
      "Trial 5, Horizon h=3, Fold 3: RMSE=2.6235, R²=0.7315\n",
      "Trial 5, Horizon h=3, Fold 4: RMSE=2.6065, R²=0.7603\n",
      "Trial 5, Horizon h=4, Fold 1: RMSE=2.4450, R²=0.6887\n",
      "Trial 5, Horizon h=4, Fold 2: RMSE=2.7200, R²=0.6664\n",
      "Trial 5, Horizon h=4, Fold 3: RMSE=2.6847, R²=0.7191\n",
      "Trial 5, Horizon h=4, Fold 4: RMSE=2.6626, R²=0.7499\n",
      "Trial 5, Horizon h=5, Fold 1: RMSE=2.5085, R²=0.6727\n",
      "Trial 5, Horizon h=5, Fold 2: RMSE=2.7900, R²=0.6485\n",
      "Trial 5, Horizon h=5, Fold 3: RMSE=2.7180, R²=0.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:09:12,822] Trial 5 finished with value: 2.4040442461815434 and parameters: {'learning_rate': 0.017348649640232777, 'max_depth': 5, 'gamma': 0.010743601940174874, 'reg_lambda': 8.436985532943275, 'reg_alpha': 9.27362521482227, 'subsample': 0.5957130884161526, 'colsample_bytree': 0.7710631300941404, 'min_child_weight': 8}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5, Horizon h=5, Fold 4: RMSE=2.6947, R²=0.7442\n",
      "Trial 5 finished, overall mean RMSE across horizons=2.4040\n",
      "\n",
      "Trial 6, Horizon h=1, Fold 1: RMSE=1.8433, R²=0.8229\n",
      "Trial 6, Horizon h=1, Fold 2: RMSE=1.8860, R²=0.8412\n",
      "Trial 6, Horizon h=1, Fold 3: RMSE=1.8267, R²=0.8695\n",
      "Trial 6, Horizon h=1, Fold 4: RMSE=1.8774, R²=0.8753\n",
      "Trial 6, Horizon h=2, Fold 1: RMSE=2.3499, R²=0.7120\n",
      "Trial 6, Horizon h=2, Fold 2: RMSE=2.5304, R²=0.7131\n",
      "Trial 6, Horizon h=2, Fold 3: RMSE=2.4063, R²=0.7742\n",
      "Trial 6, Horizon h=2, Fold 4: RMSE=2.3653, R²=0.8026\n",
      "Trial 6, Horizon h=3, Fold 1: RMSE=2.4796, R²=0.6796\n",
      "Trial 6, Horizon h=3, Fold 2: RMSE=2.8049, R²=0.6463\n",
      "Trial 6, Horizon h=3, Fold 3: RMSE=2.6801, R²=0.7198\n",
      "Trial 6, Horizon h=3, Fold 4: RMSE=2.6746, R²=0.7476\n",
      "Trial 6, Horizon h=4, Fold 1: RMSE=2.4818, R²=0.6792\n",
      "Trial 6, Horizon h=4, Fold 2: RMSE=2.7091, R²=0.6691\n",
      "Trial 6, Horizon h=4, Fold 3: RMSE=2.7155, R²=0.7126\n",
      "Trial 6, Horizon h=4, Fold 4: RMSE=2.6378, R²=0.7545\n",
      "Trial 6, Horizon h=5, Fold 1: RMSE=2.6060, R²=0.6467\n",
      "Trial 6, Horizon h=5, Fold 2: RMSE=2.7303, R²=0.6634\n",
      "Trial 6, Horizon h=5, Fold 3: RMSE=2.8405, R²=0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:09:29,882] Trial 6 finished with value: 2.456296253248439 and parameters: {'learning_rate': 0.09846193266433644, 'max_depth': 6, 'gamma': 0.4877017254980929, 'reg_lambda': 8.295738815865764, 'reg_alpha': 4.056277079408522, 'subsample': 0.986918703793189, 'colsample_bytree': 0.7536046796377436, 'min_child_weight': 4}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6, Horizon h=5, Fold 4: RMSE=2.6803, R²=0.7469\n",
      "Trial 6 finished, overall mean RMSE across horizons=2.4563\n",
      "\n",
      "Trial 7, Horizon h=1, Fold 1: RMSE=1.7616, R²=0.8382\n",
      "Trial 7, Horizon h=1, Fold 2: RMSE=1.8612, R²=0.8453\n",
      "Trial 7, Horizon h=1, Fold 3: RMSE=1.7032, R²=0.8865\n",
      "Trial 7, Horizon h=1, Fold 4: RMSE=1.8148, R²=0.8835\n",
      "Trial 7, Horizon h=2, Fold 1: RMSE=2.2534, R²=0.7352\n",
      "Trial 7, Horizon h=2, Fold 2: RMSE=2.4828, R²=0.7238\n",
      "Trial 7, Horizon h=2, Fold 3: RMSE=2.4191, R²=0.7718\n",
      "Trial 7, Horizon h=2, Fold 4: RMSE=2.2795, R²=0.8166\n",
      "Trial 7, Horizon h=3, Fold 1: RMSE=2.3980, R²=0.7003\n",
      "Trial 7, Horizon h=3, Fold 2: RMSE=2.7188, R²=0.6677\n",
      "Trial 7, Horizon h=3, Fold 3: RMSE=2.6164, R²=0.7329\n",
      "Trial 7, Horizon h=3, Fold 4: RMSE=2.5954, R²=0.7623\n",
      "Trial 7, Horizon h=4, Fold 1: RMSE=2.4767, R²=0.6805\n",
      "Trial 7, Horizon h=4, Fold 2: RMSE=2.7392, R²=0.6617\n",
      "Trial 7, Horizon h=4, Fold 3: RMSE=2.7064, R²=0.7145\n",
      "Trial 7, Horizon h=4, Fold 4: RMSE=2.6478, R²=0.7527\n",
      "Trial 7, Horizon h=5, Fold 1: RMSE=2.4907, R²=0.6773\n",
      "Trial 7, Horizon h=5, Fold 2: RMSE=2.7625, R²=0.6554\n",
      "Trial 7, Horizon h=5, Fold 3: RMSE=2.8312, R²=0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:09:56,108] Trial 7 finished with value: 2.4163524489166432 and parameters: {'learning_rate': 0.04766421794781486, 'max_depth': 6, 'gamma': 0.45645684813775533, 'reg_lambda': 4.912094331598503, 'reg_alpha': 0.32027898282962597, 'subsample': 0.6573528920594462, 'colsample_bytree': 0.8791419229715918, 'min_child_weight': 7}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7, Horizon h=5, Fold 4: RMSE=2.7681, R²=0.7301\n",
      "Trial 7 finished, overall mean RMSE across horizons=2.4164\n",
      "\n",
      "Trial 8, Horizon h=1, Fold 1: RMSE=1.8303, R²=0.8254\n",
      "Trial 8, Horizon h=1, Fold 2: RMSE=1.9214, R²=0.8352\n",
      "Trial 8, Horizon h=1, Fold 3: RMSE=1.7379, R²=0.8819\n",
      "Trial 8, Horizon h=1, Fold 4: RMSE=1.8081, R²=0.8844\n",
      "Trial 8, Horizon h=2, Fold 1: RMSE=2.3075, R²=0.7223\n",
      "Trial 8, Horizon h=2, Fold 2: RMSE=2.4806, R²=0.7243\n",
      "Trial 8, Horizon h=2, Fold 3: RMSE=2.3754, R²=0.7799\n",
      "Trial 8, Horizon h=2, Fold 4: RMSE=2.3246, R²=0.8093\n",
      "Trial 8, Horizon h=3, Fold 1: RMSE=2.4512, R²=0.6869\n",
      "Trial 8, Horizon h=3, Fold 2: RMSE=2.6989, R²=0.6725\n",
      "Trial 8, Horizon h=3, Fold 3: RMSE=2.6148, R²=0.7333\n",
      "Trial 8, Horizon h=3, Fold 4: RMSE=2.5729, R²=0.7664\n",
      "Trial 8, Horizon h=4, Fold 1: RMSE=2.4482, R²=0.6878\n",
      "Trial 8, Horizon h=4, Fold 2: RMSE=2.7353, R²=0.6627\n",
      "Trial 8, Horizon h=4, Fold 3: RMSE=2.7063, R²=0.7145\n",
      "Trial 8, Horizon h=4, Fold 4: RMSE=2.6383, R²=0.7544\n",
      "Trial 8, Horizon h=5, Fold 1: RMSE=2.5122, R²=0.6717\n",
      "Trial 8, Horizon h=5, Fold 2: RMSE=2.7845, R²=0.6499\n",
      "Trial 8, Horizon h=5, Fold 3: RMSE=2.8051, R²=0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:10:30,336] Trial 8 finished with value: 2.423791326527011 and parameters: {'learning_rate': 0.03109308989011622, 'max_depth': 6, 'gamma': 0.7987552020496305, 'reg_lambda': 8.907706218200591, 'reg_alpha': 4.368651183928777, 'subsample': 0.9355468198559824, 'colsample_bytree': 0.7471495075855984, 'min_child_weight': 10}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8, Horizon h=5, Fold 4: RMSE=2.7223, R²=0.7389\n",
      "Trial 8 finished, overall mean RMSE across horizons=2.4238\n",
      "\n",
      "Trial 9, Horizon h=1, Fold 1: RMSE=1.8303, R²=0.8254\n",
      "Trial 9, Horizon h=1, Fold 2: RMSE=1.8460, R²=0.8478\n",
      "Trial 9, Horizon h=1, Fold 3: RMSE=1.7830, R²=0.8756\n",
      "Trial 9, Horizon h=1, Fold 4: RMSE=1.7769, R²=0.8883\n",
      "Trial 9, Horizon h=2, Fold 1: RMSE=2.2940, R²=0.7256\n",
      "Trial 9, Horizon h=2, Fold 2: RMSE=2.4799, R²=0.7245\n",
      "Trial 9, Horizon h=2, Fold 3: RMSE=2.3927, R²=0.7767\n",
      "Trial 9, Horizon h=2, Fold 4: RMSE=2.3207, R²=0.8099\n",
      "Trial 9, Horizon h=3, Fold 1: RMSE=2.4613, R²=0.6843\n",
      "Trial 9, Horizon h=3, Fold 2: RMSE=2.7905, R²=0.6499\n",
      "Trial 9, Horizon h=3, Fold 3: RMSE=2.6332, R²=0.7295\n",
      "Trial 9, Horizon h=3, Fold 4: RMSE=2.5596, R²=0.7688\n",
      "Trial 9, Horizon h=4, Fold 1: RMSE=2.4609, R²=0.6846\n",
      "Trial 9, Horizon h=4, Fold 2: RMSE=2.7293, R²=0.6642\n",
      "Trial 9, Horizon h=4, Fold 3: RMSE=2.7127, R²=0.7132\n",
      "Trial 9, Horizon h=4, Fold 4: RMSE=2.6408, R²=0.7540\n",
      "Trial 9, Horizon h=5, Fold 1: RMSE=2.6100, R²=0.6456\n",
      "Trial 9, Horizon h=5, Fold 2: RMSE=2.7092, R²=0.6686\n",
      "Trial 9, Horizon h=5, Fold 3: RMSE=2.7845, R²=0.6978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:11:09,766] Trial 9 finished with value: 2.4247700481379453 and parameters: {'learning_rate': 0.016190826193520667, 'max_depth': 5, 'gamma': 0.711781300689653, 'reg_lambda': 8.082261863037239, 'reg_alpha': 4.540291852766476, 'subsample': 0.8811509142624836, 'colsample_bytree': 0.9725617727642251, 'min_child_weight': 7}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9, Horizon h=5, Fold 4: RMSE=2.6800, R²=0.7470\n",
      "Trial 9 finished, overall mean RMSE across horizons=2.4248\n",
      "\n",
      "Trial 10, Horizon h=1, Fold 1: RMSE=1.9246, R²=0.8069\n",
      "Trial 10, Horizon h=1, Fold 2: RMSE=1.9510, R²=0.8300\n",
      "Trial 10, Horizon h=1, Fold 3: RMSE=1.6374, R²=0.8951\n",
      "Trial 10, Horizon h=1, Fold 4: RMSE=1.8027, R²=0.8851\n",
      "Trial 10, Horizon h=2, Fold 1: RMSE=2.3499, R²=0.7120\n",
      "Trial 10, Horizon h=2, Fold 2: RMSE=2.4676, R²=0.7272\n",
      "Trial 10, Horizon h=2, Fold 3: RMSE=2.3189, R²=0.7903\n",
      "Trial 10, Horizon h=2, Fold 4: RMSE=2.2180, R²=0.8264\n",
      "Trial 10, Horizon h=3, Fold 1: RMSE=2.4394, R²=0.6899\n",
      "Trial 10, Horizon h=3, Fold 2: RMSE=2.7318, R²=0.6645\n",
      "Trial 10, Horizon h=3, Fold 3: RMSE=2.6092, R²=0.7344\n",
      "Trial 10, Horizon h=3, Fold 4: RMSE=2.5261, R²=0.7749\n",
      "Trial 10, Horizon h=4, Fold 1: RMSE=2.5688, R²=0.6563\n",
      "Trial 10, Horizon h=4, Fold 2: RMSE=2.7494, R²=0.6592\n",
      "Trial 10, Horizon h=4, Fold 3: RMSE=2.6246, R²=0.7315\n",
      "Trial 10, Horizon h=4, Fold 4: RMSE=2.5548, R²=0.7697\n",
      "Trial 10, Horizon h=5, Fold 1: RMSE=2.6636, R²=0.6309\n",
      "Trial 10, Horizon h=5, Fold 2: RMSE=2.8091, R²=0.6437\n",
      "Trial 10, Horizon h=5, Fold 3: RMSE=2.8072, R²=0.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:11:17,311] Trial 10 finished with value: 2.4195914497561484 and parameters: {'learning_rate': 0.2648266384813408, 'max_depth': 4, 'gamma': 0.25151760720207017, 'reg_lambda': 4.045030081189797, 'reg_alpha': 0.016384503807170603, 'subsample': 0.8227627750472415, 'colsample_bytree': 0.5215059686790675, 'min_child_weight': 5}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10, Horizon h=5, Fold 4: RMSE=2.6376, R²=0.7549\n",
      "Trial 10 finished, overall mean RMSE across horizons=2.4196\n",
      "\n",
      "Trial 11, Horizon h=1, Fold 1: RMSE=1.8285, R²=0.8257\n",
      "Trial 11, Horizon h=1, Fold 2: RMSE=1.8366, R²=0.8494\n",
      "Trial 11, Horizon h=1, Fold 3: RMSE=1.6722, R²=0.8906\n",
      "Trial 11, Horizon h=1, Fold 4: RMSE=1.6866, R²=0.8994\n",
      "Trial 11, Horizon h=2, Fold 1: RMSE=2.2134, R²=0.7445\n",
      "Trial 11, Horizon h=2, Fold 2: RMSE=2.4362, R²=0.7341\n",
      "Trial 11, Horizon h=2, Fold 3: RMSE=2.2729, R²=0.7985\n",
      "Trial 11, Horizon h=2, Fold 4: RMSE=2.2731, R²=0.8177\n",
      "Trial 11, Horizon h=3, Fold 1: RMSE=2.3764, R²=0.7057\n",
      "Trial 11, Horizon h=3, Fold 2: RMSE=2.6920, R²=0.6742\n",
      "Trial 11, Horizon h=3, Fold 3: RMSE=2.5807, R²=0.7402\n",
      "Trial 11, Horizon h=3, Fold 4: RMSE=2.4933, R²=0.7807\n",
      "Trial 11, Horizon h=4, Fold 1: RMSE=2.4174, R²=0.6957\n",
      "Trial 11, Horizon h=4, Fold 2: RMSE=2.7542, R²=0.6580\n",
      "Trial 11, Horizon h=4, Fold 3: RMSE=2.6256, R²=0.7313\n",
      "Trial 11, Horizon h=4, Fold 4: RMSE=2.5590, R²=0.7690\n",
      "Trial 11, Horizon h=5, Fold 1: RMSE=2.4749, R²=0.6814\n",
      "Trial 11, Horizon h=5, Fold 2: RMSE=2.7839, R²=0.6500\n",
      "Trial 11, Horizon h=5, Fold 3: RMSE=2.6979, R²=0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:11:40,591] Trial 11 finished with value: 2.363642260184711 and parameters: {'learning_rate': 0.012132591191593538, 'max_depth': 3, 'gamma': 0.38011974475273014, 'reg_lambda': 6.545135683213589, 'reg_alpha': 1.7164525829864277, 'subsample': 0.8225124365264791, 'colsample_bytree': 0.8681697811556655, 'min_child_weight': 5}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11, Horizon h=5, Fold 4: RMSE=2.5981, R²=0.7622\n",
      "Trial 11 finished, overall mean RMSE across horizons=2.3636\n",
      "\n",
      "Trial 12, Horizon h=1, Fold 1: RMSE=1.7902, R²=0.8329\n",
      "Trial 12, Horizon h=1, Fold 2: RMSE=1.8520, R²=0.8468\n",
      "Trial 12, Horizon h=1, Fold 3: RMSE=1.6938, R²=0.8878\n",
      "Trial 12, Horizon h=1, Fold 4: RMSE=1.6891, R²=0.8991\n",
      "Trial 12, Horizon h=2, Fold 1: RMSE=2.2138, R²=0.7444\n",
      "Trial 12, Horizon h=2, Fold 2: RMSE=2.3998, R²=0.7420\n",
      "Trial 12, Horizon h=2, Fold 3: RMSE=2.2578, R²=0.8012\n",
      "Trial 12, Horizon h=2, Fold 4: RMSE=2.2559, R²=0.8204\n",
      "Trial 12, Horizon h=3, Fold 1: RMSE=2.3715, R²=0.7069\n",
      "Trial 12, Horizon h=3, Fold 2: RMSE=2.6734, R²=0.6787\n",
      "Trial 12, Horizon h=3, Fold 3: RMSE=2.5644, R²=0.7435\n",
      "Trial 12, Horizon h=3, Fold 4: RMSE=2.4883, R²=0.7815\n",
      "Trial 12, Horizon h=4, Fold 1: RMSE=2.3900, R²=0.7025\n",
      "Trial 12, Horizon h=4, Fold 2: RMSE=2.7070, R²=0.6696\n",
      "Trial 12, Horizon h=4, Fold 3: RMSE=2.6366, R²=0.7291\n",
      "Trial 12, Horizon h=4, Fold 4: RMSE=2.5909, R²=0.7632\n",
      "Trial 12, Horizon h=5, Fold 1: RMSE=2.4527, R²=0.6871\n",
      "Trial 12, Horizon h=5, Fold 2: RMSE=2.7565, R²=0.6569\n",
      "Trial 12, Horizon h=5, Fold 3: RMSE=2.6922, R²=0.7175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:12:07,816] Trial 12 finished with value: 2.3535245774592126 and parameters: {'learning_rate': 0.01010821790584235, 'max_depth': 3, 'gamma': 0.2991260405363726, 'reg_lambda': 9.856493236810545, 'reg_alpha': 2.2804709005733104, 'subsample': 0.6864545132259806, 'colsample_bytree': 0.8462098244662244, 'min_child_weight': 5}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12, Horizon h=5, Fold 4: RMSE=2.5946, R²=0.7629\n",
      "Trial 12 finished, overall mean RMSE across horizons=2.3535\n",
      "\n",
      "Trial 13, Horizon h=1, Fold 1: RMSE=1.7579, R²=0.8389\n",
      "Trial 13, Horizon h=1, Fold 2: RMSE=1.8497, R²=0.8472\n",
      "Trial 13, Horizon h=1, Fold 3: RMSE=1.7186, R²=0.8845\n",
      "Trial 13, Horizon h=1, Fold 4: RMSE=1.7346, R²=0.8936\n",
      "Trial 13, Horizon h=2, Fold 1: RMSE=2.2218, R²=0.7426\n",
      "Trial 13, Horizon h=2, Fold 2: RMSE=2.4231, R²=0.7370\n",
      "Trial 13, Horizon h=2, Fold 3: RMSE=2.3447, R²=0.7856\n",
      "Trial 13, Horizon h=2, Fold 4: RMSE=2.2774, R²=0.8170\n",
      "Trial 13, Horizon h=3, Fold 1: RMSE=2.3871, R²=0.7031\n",
      "Trial 13, Horizon h=3, Fold 2: RMSE=2.7059, R²=0.6708\n",
      "Trial 13, Horizon h=3, Fold 3: RMSE=2.5827, R²=0.7398\n",
      "Trial 13, Horizon h=3, Fold 4: RMSE=2.5060, R²=0.7784\n",
      "Trial 13, Horizon h=4, Fold 1: RMSE=2.4233, R²=0.6942\n",
      "Trial 13, Horizon h=4, Fold 2: RMSE=2.7222, R²=0.6659\n",
      "Trial 13, Horizon h=4, Fold 3: RMSE=2.6696, R²=0.7222\n",
      "Trial 13, Horizon h=4, Fold 4: RMSE=2.6365, R²=0.7548\n",
      "Trial 13, Horizon h=5, Fold 1: RMSE=2.5239, R²=0.6686\n",
      "Trial 13, Horizon h=5, Fold 2: RMSE=2.7229, R²=0.6652\n",
      "Trial 13, Horizon h=5, Fold 3: RMSE=2.7133, R²=0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:12:42,871] Trial 13 finished with value: 2.379283328686421 and parameters: {'learning_rate': 0.010547136238290436, 'max_depth': 4, 'gamma': 0.9688894421302083, 'reg_lambda': 9.597627322516361, 'reg_alpha': 2.382368579522279, 'subsample': 0.6634143548377993, 'colsample_bytree': 0.8355395873182367, 'min_child_weight': 5}. Best is trial 2 with value: 2.3522760801749585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13, Horizon h=5, Fold 4: RMSE=2.6646, R²=0.7499\n",
      "Trial 13 finished, overall mean RMSE across horizons=2.3793\n",
      "\n",
      "Trial 14, Horizon h=1, Fold 1: RMSE=1.7988, R²=0.8313\n",
      "Trial 14, Horizon h=1, Fold 2: RMSE=1.8227, R²=0.8517\n",
      "Trial 14, Horizon h=1, Fold 3: RMSE=1.6775, R²=0.8899\n",
      "Trial 14, Horizon h=1, Fold 4: RMSE=1.6883, R²=0.8992\n",
      "Trial 14, Horizon h=2, Fold 1: RMSE=2.1921, R²=0.7494\n",
      "Trial 14, Horizon h=2, Fold 2: RMSE=2.4119, R²=0.7394\n",
      "Trial 14, Horizon h=2, Fold 3: RMSE=2.2457, R²=0.8033\n",
      "Trial 14, Horizon h=2, Fold 4: RMSE=2.2571, R²=0.8202\n",
      "Trial 14, Horizon h=3, Fold 1: RMSE=2.3552, R²=0.7109\n",
      "Trial 14, Horizon h=3, Fold 2: RMSE=2.6630, R²=0.6812\n",
      "Trial 14, Horizon h=3, Fold 3: RMSE=2.5336, R²=0.7496\n",
      "Trial 14, Horizon h=3, Fold 4: RMSE=2.5000, R²=0.7795\n",
      "Trial 14, Horizon h=4, Fold 1: RMSE=2.3602, R²=0.7099\n",
      "Trial 14, Horizon h=4, Fold 2: RMSE=2.6955, R²=0.6724\n",
      "Trial 14, Horizon h=4, Fold 3: RMSE=2.6327, R²=0.7299\n",
      "Trial 14, Horizon h=4, Fold 4: RMSE=2.5794, R²=0.7653\n",
      "Trial 14, Horizon h=5, Fold 1: RMSE=2.4529, R²=0.6870\n",
      "Trial 14, Horizon h=5, Fold 2: RMSE=2.7287, R²=0.6638\n",
      "Trial 14, Horizon h=5, Fold 3: RMSE=2.6664, R²=0.7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:13:08,990] Trial 14 finished with value: 2.3436899157596134 and parameters: {'learning_rate': 0.010438141760219184, 'max_depth': 3, 'gamma': 0.3122852500423123, 'reg_lambda': 9.721144091310862, 'reg_alpha': 2.437650835020749, 'subsample': 0.6710993558374608, 'colsample_bytree': 0.6685633615567157, 'min_child_weight': 3}. Best is trial 14 with value: 2.3436899157596134.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14, Horizon h=5, Fold 4: RMSE=2.6123, R²=0.7596\n",
      "Trial 14 finished, overall mean RMSE across horizons=2.3437\n",
      "\n",
      "Trial 15, Horizon h=1, Fold 1: RMSE=1.7773, R²=0.8353\n",
      "Trial 15, Horizon h=1, Fold 2: RMSE=1.8216, R²=0.8518\n",
      "Trial 15, Horizon h=1, Fold 3: RMSE=1.7158, R²=0.8848\n",
      "Trial 15, Horizon h=1, Fold 4: RMSE=1.7465, R²=0.8921\n",
      "Trial 15, Horizon h=2, Fold 1: RMSE=2.2422, R²=0.7378\n",
      "Trial 15, Horizon h=2, Fold 2: RMSE=2.4362, R²=0.7341\n",
      "Trial 15, Horizon h=2, Fold 3: RMSE=2.3120, R²=0.7915\n",
      "Trial 15, Horizon h=2, Fold 4: RMSE=2.2912, R²=0.8147\n",
      "Trial 15, Horizon h=3, Fold 1: RMSE=2.4323, R²=0.6917\n",
      "Trial 15, Horizon h=3, Fold 2: RMSE=2.6401, R²=0.6866\n",
      "Trial 15, Horizon h=3, Fold 3: RMSE=2.5738, R²=0.7416\n",
      "Trial 15, Horizon h=3, Fold 4: RMSE=2.5185, R²=0.7762\n",
      "Trial 15, Horizon h=4, Fold 1: RMSE=2.4260, R²=0.6935\n",
      "Trial 15, Horizon h=4, Fold 2: RMSE=2.7177, R²=0.6670\n",
      "Trial 15, Horizon h=4, Fold 3: RMSE=2.6190, R²=0.7327\n",
      "Trial 15, Horizon h=4, Fold 4: RMSE=2.5979, R²=0.7619\n",
      "Trial 15, Horizon h=5, Fold 1: RMSE=2.5060, R²=0.6733\n",
      "Trial 15, Horizon h=5, Fold 2: RMSE=2.7674, R²=0.6542\n",
      "Trial 15, Horizon h=5, Fold 3: RMSE=2.7206, R²=0.7115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:13:27,114] Trial 15 finished with value: 2.375201781951605 and parameters: {'learning_rate': 0.02944428519491123, 'max_depth': 4, 'gamma': 0.2129864996590361, 'reg_lambda': 4.616335466774247, 'reg_alpha': 6.795753878381174, 'subsample': 0.5921170994431172, 'colsample_bytree': 0.6413792468711683, 'min_child_weight': 3}. Best is trial 14 with value: 2.3436899157596134.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15, Horizon h=5, Fold 4: RMSE=2.6419, R²=0.7541\n",
      "Trial 15 finished, overall mean RMSE across horizons=2.3752\n",
      "\n",
      "Trial 16, Horizon h=1, Fold 1: RMSE=1.9889, R²=0.7938\n",
      "Trial 16, Horizon h=1, Fold 2: RMSE=1.8935, R²=0.8399\n",
      "Trial 16, Horizon h=1, Fold 3: RMSE=1.6604, R²=0.8922\n",
      "Trial 16, Horizon h=1, Fold 4: RMSE=1.7249, R²=0.8948\n",
      "Trial 16, Horizon h=2, Fold 1: RMSE=2.3158, R²=0.7203\n",
      "Trial 16, Horizon h=2, Fold 2: RMSE=2.4654, R²=0.7277\n",
      "Trial 16, Horizon h=2, Fold 3: RMSE=2.2811, R²=0.7971\n",
      "Trial 16, Horizon h=2, Fold 4: RMSE=2.2141, R²=0.8270\n",
      "Trial 16, Horizon h=3, Fold 1: RMSE=2.3953, R²=0.7010\n",
      "Trial 16, Horizon h=3, Fold 2: RMSE=2.6807, R²=0.6769\n",
      "Trial 16, Horizon h=3, Fold 3: RMSE=2.5987, R²=0.7365\n",
      "Trial 16, Horizon h=3, Fold 4: RMSE=2.4623, R²=0.7861\n",
      "Trial 16, Horizon h=4, Fold 1: RMSE=2.3449, R²=0.7136\n",
      "Trial 16, Horizon h=4, Fold 2: RMSE=2.8276, R²=0.6395\n",
      "Trial 16, Horizon h=4, Fold 3: RMSE=2.7003, R²=0.7158\n",
      "Trial 16, Horizon h=4, Fold 4: RMSE=2.5445, R²=0.7716\n",
      "Trial 16, Horizon h=5, Fold 1: RMSE=2.4048, R²=0.6992\n",
      "Trial 16, Horizon h=5, Fold 2: RMSE=2.7884, R²=0.6489\n",
      "Trial 16, Horizon h=5, Fold 3: RMSE=2.7041, R²=0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:13:34,237] Trial 16 finished with value: 2.3762324231938003 and parameters: {'learning_rate': 0.18628243459522564, 'max_depth': 3, 'gamma': 0.40552411732004146, 'reg_lambda': 2.7717608019830156, 'reg_alpha': 1.4184338209121456, 'subsample': 0.7671906947084433, 'colsample_bytree': 0.6727795777597498, 'min_child_weight': 4}. Best is trial 14 with value: 2.3436899157596134.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16, Horizon h=5, Fold 4: RMSE=2.5291, R²=0.7747\n",
      "Trial 16 finished, overall mean RMSE across horizons=2.3762\n",
      "\n",
      "Trial 17, Horizon h=1, Fold 1: RMSE=1.8225, R²=0.8268\n",
      "Trial 17, Horizon h=1, Fold 2: RMSE=1.8349, R²=0.8497\n",
      "Trial 17, Horizon h=1, Fold 3: RMSE=1.6282, R²=0.8963\n",
      "Trial 17, Horizon h=1, Fold 4: RMSE=1.6437, R²=0.9044\n",
      "Trial 17, Horizon h=2, Fold 1: RMSE=2.2337, R²=0.7398\n",
      "Trial 17, Horizon h=2, Fold 2: RMSE=2.4206, R²=0.7375\n",
      "Trial 17, Horizon h=2, Fold 3: RMSE=2.2740, R²=0.7983\n",
      "Trial 17, Horizon h=2, Fold 4: RMSE=2.2507, R²=0.8212\n",
      "Trial 17, Horizon h=3, Fold 1: RMSE=2.3441, R²=0.7136\n",
      "Trial 17, Horizon h=3, Fold 2: RMSE=2.6162, R²=0.6923\n",
      "Trial 17, Horizon h=3, Fold 3: RMSE=2.5302, R²=0.7503\n",
      "Trial 17, Horizon h=3, Fold 4: RMSE=2.4923, R²=0.7808\n",
      "Trial 17, Horizon h=4, Fold 1: RMSE=2.3608, R²=0.7097\n",
      "Trial 17, Horizon h=4, Fold 2: RMSE=2.7083, R²=0.6693\n",
      "Trial 17, Horizon h=4, Fold 3: RMSE=2.6126, R²=0.7340\n",
      "Trial 17, Horizon h=4, Fold 4: RMSE=2.5879, R²=0.7637\n",
      "Trial 17, Horizon h=5, Fold 1: RMSE=2.4565, R²=0.6861\n",
      "Trial 17, Horizon h=5, Fold 2: RMSE=2.7632, R²=0.6552\n",
      "Trial 17, Horizon h=5, Fold 3: RMSE=2.6648, R²=0.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:13:45,192] Trial 17 finished with value: 2.340564275129548 and parameters: {'learning_rate': 0.04593560960722605, 'max_depth': 3, 'gamma': 0.5611948069526662, 'reg_lambda': 6.742565317105491, 'reg_alpha': 3.2335084723839853, 'subsample': 0.6013785234615592, 'colsample_bytree': 0.5719145748939403, 'min_child_weight': 4}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17, Horizon h=5, Fold 4: RMSE=2.5659, R²=0.7681\n",
      "Trial 17 finished, overall mean RMSE across horizons=2.3406\n",
      "\n",
      "Trial 18, Horizon h=1, Fold 1: RMSE=1.8004, R²=0.8310\n",
      "Trial 18, Horizon h=1, Fold 2: RMSE=1.7535, R²=0.8627\n",
      "Trial 18, Horizon h=1, Fold 3: RMSE=1.6456, R²=0.8941\n",
      "Trial 18, Horizon h=1, Fold 4: RMSE=1.7512, R²=0.8915\n",
      "Trial 18, Horizon h=2, Fold 1: RMSE=2.2340, R²=0.7397\n",
      "Trial 18, Horizon h=2, Fold 2: RMSE=2.3905, R²=0.7440\n",
      "Trial 18, Horizon h=2, Fold 3: RMSE=2.3013, R²=0.7935\n",
      "Trial 18, Horizon h=2, Fold 4: RMSE=2.2948, R²=0.8142\n",
      "Trial 18, Horizon h=3, Fold 1: RMSE=2.3821, R²=0.7043\n",
      "Trial 18, Horizon h=3, Fold 2: RMSE=2.6543, R²=0.6832\n",
      "Trial 18, Horizon h=3, Fold 3: RMSE=2.4928, R²=0.7576\n",
      "Trial 18, Horizon h=3, Fold 4: RMSE=2.4916, R²=0.7810\n",
      "Trial 18, Horizon h=4, Fold 1: RMSE=2.4501, R²=0.6874\n",
      "Trial 18, Horizon h=4, Fold 2: RMSE=2.7256, R²=0.6650\n",
      "Trial 18, Horizon h=4, Fold 3: RMSE=2.5965, R²=0.7372\n",
      "Trial 18, Horizon h=4, Fold 4: RMSE=2.5568, R²=0.7694\n",
      "Trial 18, Horizon h=5, Fold 1: RMSE=2.5078, R²=0.6728\n",
      "Trial 18, Horizon h=5, Fold 2: RMSE=2.8458, R²=0.6343\n",
      "Trial 18, Horizon h=5, Fold 3: RMSE=2.7257, R²=0.7104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:13:57,576] Trial 18 finished with value: 2.359847223724052 and parameters: {'learning_rate': 0.0517847631033106, 'max_depth': 4, 'gamma': 0.1295948796824224, 'reg_lambda': 3.556999727085627, 'reg_alpha': 3.1349429477997215, 'subsample': 0.5089654332068325, 'colsample_bytree': 0.537361248265967, 'min_child_weight': 3}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18, Horizon h=5, Fold 4: RMSE=2.5964, R²=0.7625\n",
      "Trial 18 finished, overall mean RMSE across horizons=2.3598\n",
      "\n",
      "Trial 19, Horizon h=1, Fold 1: RMSE=1.8820, R²=0.8154\n",
      "Trial 19, Horizon h=1, Fold 2: RMSE=1.9031, R²=0.8383\n",
      "Trial 19, Horizon h=1, Fold 3: RMSE=1.6954, R²=0.8876\n",
      "Trial 19, Horizon h=1, Fold 4: RMSE=1.6797, R²=0.9002\n",
      "Trial 19, Horizon h=2, Fold 1: RMSE=2.2604, R²=0.7335\n",
      "Trial 19, Horizon h=2, Fold 2: RMSE=2.4064, R²=0.7406\n",
      "Trial 19, Horizon h=2, Fold 3: RMSE=2.2899, R²=0.7955\n",
      "Trial 19, Horizon h=2, Fold 4: RMSE=2.2616, R²=0.8195\n",
      "Trial 19, Horizon h=3, Fold 1: RMSE=2.4058, R²=0.6984\n",
      "Trial 19, Horizon h=3, Fold 2: RMSE=2.6866, R²=0.6755\n",
      "Trial 19, Horizon h=3, Fold 3: RMSE=2.5488, R²=0.7466\n",
      "Trial 19, Horizon h=3, Fold 4: RMSE=2.4521, R²=0.7879\n",
      "Trial 19, Horizon h=4, Fold 1: RMSE=2.4193, R²=0.6952\n",
      "Trial 19, Horizon h=4, Fold 2: RMSE=2.7406, R²=0.6614\n",
      "Trial 19, Horizon h=4, Fold 3: RMSE=2.6356, R²=0.7293\n",
      "Trial 19, Horizon h=4, Fold 4: RMSE=2.5773, R²=0.7657\n",
      "Trial 19, Horizon h=5, Fold 1: RMSE=2.4670, R²=0.6834\n",
      "Trial 19, Horizon h=5, Fold 2: RMSE=2.7620, R²=0.6555\n",
      "Trial 19, Horizon h=5, Fold 3: RMSE=2.6908, R²=0.7178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:14:04,936] Trial 19 finished with value: 2.3668893677168676 and parameters: {'learning_rate': 0.13265854855389975, 'max_depth': 3, 'gamma': 0.33897994478682003, 'reg_lambda': 5.632937839531468, 'reg_alpha': 6.533663514917301, 'subsample': 0.5912736787475309, 'colsample_bytree': 0.5910343652464067, 'min_child_weight': 4}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19, Horizon h=5, Fold 4: RMSE=2.5737, R²=0.7667\n",
      "Trial 19 finished, overall mean RMSE across horizons=2.3669\n",
      "\n",
      "Trial 20, Horizon h=1, Fold 1: RMSE=1.7873, R²=0.8335\n",
      "Trial 20, Horizon h=1, Fold 2: RMSE=1.8020, R²=0.8550\n",
      "Trial 20, Horizon h=1, Fold 3: RMSE=1.6550, R²=0.8929\n",
      "Trial 20, Horizon h=1, Fold 4: RMSE=1.7666, R²=0.8896\n",
      "Trial 20, Horizon h=2, Fold 1: RMSE=2.2204, R²=0.7429\n",
      "Trial 20, Horizon h=2, Fold 2: RMSE=2.4388, R²=0.7335\n",
      "Trial 20, Horizon h=2, Fold 3: RMSE=2.3367, R²=0.7871\n",
      "Trial 20, Horizon h=2, Fold 4: RMSE=2.3471, R²=0.8056\n",
      "Trial 20, Horizon h=3, Fold 1: RMSE=2.3903, R²=0.7023\n",
      "Trial 20, Horizon h=3, Fold 2: RMSE=2.6672, R²=0.6802\n",
      "Trial 20, Horizon h=3, Fold 3: RMSE=2.5302, R²=0.7502\n",
      "Trial 20, Horizon h=3, Fold 4: RMSE=2.5251, R²=0.7750\n",
      "Trial 20, Horizon h=4, Fold 1: RMSE=2.4075, R²=0.6981\n",
      "Trial 20, Horizon h=4, Fold 2: RMSE=2.7264, R²=0.6648\n",
      "Trial 20, Horizon h=4, Fold 3: RMSE=2.6562, R²=0.7250\n",
      "Trial 20, Horizon h=4, Fold 4: RMSE=2.5991, R²=0.7617\n",
      "Trial 20, Horizon h=5, Fold 1: RMSE=2.4879, R²=0.6780\n",
      "Trial 20, Horizon h=5, Fold 2: RMSE=2.7296, R²=0.6636\n",
      "Trial 20, Horizon h=5, Fold 3: RMSE=2.6969, R²=0.7165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:14:18,974] Trial 20 finished with value: 2.3705770775010366 and parameters: {'learning_rate': 0.039484527896854624, 'max_depth': 4, 'gamma': 0.6216466991549551, 'reg_lambda': 9.09677940920502, 'reg_alpha': 3.1955723787180452, 'subsample': 0.6325709570156025, 'colsample_bytree': 0.5792255280109577, 'min_child_weight': 6}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20, Horizon h=5, Fold 4: RMSE=2.6414, R²=0.7542\n",
      "Trial 20 finished, overall mean RMSE across horizons=2.3706\n",
      "\n",
      "Trial 21, Horizon h=1, Fold 1: RMSE=1.8158, R²=0.8281\n",
      "Trial 21, Horizon h=1, Fold 2: RMSE=1.8191, R²=0.8522\n",
      "Trial 21, Horizon h=1, Fold 3: RMSE=1.6555, R²=0.8928\n",
      "Trial 21, Horizon h=1, Fold 4: RMSE=1.6749, R²=0.9008\n",
      "Trial 21, Horizon h=2, Fold 1: RMSE=2.2213, R²=0.7427\n",
      "Trial 21, Horizon h=2, Fold 2: RMSE=2.4397, R²=0.7333\n",
      "Trial 21, Horizon h=2, Fold 3: RMSE=2.2441, R²=0.8036\n",
      "Trial 21, Horizon h=2, Fold 4: RMSE=2.2589, R²=0.8199\n",
      "Trial 21, Horizon h=3, Fold 1: RMSE=2.3577, R²=0.7103\n",
      "Trial 21, Horizon h=3, Fold 2: RMSE=2.6785, R²=0.6775\n",
      "Trial 21, Horizon h=3, Fold 3: RMSE=2.5437, R²=0.7476\n",
      "Trial 21, Horizon h=3, Fold 4: RMSE=2.4766, R²=0.7836\n",
      "Trial 21, Horizon h=4, Fold 1: RMSE=2.3961, R²=0.7010\n",
      "Trial 21, Horizon h=4, Fold 2: RMSE=2.7291, R²=0.6642\n",
      "Trial 21, Horizon h=4, Fold 3: RMSE=2.6133, R²=0.7338\n",
      "Trial 21, Horizon h=4, Fold 4: RMSE=2.5647, R²=0.7679\n",
      "Trial 21, Horizon h=5, Fold 1: RMSE=2.4418, R²=0.6898\n",
      "Trial 21, Horizon h=5, Fold 2: RMSE=2.7541, R²=0.6575\n",
      "Trial 21, Horizon h=5, Fold 3: RMSE=2.6797, R²=0.7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:14:36,972] Trial 21 finished with value: 2.3485214766338536 and parameters: {'learning_rate': 0.0189207443130906, 'max_depth': 3, 'gamma': 0.5301023607905218, 'reg_lambda': 6.830456450814253, 'reg_alpha': 1.0674129296804193, 'subsample': 0.7120648620533019, 'colsample_bytree': 0.6889585810366631, 'min_child_weight': 4}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21, Horizon h=5, Fold 4: RMSE=2.6058, R²=0.7608\n",
      "Trial 21 finished, overall mean RMSE across horizons=2.3485\n",
      "\n",
      "Trial 22, Horizon h=1, Fold 1: RMSE=1.8028, R²=0.8306\n",
      "Trial 22, Horizon h=1, Fold 2: RMSE=1.7955, R²=0.8560\n",
      "Trial 22, Horizon h=1, Fold 3: RMSE=1.6539, R²=0.8930\n",
      "Trial 22, Horizon h=1, Fold 4: RMSE=1.6627, R²=0.9022\n",
      "Trial 22, Horizon h=2, Fold 1: RMSE=2.2165, R²=0.7438\n",
      "Trial 22, Horizon h=2, Fold 2: RMSE=2.4180, R²=0.7380\n",
      "Trial 22, Horizon h=2, Fold 3: RMSE=2.2655, R²=0.7998\n",
      "Trial 22, Horizon h=2, Fold 4: RMSE=2.2579, R²=0.8201\n",
      "Trial 22, Horizon h=3, Fold 1: RMSE=2.3745, R²=0.7062\n",
      "Trial 22, Horizon h=3, Fold 2: RMSE=2.6425, R²=0.6861\n",
      "Trial 22, Horizon h=3, Fold 3: RMSE=2.5376, R²=0.7488\n",
      "Trial 22, Horizon h=3, Fold 4: RMSE=2.4739, R²=0.7841\n",
      "Trial 22, Horizon h=4, Fold 1: RMSE=2.3960, R²=0.7010\n",
      "Trial 22, Horizon h=4, Fold 2: RMSE=2.7161, R²=0.6674\n",
      "Trial 22, Horizon h=4, Fold 3: RMSE=2.5906, R²=0.7384\n",
      "Trial 22, Horizon h=4, Fold 4: RMSE=2.5709, R²=0.7668\n",
      "Trial 22, Horizon h=5, Fold 1: RMSE=2.5072, R²=0.6730\n",
      "Trial 22, Horizon h=5, Fold 2: RMSE=2.7596, R²=0.6561\n",
      "Trial 22, Horizon h=5, Fold 3: RMSE=2.6439, R²=0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:14:52,697] Trial 22 finished with value: 2.3450279475567433 and parameters: {'learning_rate': 0.023616629662368417, 'max_depth': 3, 'gamma': 0.7047426712991178, 'reg_lambda': 6.185374810541055, 'reg_alpha': 0.9571538020372952, 'subsample': 0.5639800290546623, 'colsample_bytree': 0.621024172638301, 'min_child_weight': 4}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22, Horizon h=5, Fold 4: RMSE=2.6148, R²=0.7592\n",
      "Trial 22 finished, overall mean RMSE across horizons=2.3450\n",
      "\n",
      "Trial 23, Horizon h=1, Fold 1: RMSE=1.7450, R²=0.8413\n",
      "Trial 23, Horizon h=1, Fold 2: RMSE=1.7934, R²=0.8564\n",
      "Trial 23, Horizon h=1, Fold 3: RMSE=1.6592, R²=0.8923\n",
      "Trial 23, Horizon h=1, Fold 4: RMSE=1.6822, R²=0.8999\n",
      "Trial 23, Horizon h=2, Fold 1: RMSE=2.2012, R²=0.7473\n",
      "Trial 23, Horizon h=2, Fold 2: RMSE=2.4223, R²=0.7371\n",
      "Trial 23, Horizon h=2, Fold 3: RMSE=2.2716, R²=0.7988\n",
      "Trial 23, Horizon h=2, Fold 4: RMSE=2.2473, R²=0.8218\n",
      "Trial 23, Horizon h=3, Fold 1: RMSE=2.3724, R²=0.7067\n",
      "Trial 23, Horizon h=3, Fold 2: RMSE=2.6579, R²=0.6824\n",
      "Trial 23, Horizon h=3, Fold 3: RMSE=2.5361, R²=0.7491\n",
      "Trial 23, Horizon h=3, Fold 4: RMSE=2.4906, R²=0.7811\n",
      "Trial 23, Horizon h=4, Fold 1: RMSE=2.3860, R²=0.7035\n",
      "Trial 23, Horizon h=4, Fold 2: RMSE=2.7178, R²=0.6670\n",
      "Trial 23, Horizon h=4, Fold 3: RMSE=2.5862, R²=0.7393\n",
      "Trial 23, Horizon h=4, Fold 4: RMSE=2.5717, R²=0.7667\n",
      "Trial 23, Horizon h=5, Fold 1: RMSE=2.4951, R²=0.6761\n",
      "Trial 23, Horizon h=5, Fold 2: RMSE=2.7508, R²=0.6583\n",
      "Trial 23, Horizon h=5, Fold 3: RMSE=2.6431, R²=0.7277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:15:07,652] Trial 23 finished with value: 2.3423600442517287 and parameters: {'learning_rate': 0.025161467292669517, 'max_depth': 3, 'gamma': 0.735636906057141, 'reg_lambda': 6.159437497619372, 'reg_alpha': 3.184261557248126, 'subsample': 0.5488047364656807, 'colsample_bytree': 0.6197207633354314, 'min_child_weight': 3}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23, Horizon h=5, Fold 4: RMSE=2.6174, R²=0.7587\n",
      "Trial 23 finished, overall mean RMSE across horizons=2.3424\n",
      "\n",
      "Trial 24, Horizon h=1, Fold 1: RMSE=1.7672, R²=0.8372\n",
      "Trial 24, Horizon h=1, Fold 2: RMSE=1.8421, R²=0.8485\n",
      "Trial 24, Horizon h=1, Fold 3: RMSE=1.6307, R²=0.8960\n",
      "Trial 24, Horizon h=1, Fold 4: RMSE=1.7325, R²=0.8938\n",
      "Trial 24, Horizon h=2, Fold 1: RMSE=2.2210, R²=0.7427\n",
      "Trial 24, Horizon h=2, Fold 2: RMSE=2.4676, R²=0.7272\n",
      "Trial 24, Horizon h=2, Fold 3: RMSE=2.2937, R²=0.7948\n",
      "Trial 24, Horizon h=2, Fold 4: RMSE=2.2780, R²=0.8169\n",
      "Trial 24, Horizon h=3, Fold 1: RMSE=2.3576, R²=0.7103\n",
      "Trial 24, Horizon h=3, Fold 2: RMSE=2.6724, R²=0.6789\n",
      "Trial 24, Horizon h=3, Fold 3: RMSE=2.5236, R²=0.7516\n",
      "Trial 24, Horizon h=3, Fold 4: RMSE=2.5295, R²=0.7742\n",
      "Trial 24, Horizon h=4, Fold 1: RMSE=2.3800, R²=0.7050\n",
      "Trial 24, Horizon h=4, Fold 2: RMSE=2.7495, R²=0.6592\n",
      "Trial 24, Horizon h=4, Fold 3: RMSE=2.5134, R²=0.7538\n",
      "Trial 24, Horizon h=4, Fold 4: RMSE=2.5377, R²=0.7728\n",
      "Trial 24, Horizon h=5, Fold 1: RMSE=2.4568, R²=0.6860\n",
      "Trial 24, Horizon h=5, Fold 2: RMSE=2.7839, R²=0.6501\n",
      "Trial 24, Horizon h=5, Fold 3: RMSE=2.6610, R²=0.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:15:16,953] Trial 24 finished with value: 2.3495371644968555 and parameters: {'learning_rate': 0.0677772092010409, 'max_depth': 3, 'gamma': 0.9192162238905277, 'reg_lambda': 5.2752869069524575, 'reg_alpha': 3.223633952266596, 'subsample': 0.5556325877139441, 'colsample_bytree': 0.5018755550883919, 'min_child_weight': 3}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24, Horizon h=5, Fold 4: RMSE=2.5925, R²=0.7632\n",
      "Trial 24 finished, overall mean RMSE across horizons=2.3495\n",
      "\n",
      "Trial 25, Horizon h=1, Fold 1: RMSE=1.7747, R²=0.8358\n",
      "Trial 25, Horizon h=1, Fold 2: RMSE=1.8289, R²=0.8506\n",
      "Trial 25, Horizon h=1, Fold 3: RMSE=1.6856, R²=0.8889\n",
      "Trial 25, Horizon h=1, Fold 4: RMSE=1.7216, R²=0.8952\n",
      "Trial 25, Horizon h=2, Fold 1: RMSE=2.2149, R²=0.7442\n",
      "Trial 25, Horizon h=2, Fold 2: RMSE=2.4766, R²=0.7252\n",
      "Trial 25, Horizon h=2, Fold 3: RMSE=2.2954, R²=0.7945\n",
      "Trial 25, Horizon h=2, Fold 4: RMSE=2.2700, R²=0.8182\n",
      "Trial 25, Horizon h=3, Fold 1: RMSE=2.4193, R²=0.6950\n",
      "Trial 25, Horizon h=3, Fold 2: RMSE=2.7205, R²=0.6673\n",
      "Trial 25, Horizon h=3, Fold 3: RMSE=2.5715, R²=0.7420\n",
      "Trial 25, Horizon h=3, Fold 4: RMSE=2.4770, R²=0.7835\n",
      "Trial 25, Horizon h=4, Fold 1: RMSE=2.4383, R²=0.6904\n",
      "Trial 25, Horizon h=4, Fold 2: RMSE=2.7705, R²=0.6539\n",
      "Trial 25, Horizon h=4, Fold 3: RMSE=2.6488, R²=0.7265\n",
      "Trial 25, Horizon h=4, Fold 4: RMSE=2.6247, R²=0.7569\n",
      "Trial 25, Horizon h=5, Fold 1: RMSE=2.5195, R²=0.6698\n",
      "Trial 25, Horizon h=5, Fold 2: RMSE=2.7786, R²=0.6514\n",
      "Trial 25, Horizon h=5, Fold 3: RMSE=2.6828, R²=0.7194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:15:31,261] Trial 25 finished with value: 2.3777370140394742 and parameters: {'learning_rate': 0.03902102964555272, 'max_depth': 4, 'gamma': 0.8065507737142857, 'reg_lambda': 1.6303577862108938, 'reg_alpha': 6.124203349901622, 'subsample': 0.6294936608223454, 'colsample_bytree': 0.5699232134889385, 'min_child_weight': 3}. Best is trial 17 with value: 2.340564275129548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25, Horizon h=5, Fold 4: RMSE=2.6354, R²=0.7554\n",
      "Trial 25 finished, overall mean RMSE across horizons=2.3777\n",
      "\n",
      "Trial 26, Horizon h=1, Fold 1: RMSE=1.7499, R²=0.8404\n",
      "Trial 26, Horizon h=1, Fold 2: RMSE=1.7785, R²=0.8588\n",
      "Trial 26, Horizon h=1, Fold 3: RMSE=1.6551, R²=0.8928\n",
      "Trial 26, Horizon h=1, Fold 4: RMSE=1.6715, R²=0.9012\n",
      "Trial 26, Horizon h=2, Fold 1: RMSE=2.1771, R²=0.7528\n",
      "Trial 26, Horizon h=2, Fold 2: RMSE=2.3993, R²=0.7421\n",
      "Trial 26, Horizon h=2, Fold 3: RMSE=2.2595, R²=0.8009\n",
      "Trial 26, Horizon h=2, Fold 4: RMSE=2.2408, R²=0.8228\n",
      "Trial 26, Horizon h=3, Fold 1: RMSE=2.3304, R²=0.7170\n",
      "Trial 26, Horizon h=3, Fold 2: RMSE=2.6325, R²=0.6884\n",
      "Trial 26, Horizon h=3, Fold 3: RMSE=2.5362, R²=0.7491\n",
      "Trial 26, Horizon h=3, Fold 4: RMSE=2.4791, R²=0.7831\n",
      "Trial 26, Horizon h=4, Fold 1: RMSE=2.3908, R²=0.7023\n",
      "Trial 26, Horizon h=4, Fold 2: RMSE=2.7152, R²=0.6676\n",
      "Trial 26, Horizon h=4, Fold 3: RMSE=2.6190, R²=0.7327\n",
      "Trial 26, Horizon h=4, Fold 4: RMSE=2.6149, R²=0.7588\n",
      "Trial 26, Horizon h=5, Fold 1: RMSE=2.4439, R²=0.6893\n",
      "Trial 26, Horizon h=5, Fold 2: RMSE=2.7627, R²=0.6554\n",
      "Trial 26, Horizon h=5, Fold 3: RMSE=2.6592, R²=0.7243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:15:52,870] Trial 26 finished with value: 2.3367909777824063 and parameters: {'learning_rate': 0.013783404127075918, 'max_depth': 3, 'gamma': 0.7205016345160069, 'reg_lambda': 7.7231433960665745, 'reg_alpha': 3.7803360016028194, 'subsample': 0.5573010414689298, 'colsample_bytree': 0.6250767010370445, 'min_child_weight': 3}. Best is trial 26 with value: 2.3367909777824063.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26, Horizon h=5, Fold 4: RMSE=2.6203, R²=0.7581\n",
      "Trial 26 finished, overall mean RMSE across horizons=2.3368\n",
      "\n",
      "Trial 27, Horizon h=1, Fold 1: RMSE=1.7399, R²=0.8422\n",
      "Trial 27, Horizon h=1, Fold 2: RMSE=1.8378, R²=0.8492\n",
      "Trial 27, Horizon h=1, Fold 3: RMSE=1.7205, R²=0.8842\n",
      "Trial 27, Horizon h=1, Fold 4: RMSE=1.7720, R²=0.8889\n",
      "Trial 27, Horizon h=2, Fold 1: RMSE=2.2229, R²=0.7423\n",
      "Trial 27, Horizon h=2, Fold 2: RMSE=2.4207, R²=0.7375\n",
      "Trial 27, Horizon h=2, Fold 3: RMSE=2.3271, R²=0.7888\n",
      "Trial 27, Horizon h=2, Fold 4: RMSE=2.3126, R²=0.8113\n",
      "Trial 27, Horizon h=3, Fold 1: RMSE=2.3537, R²=0.7113\n",
      "Trial 27, Horizon h=3, Fold 2: RMSE=2.6804, R²=0.6770\n",
      "Trial 27, Horizon h=3, Fold 3: RMSE=2.5673, R²=0.7429\n",
      "Trial 27, Horizon h=3, Fold 4: RMSE=2.5469, R²=0.7711\n",
      "Trial 27, Horizon h=4, Fold 1: RMSE=2.4196, R²=0.6951\n",
      "Trial 27, Horizon h=4, Fold 2: RMSE=2.7028, R²=0.6706\n",
      "Trial 27, Horizon h=4, Fold 3: RMSE=2.6366, R²=0.7291\n",
      "Trial 27, Horizon h=4, Fold 4: RMSE=2.6290, R²=0.7562\n",
      "Trial 27, Horizon h=5, Fold 1: RMSE=2.4673, R²=0.6833\n",
      "Trial 27, Horizon h=5, Fold 2: RMSE=2.7119, R²=0.6679\n",
      "Trial 27, Horizon h=5, Fold 3: RMSE=2.6784, R²=0.7204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:16:11,640] Trial 27 finished with value: 2.3706111915534986 and parameters: {'learning_rate': 0.024127369384928196, 'max_depth': 4, 'gamma': 0.7213346107534114, 'reg_lambda': 7.540104648394575, 'reg_alpha': 7.923122474694366, 'subsample': 0.5018210657946788, 'colsample_bytree': 0.6246802225660741, 'min_child_weight': 6}. Best is trial 26 with value: 2.3367909777824063.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27, Horizon h=5, Fold 4: RMSE=2.6650, R²=0.7498\n",
      "Trial 27 finished, overall mean RMSE across horizons=2.3706\n",
      "\n",
      "Trial 28, Horizon h=1, Fold 1: RMSE=1.7776, R²=0.8353\n",
      "Trial 28, Horizon h=1, Fold 2: RMSE=1.7997, R²=0.8554\n",
      "Trial 28, Horizon h=1, Fold 3: RMSE=1.6511, R²=0.8934\n",
      "Trial 28, Horizon h=1, Fold 4: RMSE=1.6605, R²=0.9025\n",
      "Trial 28, Horizon h=2, Fold 1: RMSE=2.1911, R²=0.7496\n",
      "Trial 28, Horizon h=2, Fold 2: RMSE=2.4026, R²=0.7414\n",
      "Trial 28, Horizon h=2, Fold 3: RMSE=2.2576, R²=0.8012\n",
      "Trial 28, Horizon h=2, Fold 4: RMSE=2.2413, R²=0.8227\n",
      "Trial 28, Horizon h=3, Fold 1: RMSE=2.3678, R²=0.7078\n",
      "Trial 28, Horizon h=3, Fold 2: RMSE=2.6331, R²=0.6883\n",
      "Trial 28, Horizon h=3, Fold 3: RMSE=2.5240, R²=0.7515\n",
      "Trial 28, Horizon h=3, Fold 4: RMSE=2.5031, R²=0.7789\n",
      "Trial 28, Horizon h=4, Fold 1: RMSE=2.4146, R²=0.6964\n",
      "Trial 28, Horizon h=4, Fold 2: RMSE=2.7220, R²=0.6659\n",
      "Trial 28, Horizon h=4, Fold 3: RMSE=2.5746, R²=0.7416\n",
      "Trial 28, Horizon h=4, Fold 4: RMSE=2.5915, R²=0.7631\n",
      "Trial 28, Horizon h=5, Fold 1: RMSE=2.4301, R²=0.6928\n",
      "Trial 28, Horizon h=5, Fold 2: RMSE=2.7644, R²=0.6549\n",
      "Trial 28, Horizon h=5, Fold 3: RMSE=2.6571, R²=0.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:16:30,282] Trial 28 finished with value: 2.338946637657804 and parameters: {'learning_rate': 0.015023419924556887, 'max_depth': 3, 'gamma': 0.8719965359926763, 'reg_lambda': 5.927219955210958, 'reg_alpha': 3.935039475893947, 'subsample': 0.5499025459002267, 'colsample_bytree': 0.5594724753336435, 'min_child_weight': 10}. Best is trial 26 with value: 2.3367909777824063.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28, Horizon h=5, Fold 4: RMSE=2.6151, R²=0.7591\n",
      "Trial 28 finished, overall mean RMSE across horizons=2.3389\n",
      "\n",
      "Trial 29, Horizon h=1, Fold 1: RMSE=1.7663, R²=0.8374\n",
      "Trial 29, Horizon h=1, Fold 2: RMSE=1.8375, R²=0.8492\n",
      "Trial 29, Horizon h=1, Fold 3: RMSE=1.6407, R²=0.8947\n",
      "Trial 29, Horizon h=1, Fold 4: RMSE=1.6750, R²=0.9008\n",
      "Trial 29, Horizon h=2, Fold 1: RMSE=2.1985, R²=0.7479\n",
      "Trial 29, Horizon h=2, Fold 2: RMSE=2.4081, R²=0.7402\n",
      "Trial 29, Horizon h=2, Fold 3: RMSE=2.2404, R²=0.8042\n",
      "Trial 29, Horizon h=2, Fold 4: RMSE=2.2477, R²=0.8217\n",
      "Trial 29, Horizon h=3, Fold 1: RMSE=2.3519, R²=0.7117\n",
      "Trial 29, Horizon h=3, Fold 2: RMSE=2.6298, R²=0.6891\n",
      "Trial 29, Horizon h=3, Fold 3: RMSE=2.5075, R²=0.7547\n",
      "Trial 29, Horizon h=3, Fold 4: RMSE=2.4760, R²=0.7837\n",
      "Trial 29, Horizon h=4, Fold 1: RMSE=2.3796, R²=0.7051\n",
      "Trial 29, Horizon h=4, Fold 2: RMSE=2.6978, R²=0.6718\n",
      "Trial 29, Horizon h=4, Fold 3: RMSE=2.5892, R²=0.7387\n",
      "Trial 29, Horizon h=4, Fold 4: RMSE=2.5689, R²=0.7672\n",
      "Trial 29, Horizon h=5, Fold 1: RMSE=2.4449, R²=0.6890\n",
      "Trial 29, Horizon h=5, Fold 2: RMSE=2.7451, R²=0.6597\n",
      "Trial 29, Horizon h=5, Fold 3: RMSE=2.6600, R²=0.7242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:16:51,262] Trial 29 finished with value: 2.3319131955655927 and parameters: {'learning_rate': 0.013158783038213525, 'max_depth': 3, 'gamma': 0.868262226798729, 'reg_lambda': 7.4732313319971375, 'reg_alpha': 3.8412920897821343, 'subsample': 0.6288205070343449, 'colsample_bytree': 0.5496680113609117, 'min_child_weight': 10}. Best is trial 29 with value: 2.3319131955655927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29, Horizon h=5, Fold 4: RMSE=2.5734, R²=0.7667\n",
      "Trial 29 finished, overall mean RMSE across horizons=2.3319\n",
      "\n",
      "Trial 30, Horizon h=1, Fold 1: RMSE=1.7767, R²=0.8354\n",
      "Trial 30, Horizon h=1, Fold 2: RMSE=1.8000, R²=0.8553\n",
      "Trial 30, Horizon h=1, Fold 3: RMSE=1.6840, R²=0.8891\n",
      "Trial 30, Horizon h=1, Fold 4: RMSE=1.7322, R²=0.8939\n",
      "Trial 30, Horizon h=2, Fold 1: RMSE=2.1905, R²=0.7498\n",
      "Trial 30, Horizon h=2, Fold 2: RMSE=2.3914, R²=0.7438\n",
      "Trial 30, Horizon h=2, Fold 3: RMSE=2.3234, R²=0.7895\n",
      "Trial 30, Horizon h=2, Fold 4: RMSE=2.2942, R²=0.8142\n",
      "Trial 30, Horizon h=3, Fold 1: RMSE=2.3854, R²=0.7035\n",
      "Trial 30, Horizon h=3, Fold 2: RMSE=2.6381, R²=0.6871\n",
      "Trial 30, Horizon h=3, Fold 3: RMSE=2.5696, R²=0.7424\n",
      "Trial 30, Horizon h=3, Fold 4: RMSE=2.5524, R²=0.7701\n",
      "Trial 30, Horizon h=4, Fold 1: RMSE=2.4088, R²=0.6978\n",
      "Trial 30, Horizon h=4, Fold 2: RMSE=2.7045, R²=0.6702\n",
      "Trial 30, Horizon h=4, Fold 3: RMSE=2.6423, R²=0.7279\n",
      "Trial 30, Horizon h=4, Fold 4: RMSE=2.6578, R²=0.7508\n",
      "Trial 30, Horizon h=5, Fold 1: RMSE=2.4679, R²=0.6832\n",
      "Trial 30, Horizon h=5, Fold 2: RMSE=2.7501, R²=0.6585\n",
      "Trial 30, Horizon h=5, Fold 3: RMSE=2.6913, R²=0.7176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:17:20,897] Trial 30 finished with value: 2.369630934074157 and parameters: {'learning_rate': 0.014397087791508677, 'max_depth': 5, 'gamma': 0.8901703881128019, 'reg_lambda': 7.659009681769723, 'reg_alpha': 5.774485683769681, 'subsample': 0.5498582169323096, 'colsample_bytree': 0.5421517798173532, 'min_child_weight': 10}. Best is trial 29 with value: 2.3319131955655927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30, Horizon h=5, Fold 4: RMSE=2.7319, R²=0.7371\n",
      "Trial 30 finished, overall mean RMSE across horizons=2.3696\n",
      "\n",
      "Trial 31, Horizon h=1, Fold 1: RMSE=1.8074, R²=0.8297\n",
      "Trial 31, Horizon h=1, Fold 2: RMSE=1.8205, R²=0.8520\n",
      "Trial 31, Horizon h=1, Fold 3: RMSE=1.6385, R²=0.8950\n",
      "Trial 31, Horizon h=1, Fold 4: RMSE=1.6922, R²=0.8987\n",
      "Trial 31, Horizon h=2, Fold 1: RMSE=2.1954, R²=0.7486\n",
      "Trial 31, Horizon h=2, Fold 2: RMSE=2.3990, R²=0.7422\n",
      "Trial 31, Horizon h=2, Fold 3: RMSE=2.2511, R²=0.8024\n",
      "Trial 31, Horizon h=2, Fold 4: RMSE=2.2453, R²=0.8221\n",
      "Trial 31, Horizon h=3, Fold 1: RMSE=2.3689, R²=0.7076\n",
      "Trial 31, Horizon h=3, Fold 2: RMSE=2.6226, R²=0.6908\n",
      "Trial 31, Horizon h=3, Fold 3: RMSE=2.5341, R²=0.7495\n",
      "Trial 31, Horizon h=3, Fold 4: RMSE=2.4852, R²=0.7821\n",
      "Trial 31, Horizon h=4, Fold 1: RMSE=2.3953, R²=0.7012\n",
      "Trial 31, Horizon h=4, Fold 2: RMSE=2.7245, R²=0.6653\n",
      "Trial 31, Horizon h=4, Fold 3: RMSE=2.5831, R²=0.7399\n",
      "Trial 31, Horizon h=4, Fold 4: RMSE=2.5548, R²=0.7697\n",
      "Trial 31, Horizon h=5, Fold 1: RMSE=2.4169, R²=0.6961\n",
      "Trial 31, Horizon h=5, Fold 2: RMSE=2.7357, R²=0.6620\n",
      "Trial 31, Horizon h=5, Fold 3: RMSE=2.6467, R²=0.7269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:17:41,040] Trial 31 finished with value: 2.334730574306741 and parameters: {'learning_rate': 0.014667505352511583, 'max_depth': 3, 'gamma': 0.9948569875701172, 'reg_lambda': 7.127768245005379, 'reg_alpha': 3.704786690944226, 'subsample': 0.6216618746218274, 'colsample_bytree': 0.555968134039718, 'min_child_weight': 9}. Best is trial 29 with value: 2.3319131955655927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31, Horizon h=5, Fold 4: RMSE=2.5776, R²=0.7660\n",
      "Trial 31 finished, overall mean RMSE across horizons=2.3347\n",
      "\n",
      "Trial 32, Horizon h=1, Fold 1: RMSE=1.7881, R²=0.8333\n",
      "Trial 32, Horizon h=1, Fold 2: RMSE=1.8332, R²=0.8499\n",
      "Trial 32, Horizon h=1, Fold 3: RMSE=1.6406, R²=0.8947\n",
      "Trial 32, Horizon h=1, Fold 4: RMSE=1.6743, R²=0.9008\n",
      "Trial 32, Horizon h=2, Fold 1: RMSE=2.2035, R²=0.7468\n",
      "Trial 32, Horizon h=2, Fold 2: RMSE=2.4093, R²=0.7399\n",
      "Trial 32, Horizon h=2, Fold 3: RMSE=2.2445, R²=0.8035\n",
      "Trial 32, Horizon h=2, Fold 4: RMSE=2.2522, R²=0.8210\n",
      "Trial 32, Horizon h=3, Fold 1: RMSE=2.3699, R²=0.7073\n",
      "Trial 32, Horizon h=3, Fold 2: RMSE=2.6210, R²=0.6911\n",
      "Trial 32, Horizon h=3, Fold 3: RMSE=2.5211, R²=0.7520\n",
      "Trial 32, Horizon h=3, Fold 4: RMSE=2.4806, R²=0.7829\n",
      "Trial 32, Horizon h=4, Fold 1: RMSE=2.3827, R²=0.7043\n",
      "Trial 32, Horizon h=4, Fold 2: RMSE=2.7126, R²=0.6682\n",
      "Trial 32, Horizon h=4, Fold 3: RMSE=2.5981, R²=0.7369\n",
      "Trial 32, Horizon h=4, Fold 4: RMSE=2.5581, R²=0.7691\n",
      "Trial 32, Horizon h=5, Fold 1: RMSE=2.4458, R²=0.6888\n",
      "Trial 32, Horizon h=5, Fold 2: RMSE=2.7342, R²=0.6624\n",
      "Trial 32, Horizon h=5, Fold 3: RMSE=2.6496, R²=0.7263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:18:01,180] Trial 32 finished with value: 2.3347555980664176 and parameters: {'learning_rate': 0.014255710747822855, 'max_depth': 3, 'gamma': 0.8715538887809505, 'reg_lambda': 7.409449251393019, 'reg_alpha': 3.871611622858085, 'subsample': 0.6295640724223066, 'colsample_bytree': 0.5497826742970624, 'min_child_weight': 9}. Best is trial 29 with value: 2.3319131955655927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32, Horizon h=5, Fold 4: RMSE=2.5755, R²=0.7663\n",
      "Trial 32 finished, overall mean RMSE across horizons=2.3348\n",
      "\n",
      "Trial 33, Horizon h=1, Fold 1: RMSE=1.7819, R²=0.8345\n",
      "Trial 33, Horizon h=1, Fold 2: RMSE=1.8335, R²=0.8499\n",
      "Trial 33, Horizon h=1, Fold 3: RMSE=1.6392, R²=0.8949\n",
      "Trial 33, Horizon h=1, Fold 4: RMSE=1.6796, R²=0.9002\n",
      "Trial 33, Horizon h=2, Fold 1: RMSE=2.2046, R²=0.7465\n",
      "Trial 33, Horizon h=2, Fold 2: RMSE=2.4075, R²=0.7403\n",
      "Trial 33, Horizon h=2, Fold 3: RMSE=2.2537, R²=0.8019\n",
      "Trial 33, Horizon h=2, Fold 4: RMSE=2.2505, R²=0.8213\n",
      "Trial 33, Horizon h=3, Fold 1: RMSE=2.3560, R²=0.7107\n",
      "Trial 33, Horizon h=3, Fold 2: RMSE=2.6393, R²=0.6868\n",
      "Trial 33, Horizon h=3, Fold 3: RMSE=2.5050, R²=0.7552\n",
      "Trial 33, Horizon h=3, Fold 4: RMSE=2.4744, R²=0.7840\n",
      "Trial 33, Horizon h=4, Fold 1: RMSE=2.3682, R²=0.7079\n",
      "Trial 33, Horizon h=4, Fold 2: RMSE=2.7103, R²=0.6688\n",
      "Trial 33, Horizon h=4, Fold 3: RMSE=2.6007, R²=0.7364\n",
      "Trial 33, Horizon h=4, Fold 4: RMSE=2.5560, R²=0.7695\n",
      "Trial 33, Horizon h=5, Fold 1: RMSE=2.4322, R²=0.6923\n",
      "Trial 33, Horizon h=5, Fold 2: RMSE=2.7417, R²=0.6606\n",
      "Trial 33, Horizon h=5, Fold 3: RMSE=2.6432, R²=0.7277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:18:22,109] Trial 33 finished with value: 2.334062024689127 and parameters: {'learning_rate': 0.012462545019907408, 'max_depth': 3, 'gamma': 0.9995589902007882, 'reg_lambda': 7.357063685621883, 'reg_alpha': 3.7984599066393785, 'subsample': 0.6299355768542105, 'colsample_bytree': 0.5096813769016831, 'min_child_weight': 9}. Best is trial 29 with value: 2.3319131955655927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33, Horizon h=5, Fold 4: RMSE=2.6037, R²=0.7612\n",
      "Trial 33 finished, overall mean RMSE across horizons=2.3341\n",
      "\n",
      "Trial 34, Horizon h=1, Fold 1: RMSE=1.8080, R²=0.8296\n",
      "Trial 34, Horizon h=1, Fold 2: RMSE=1.8105, R²=0.8536\n",
      "Trial 34, Horizon h=1, Fold 3: RMSE=1.6042, R²=0.8993\n",
      "Trial 34, Horizon h=1, Fold 4: RMSE=1.6845, R²=0.8996\n",
      "Trial 34, Horizon h=2, Fold 1: RMSE=2.2054, R²=0.7463\n",
      "Trial 34, Horizon h=2, Fold 2: RMSE=2.4011, R²=0.7417\n",
      "Trial 34, Horizon h=2, Fold 3: RMSE=2.2197, R²=0.8078\n",
      "Trial 34, Horizon h=2, Fold 4: RMSE=2.2658, R²=0.8188\n",
      "Trial 34, Horizon h=3, Fold 1: RMSE=2.3744, R²=0.7062\n",
      "Trial 34, Horizon h=3, Fold 2: RMSE=2.6185, R²=0.6917\n",
      "Trial 34, Horizon h=3, Fold 3: RMSE=2.5066, R²=0.7549\n",
      "Trial 34, Horizon h=3, Fold 4: RMSE=2.4899, R²=0.7813\n",
      "Trial 34, Horizon h=4, Fold 1: RMSE=2.3671, R²=0.7082\n",
      "Trial 34, Horizon h=4, Fold 2: RMSE=2.7052, R²=0.6700\n",
      "Trial 34, Horizon h=4, Fold 3: RMSE=2.5822, R²=0.7401\n",
      "Trial 34, Horizon h=4, Fold 4: RMSE=2.5988, R²=0.7617\n",
      "Trial 34, Horizon h=5, Fold 1: RMSE=2.4265, R²=0.6937\n",
      "Trial 34, Horizon h=5, Fold 2: RMSE=2.7533, R²=0.6577\n",
      "Trial 34, Horizon h=5, Fold 3: RMSE=2.5964, R²=0.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:18:37,597] Trial 34 finished with value: 2.3312497613741066 and parameters: {'learning_rate': 0.02072073624900749, 'max_depth': 3, 'gamma': 0.9445603499857984, 'reg_lambda': 7.157018926431709, 'reg_alpha': 4.852922737991103, 'subsample': 0.6265138818932218, 'colsample_bytree': 0.502309793563544, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34, Horizon h=5, Fold 4: RMSE=2.6068, R²=0.7606\n",
      "Trial 34 finished, overall mean RMSE across horizons=2.3312\n",
      "\n",
      "Trial 35, Horizon h=1, Fold 1: RMSE=1.8045, R²=0.8302\n",
      "Trial 35, Horizon h=1, Fold 2: RMSE=1.8103, R²=0.8537\n",
      "Trial 35, Horizon h=1, Fold 3: RMSE=1.6294, R²=0.8961\n",
      "Trial 35, Horizon h=1, Fold 4: RMSE=1.6980, R²=0.8980\n",
      "Trial 35, Horizon h=2, Fold 1: RMSE=2.2099, R²=0.7453\n",
      "Trial 35, Horizon h=2, Fold 2: RMSE=2.3884, R²=0.7444\n",
      "Trial 35, Horizon h=2, Fold 3: RMSE=2.2288, R²=0.8063\n",
      "Trial 35, Horizon h=2, Fold 4: RMSE=2.2817, R²=0.8163\n",
      "Trial 35, Horizon h=3, Fold 1: RMSE=2.3774, R²=0.7055\n",
      "Trial 35, Horizon h=3, Fold 2: RMSE=2.6402, R²=0.6866\n",
      "Trial 35, Horizon h=3, Fold 3: RMSE=2.5070, R²=0.7548\n",
      "Trial 35, Horizon h=3, Fold 4: RMSE=2.4998, R²=0.7795\n",
      "Trial 35, Horizon h=4, Fold 1: RMSE=2.3715, R²=0.7071\n",
      "Trial 35, Horizon h=4, Fold 2: RMSE=2.7317, R²=0.6636\n",
      "Trial 35, Horizon h=4, Fold 3: RMSE=2.5895, R²=0.7387\n",
      "Trial 35, Horizon h=4, Fold 4: RMSE=2.5618, R²=0.7685\n",
      "Trial 35, Horizon h=5, Fold 1: RMSE=2.4389, R²=0.6906\n",
      "Trial 35, Horizon h=5, Fold 2: RMSE=2.7786, R²=0.6514\n",
      "Trial 35, Horizon h=5, Fold 3: RMSE=2.6256, R²=0.7313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:18:53,021] Trial 35 finished with value: 2.338543853165384 and parameters: {'learning_rate': 0.020872071834972774, 'max_depth': 3, 'gamma': 0.9439013294664123, 'reg_lambda': 7.083855767977637, 'reg_alpha': 5.158696326726617, 'subsample': 0.7011080563222968, 'colsample_bytree': 0.5009165532022887, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35, Horizon h=5, Fold 4: RMSE=2.5981, R²=0.7622\n",
      "Trial 35 finished, overall mean RMSE across horizons=2.3385\n",
      "\n",
      "Trial 36, Horizon h=1, Fold 1: RMSE=1.8062, R²=0.8299\n",
      "Trial 36, Horizon h=1, Fold 2: RMSE=1.8440, R²=0.8482\n",
      "Trial 36, Horizon h=1, Fold 3: RMSE=1.6726, R²=0.8906\n",
      "Trial 36, Horizon h=1, Fold 4: RMSE=1.7343, R²=0.8936\n",
      "Trial 36, Horizon h=2, Fold 1: RMSE=2.2268, R²=0.7414\n",
      "Trial 36, Horizon h=2, Fold 2: RMSE=2.4129, R²=0.7391\n",
      "Trial 36, Horizon h=2, Fold 3: RMSE=2.2886, R²=0.7957\n",
      "Trial 36, Horizon h=2, Fold 4: RMSE=2.2935, R²=0.8144\n",
      "Trial 36, Horizon h=3, Fold 1: RMSE=2.3879, R²=0.7028\n",
      "Trial 36, Horizon h=3, Fold 2: RMSE=2.6655, R²=0.6806\n",
      "Trial 36, Horizon h=3, Fold 3: RMSE=2.5452, R²=0.7473\n",
      "Trial 36, Horizon h=3, Fold 4: RMSE=2.5194, R²=0.7760\n",
      "Trial 36, Horizon h=4, Fold 1: RMSE=2.4108, R²=0.6973\n",
      "Trial 36, Horizon h=4, Fold 2: RMSE=2.7255, R²=0.6651\n",
      "Trial 36, Horizon h=4, Fold 3: RMSE=2.6250, R²=0.7314\n",
      "Trial 36, Horizon h=4, Fold 4: RMSE=2.6304, R²=0.7559\n",
      "Trial 36, Horizon h=5, Fold 1: RMSE=2.4488, R²=0.6881\n",
      "Trial 36, Horizon h=5, Fold 2: RMSE=2.7735, R²=0.6526\n",
      "Trial 36, Horizon h=5, Fold 3: RMSE=2.6647, R²=0.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:19:17,660] Trial 36 finished with value: 2.3664780679996795 and parameters: {'learning_rate': 0.012766516939709571, 'max_depth': 4, 'gamma': 0.993277875641173, 'reg_lambda': 8.742105457307359, 'reg_alpha': 4.573558243405758, 'subsample': 0.7573172822151234, 'colsample_bytree': 0.5228342267873866, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36, Horizon h=5, Fold 4: RMSE=2.6541, R²=0.7519\n",
      "Trial 36 finished, overall mean RMSE across horizons=2.3665\n",
      "\n",
      "Trial 37, Horizon h=1, Fold 1: RMSE=1.8205, R²=0.8272\n",
      "Trial 37, Horizon h=1, Fold 2: RMSE=1.8139, R²=0.8531\n",
      "Trial 37, Horizon h=1, Fold 3: RMSE=1.6308, R²=0.8960\n",
      "Trial 37, Horizon h=1, Fold 4: RMSE=1.6776, R²=0.9005\n",
      "Trial 37, Horizon h=2, Fold 1: RMSE=2.2017, R²=0.7472\n",
      "Trial 37, Horizon h=2, Fold 2: RMSE=2.3862, R²=0.7449\n",
      "Trial 37, Horizon h=2, Fold 3: RMSE=2.2619, R²=0.8005\n",
      "Trial 37, Horizon h=2, Fold 4: RMSE=2.2470, R²=0.8218\n",
      "Trial 37, Horizon h=3, Fold 1: RMSE=2.3836, R²=0.7039\n",
      "Trial 37, Horizon h=3, Fold 2: RMSE=2.6348, R²=0.6879\n",
      "Trial 37, Horizon h=3, Fold 3: RMSE=2.5424, R²=0.7478\n",
      "Trial 37, Horizon h=3, Fold 4: RMSE=2.4961, R²=0.7802\n",
      "Trial 37, Horizon h=4, Fold 1: RMSE=2.3610, R²=0.7097\n",
      "Trial 37, Horizon h=4, Fold 2: RMSE=2.6952, R²=0.6725\n",
      "Trial 37, Horizon h=4, Fold 3: RMSE=2.5972, R²=0.7371\n",
      "Trial 37, Horizon h=4, Fold 4: RMSE=2.5762, R²=0.7659\n",
      "Trial 37, Horizon h=5, Fold 1: RMSE=2.4151, R²=0.6966\n",
      "Trial 37, Horizon h=5, Fold 2: RMSE=2.7564, R²=0.6569\n",
      "Trial 37, Horizon h=5, Fold 3: RMSE=2.6368, R²=0.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:19:33,846] Trial 37 finished with value: 2.3356938005447203 and parameters: {'learning_rate': 0.02039014012890637, 'max_depth': 3, 'gamma': 0.9947386688674348, 'reg_lambda': 8.045533235792707, 'reg_alpha': 5.403770970196226, 'subsample': 0.6445271745536765, 'colsample_bytree': 0.5959364592856028, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37, Horizon h=5, Fold 4: RMSE=2.5794, R²=0.7656\n",
      "Trial 37 finished, overall mean RMSE across horizons=2.3357\n",
      "\n",
      "Trial 38, Horizon h=1, Fold 1: RMSE=1.7896, R²=0.8330\n",
      "Trial 38, Horizon h=1, Fold 2: RMSE=1.8337, R²=0.8499\n",
      "Trial 38, Horizon h=1, Fold 3: RMSE=1.6344, R²=0.8955\n",
      "Trial 38, Horizon h=1, Fold 4: RMSE=1.6815, R²=0.9000\n",
      "Trial 38, Horizon h=2, Fold 1: RMSE=2.1831, R²=0.7515\n",
      "Trial 38, Horizon h=2, Fold 2: RMSE=2.3949, R²=0.7430\n",
      "Trial 38, Horizon h=2, Fold 3: RMSE=2.2536, R²=0.8019\n",
      "Trial 38, Horizon h=2, Fold 4: RMSE=2.2500, R²=0.8213\n",
      "Trial 38, Horizon h=3, Fold 1: RMSE=2.3697, R²=0.7074\n",
      "Trial 38, Horizon h=3, Fold 2: RMSE=2.6295, R²=0.6892\n",
      "Trial 38, Horizon h=3, Fold 3: RMSE=2.5134, R²=0.7536\n",
      "Trial 38, Horizon h=3, Fold 4: RMSE=2.4870, R²=0.7818\n",
      "Trial 38, Horizon h=4, Fold 1: RMSE=2.3695, R²=0.7076\n",
      "Trial 38, Horizon h=4, Fold 2: RMSE=2.7136, R²=0.6680\n",
      "Trial 38, Horizon h=4, Fold 3: RMSE=2.5899, R²=0.7386\n",
      "Trial 38, Horizon h=4, Fold 4: RMSE=2.5704, R²=0.7669\n",
      "Trial 38, Horizon h=5, Fold 1: RMSE=2.4197, R²=0.6954\n",
      "Trial 38, Horizon h=5, Fold 2: RMSE=2.7505, R²=0.6584\n",
      "Trial 38, Horizon h=5, Fold 3: RMSE=2.6292, R²=0.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:19:51,453] Trial 38 finished with value: 2.3332642672180066 and parameters: {'learning_rate': 0.017354259734193012, 'max_depth': 3, 'gamma': 0.8394933496355212, 'reg_lambda': 6.515064781418005, 'reg_alpha': 6.963861230150926, 'subsample': 0.6177735429769378, 'colsample_bytree': 0.521937284549817, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38, Horizon h=5, Fold 4: RMSE=2.6021, R²=0.7615\n",
      "Trial 38 finished, overall mean RMSE across horizons=2.3333\n",
      "\n",
      "Trial 39, Horizon h=1, Fold 1: RMSE=1.8501, R²=0.8216\n",
      "Trial 39, Horizon h=1, Fold 2: RMSE=1.8553, R²=0.8463\n",
      "Trial 39, Horizon h=1, Fold 3: RMSE=1.6705, R²=0.8908\n",
      "Trial 39, Horizon h=1, Fold 4: RMSE=1.7703, R²=0.8892\n",
      "Trial 39, Horizon h=2, Fold 1: RMSE=2.2235, R²=0.7422\n",
      "Trial 39, Horizon h=2, Fold 2: RMSE=2.4329, R²=0.7348\n",
      "Trial 39, Horizon h=2, Fold 3: RMSE=2.2817, R²=0.7970\n",
      "Trial 39, Horizon h=2, Fold 4: RMSE=2.2947, R²=0.8142\n",
      "Trial 39, Horizon h=3, Fold 1: RMSE=2.3424, R²=0.7141\n",
      "Trial 39, Horizon h=3, Fold 2: RMSE=2.6664, R²=0.6803\n",
      "Trial 39, Horizon h=3, Fold 3: RMSE=2.5338, R²=0.7495\n",
      "Trial 39, Horizon h=3, Fold 4: RMSE=2.5335, R²=0.7735\n",
      "Trial 39, Horizon h=4, Fold 1: RMSE=2.3899, R²=0.7025\n",
      "Trial 39, Horizon h=4, Fold 2: RMSE=2.7157, R²=0.6675\n",
      "Trial 39, Horizon h=4, Fold 3: RMSE=2.6122, R²=0.7341\n",
      "Trial 39, Horizon h=4, Fold 4: RMSE=2.6225, R²=0.7574\n",
      "Trial 39, Horizon h=5, Fold 1: RMSE=2.4549, R²=0.6865\n",
      "Trial 39, Horizon h=5, Fold 2: RMSE=2.7717, R²=0.6531\n",
      "Trial 39, Horizon h=5, Fold 3: RMSE=2.7122, R²=0.7132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:20:06,483] Trial 39 finished with value: 2.3676318652243955 and parameters: {'learning_rate': 0.031697584384589174, 'max_depth': 4, 'gamma': 0.7888620594727165, 'reg_lambda': 6.6253589323107285, 'reg_alpha': 7.398005968982018, 'subsample': 0.7303610692315623, 'colsample_bytree': 0.5032263213535506, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39, Horizon h=5, Fold 4: RMSE=2.6182, R²=0.7585\n",
      "Trial 39 finished, overall mean RMSE across horizons=2.3676\n",
      "\n",
      "Trial 40, Horizon h=1, Fold 1: RMSE=1.7915, R²=0.8327\n",
      "Trial 40, Horizon h=1, Fold 2: RMSE=1.8298, R²=0.8505\n",
      "Trial 40, Horizon h=1, Fold 3: RMSE=1.6380, R²=0.8951\n",
      "Trial 40, Horizon h=1, Fold 4: RMSE=1.6753, R²=0.9007\n",
      "Trial 40, Horizon h=2, Fold 1: RMSE=2.2171, R²=0.7437\n",
      "Trial 40, Horizon h=2, Fold 2: RMSE=2.4216, R²=0.7373\n",
      "Trial 40, Horizon h=2, Fold 3: RMSE=2.2369, R²=0.8049\n",
      "Trial 40, Horizon h=2, Fold 4: RMSE=2.2748, R²=0.8174\n",
      "Trial 40, Horizon h=3, Fold 1: RMSE=2.3685, R²=0.7077\n",
      "Trial 40, Horizon h=3, Fold 2: RMSE=2.6689, R²=0.6798\n",
      "Trial 40, Horizon h=3, Fold 3: RMSE=2.5179, R²=0.7527\n",
      "Trial 40, Horizon h=3, Fold 4: RMSE=2.4734, R²=0.7842\n",
      "Trial 40, Horizon h=4, Fold 1: RMSE=2.4022, R²=0.6995\n",
      "Trial 40, Horizon h=4, Fold 2: RMSE=2.7363, R²=0.6624\n",
      "Trial 40, Horizon h=4, Fold 3: RMSE=2.6107, R²=0.7343\n",
      "Trial 40, Horizon h=4, Fold 4: RMSE=2.5850, R²=0.7642\n",
      "Trial 40, Horizon h=5, Fold 1: RMSE=2.4388, R²=0.6906\n",
      "Trial 40, Horizon h=5, Fold 2: RMSE=2.7620, R²=0.6555\n",
      "Trial 40, Horizon h=5, Fold 3: RMSE=2.6519, R²=0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:20:24,362] Trial 40 finished with value: 2.3437944335581435 and parameters: {'learning_rate': 0.017275712424096524, 'max_depth': 3, 'gamma': 0.8572459235759315, 'reg_lambda': 5.574746018926028, 'reg_alpha': 9.157578695562332, 'subsample': 0.7818580879081399, 'colsample_bytree': 0.5309718017343102, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40, Horizon h=5, Fold 4: RMSE=2.5755, R²=0.7663\n",
      "Trial 40 finished, overall mean RMSE across horizons=2.3438\n",
      "\n",
      "Trial 41, Horizon h=1, Fold 1: RMSE=1.8246, R²=0.8264\n",
      "Trial 41, Horizon h=1, Fold 2: RMSE=1.8393, R²=0.8489\n",
      "Trial 41, Horizon h=1, Fold 3: RMSE=1.6661, R²=0.8914\n",
      "Trial 41, Horizon h=1, Fold 4: RMSE=1.6959, R²=0.8983\n",
      "Trial 41, Horizon h=2, Fold 1: RMSE=2.1898, R²=0.7499\n",
      "Trial 41, Horizon h=2, Fold 2: RMSE=2.3892, R²=0.7443\n",
      "Trial 41, Horizon h=2, Fold 3: RMSE=2.2466, R²=0.8032\n",
      "Trial 41, Horizon h=2, Fold 4: RMSE=2.2528, R²=0.8209\n",
      "Trial 41, Horizon h=3, Fold 1: RMSE=2.3554, R²=0.7109\n",
      "Trial 41, Horizon h=3, Fold 2: RMSE=2.6232, R²=0.6906\n",
      "Trial 41, Horizon h=3, Fold 3: RMSE=2.5078, R²=0.7546\n",
      "Trial 41, Horizon h=3, Fold 4: RMSE=2.4789, R²=0.7832\n",
      "Trial 41, Horizon h=4, Fold 1: RMSE=2.3764, R²=0.7059\n",
      "Trial 41, Horizon h=4, Fold 2: RMSE=2.6901, R²=0.6737\n",
      "Trial 41, Horizon h=4, Fold 3: RMSE=2.5972, R²=0.7371\n",
      "Trial 41, Horizon h=4, Fold 4: RMSE=2.5788, R²=0.7654\n",
      "Trial 41, Horizon h=5, Fold 1: RMSE=2.4188, R²=0.6956\n",
      "Trial 41, Horizon h=5, Fold 2: RMSE=2.7286, R²=0.6638\n",
      "Trial 41, Horizon h=5, Fold 3: RMSE=2.6696, R²=0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:20:45,992] Trial 41 finished with value: 2.3363593044174977 and parameters: {'learning_rate': 0.011552452973281894, 'max_depth': 3, 'gamma': 0.9198342543876084, 'reg_lambda': 7.347413091076161, 'reg_alpha': 8.549965264846762, 'subsample': 0.6023932404087978, 'colsample_bytree': 0.5296174615090009, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41, Horizon h=5, Fold 4: RMSE=2.5982, R²=0.7622\n",
      "Trial 41 finished, overall mean RMSE across horizons=2.3364\n",
      "\n",
      "Trial 42, Horizon h=1, Fold 1: RMSE=1.7933, R²=0.8324\n",
      "Trial 42, Horizon h=1, Fold 2: RMSE=1.8628, R²=0.8450\n",
      "Trial 42, Horizon h=1, Fold 3: RMSE=1.6380, R²=0.8950\n",
      "Trial 42, Horizon h=1, Fold 4: RMSE=1.6998, R²=0.8978\n",
      "Trial 42, Horizon h=2, Fold 1: RMSE=2.2095, R²=0.7454\n",
      "Trial 42, Horizon h=2, Fold 2: RMSE=2.3873, R²=0.7447\n",
      "Trial 42, Horizon h=2, Fold 3: RMSE=2.2610, R²=0.8006\n",
      "Trial 42, Horizon h=2, Fold 4: RMSE=2.2410, R²=0.8228\n",
      "Trial 42, Horizon h=3, Fold 1: RMSE=2.3697, R²=0.7074\n",
      "Trial 42, Horizon h=3, Fold 2: RMSE=2.6256, R²=0.6901\n",
      "Trial 42, Horizon h=3, Fold 3: RMSE=2.5446, R²=0.7474\n",
      "Trial 42, Horizon h=3, Fold 4: RMSE=2.4993, R²=0.7796\n",
      "Trial 42, Horizon h=4, Fold 1: RMSE=2.3801, R²=0.7050\n",
      "Trial 42, Horizon h=4, Fold 2: RMSE=2.6970, R²=0.6720\n",
      "Trial 42, Horizon h=4, Fold 3: RMSE=2.6054, R²=0.7354\n",
      "Trial 42, Horizon h=4, Fold 4: RMSE=2.5733, R²=0.7664\n",
      "Trial 42, Horizon h=5, Fold 1: RMSE=2.4370, R²=0.6911\n",
      "Trial 42, Horizon h=5, Fold 2: RMSE=2.7344, R²=0.6624\n",
      "Trial 42, Horizon h=5, Fold 3: RMSE=2.6410, R²=0.7281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:21:04,370] Trial 42 finished with value: 2.3397686991855315 and parameters: {'learning_rate': 0.017025105341440302, 'max_depth': 3, 'gamma': 0.9526277862182377, 'reg_lambda': 8.041735336361487, 'reg_alpha': 4.62480173071457, 'subsample': 0.6130169383035957, 'colsample_bytree': 0.5994976777621264, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42, Horizon h=5, Fold 4: RMSE=2.5954, R²=0.7627\n",
      "Trial 42 finished, overall mean RMSE across horizons=2.3398\n",
      "\n",
      "Trial 43, Horizon h=1, Fold 1: RMSE=1.8009, R²=0.8309\n",
      "Trial 43, Horizon h=1, Fold 2: RMSE=1.8444, R²=0.8481\n",
      "Trial 43, Horizon h=1, Fold 3: RMSE=1.6466, R²=0.8939\n",
      "Trial 43, Horizon h=1, Fold 4: RMSE=1.6722, R²=0.9011\n",
      "Trial 43, Horizon h=2, Fold 1: RMSE=2.2197, R²=0.7430\n",
      "Trial 43, Horizon h=2, Fold 2: RMSE=2.4123, R²=0.7393\n",
      "Trial 43, Horizon h=2, Fold 3: RMSE=2.2516, R²=0.8023\n",
      "Trial 43, Horizon h=2, Fold 4: RMSE=2.2504, R²=0.8213\n",
      "Trial 43, Horizon h=3, Fold 1: RMSE=2.3689, R²=0.7076\n",
      "Trial 43, Horizon h=3, Fold 2: RMSE=2.6532, R²=0.6835\n",
      "Trial 43, Horizon h=3, Fold 3: RMSE=2.5256, R²=0.7512\n",
      "Trial 43, Horizon h=3, Fold 4: RMSE=2.4747, R²=0.7839\n",
      "Trial 43, Horizon h=4, Fold 1: RMSE=2.3816, R²=0.7046\n",
      "Trial 43, Horizon h=4, Fold 2: RMSE=2.7244, R²=0.6653\n",
      "Trial 43, Horizon h=4, Fold 3: RMSE=2.6019, R²=0.7361\n",
      "Trial 43, Horizon h=4, Fold 4: RMSE=2.5591, R²=0.7690\n",
      "Trial 43, Horizon h=5, Fold 1: RMSE=2.4239, R²=0.6944\n",
      "Trial 43, Horizon h=5, Fold 2: RMSE=2.7337, R²=0.6625\n",
      "Trial 43, Horizon h=5, Fold 3: RMSE=2.6450, R²=0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:21:24,642] Trial 43 finished with value: 2.339377771231198 and parameters: {'learning_rate': 0.012462617011413902, 'max_depth': 3, 'gamma': 0.8319035819803541, 'reg_lambda': 6.418870132923284, 'reg_alpha': 5.65058559773005, 'subsample': 0.6871395907424088, 'colsample_bytree': 0.5450249286880313, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43, Horizon h=5, Fold 4: RMSE=2.5975, R²=0.7623\n",
      "Trial 43 finished, overall mean RMSE across horizons=2.3394\n",
      "\n",
      "Trial 44, Horizon h=1, Fold 1: RMSE=1.7962, R²=0.8318\n",
      "Trial 44, Horizon h=1, Fold 2: RMSE=1.8328, R²=0.8500\n",
      "Trial 44, Horizon h=1, Fold 3: RMSE=1.6921, R²=0.8880\n",
      "Trial 44, Horizon h=1, Fold 4: RMSE=1.7718, R²=0.8890\n",
      "Trial 44, Horizon h=2, Fold 1: RMSE=2.2112, R²=0.7450\n",
      "Trial 44, Horizon h=2, Fold 2: RMSE=2.4168, R²=0.7383\n",
      "Trial 44, Horizon h=2, Fold 3: RMSE=2.3222, R²=0.7897\n",
      "Trial 44, Horizon h=2, Fold 4: RMSE=2.3258, R²=0.8091\n",
      "Trial 44, Horizon h=3, Fold 1: RMSE=2.3939, R²=0.7013\n",
      "Trial 44, Horizon h=3, Fold 2: RMSE=2.6719, R²=0.6790\n",
      "Trial 44, Horizon h=3, Fold 3: RMSE=2.5947, R²=0.7374\n",
      "Trial 44, Horizon h=3, Fold 4: RMSE=2.5360, R²=0.7731\n",
      "Trial 44, Horizon h=4, Fold 1: RMSE=2.4458, R²=0.6885\n",
      "Trial 44, Horizon h=4, Fold 2: RMSE=2.7246, R²=0.6653\n",
      "Trial 44, Horizon h=4, Fold 3: RMSE=2.6713, R²=0.7219\n",
      "Trial 44, Horizon h=4, Fold 4: RMSE=2.6653, R²=0.7494\n",
      "Trial 44, Horizon h=5, Fold 1: RMSE=2.4898, R²=0.6775\n",
      "Trial 44, Horizon h=5, Fold 2: RMSE=2.7790, R²=0.6513\n",
      "Trial 44, Horizon h=5, Fold 3: RMSE=2.7223, R²=0.7111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:21:50,748] Trial 44 finished with value: 2.386012816098911 and parameters: {'learning_rate': 0.022341353261750903, 'max_depth': 5, 'gamma': 0.7748460262889638, 'reg_lambda': 7.0685006054107244, 'reg_alpha': 5.052975137642641, 'subsample': 0.6534433137350887, 'colsample_bytree': 0.7906895585387181, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44, Horizon h=5, Fold 4: RMSE=2.6567, R²=0.7514\n",
      "Trial 44 finished, overall mean RMSE across horizons=2.3860\n",
      "\n",
      "Trial 45, Horizon h=1, Fold 1: RMSE=1.7898, R²=0.8330\n",
      "Trial 45, Horizon h=1, Fold 2: RMSE=1.8105, R²=0.8536\n",
      "Trial 45, Horizon h=1, Fold 3: RMSE=1.6416, R²=0.8946\n",
      "Trial 45, Horizon h=1, Fold 4: RMSE=1.6915, R²=0.8988\n",
      "Trial 45, Horizon h=2, Fold 1: RMSE=2.1819, R²=0.7517\n",
      "Trial 45, Horizon h=2, Fold 2: RMSE=2.3925, R²=0.7436\n",
      "Trial 45, Horizon h=2, Fold 3: RMSE=2.2429, R²=0.8038\n",
      "Trial 45, Horizon h=2, Fold 4: RMSE=2.2398, R²=0.8230\n",
      "Trial 45, Horizon h=3, Fold 1: RMSE=2.3614, R²=0.7094\n",
      "Trial 45, Horizon h=3, Fold 2: RMSE=2.6389, R²=0.6869\n",
      "Trial 45, Horizon h=3, Fold 3: RMSE=2.5382, R²=0.7487\n",
      "Trial 45, Horizon h=3, Fold 4: RMSE=2.5072, R²=0.7782\n",
      "Trial 45, Horizon h=4, Fold 1: RMSE=2.3872, R²=0.7032\n",
      "Trial 45, Horizon h=4, Fold 2: RMSE=2.7155, R²=0.6675\n",
      "Trial 45, Horizon h=4, Fold 3: RMSE=2.6052, R²=0.7355\n",
      "Trial 45, Horizon h=4, Fold 4: RMSE=2.5629, R²=0.7683\n",
      "Trial 45, Horizon h=5, Fold 1: RMSE=2.4331, R²=0.6920\n",
      "Trial 45, Horizon h=5, Fold 2: RMSE=2.7281, R²=0.6639\n",
      "Trial 45, Horizon h=5, Fold 3: RMSE=2.6364, R²=0.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:22:09,215] Trial 45 finished with value: 2.335123712785914 and parameters: {'learning_rate': 0.016773708724239958, 'max_depth': 3, 'gamma': 0.9131575492720909, 'reg_lambda': 8.722910954911903, 'reg_alpha': 4.280883929185707, 'subsample': 0.5823612350534884, 'colsample_bytree': 0.5594925607921502, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45, Horizon h=5, Fold 4: RMSE=2.5981, R²=0.7622\n",
      "Trial 45 finished, overall mean RMSE across horizons=2.3351\n",
      "\n",
      "Trial 46, Horizon h=1, Fold 1: RMSE=1.8094, R²=0.8293\n",
      "Trial 46, Horizon h=1, Fold 2: RMSE=1.8383, R²=0.8491\n",
      "Trial 46, Horizon h=1, Fold 3: RMSE=1.6267, R²=0.8965\n",
      "Trial 46, Horizon h=1, Fold 4: RMSE=1.6763, R²=0.9006\n",
      "Trial 46, Horizon h=2, Fold 1: RMSE=2.2166, R²=0.7438\n",
      "Trial 46, Horizon h=2, Fold 2: RMSE=2.3987, R²=0.7422\n",
      "Trial 46, Horizon h=2, Fold 3: RMSE=2.2730, R²=0.7985\n",
      "Trial 46, Horizon h=2, Fold 4: RMSE=2.2610, R²=0.8196\n",
      "Trial 46, Horizon h=3, Fold 1: RMSE=2.3775, R²=0.7054\n",
      "Trial 46, Horizon h=3, Fold 2: RMSE=2.6374, R²=0.6873\n",
      "Trial 46, Horizon h=3, Fold 3: RMSE=2.5976, R²=0.7368\n",
      "Trial 46, Horizon h=3, Fold 4: RMSE=2.4530, R²=0.7877\n",
      "Trial 46, Horizon h=4, Fold 1: RMSE=2.4098, R²=0.6976\n",
      "Trial 46, Horizon h=4, Fold 2: RMSE=2.6834, R²=0.6753\n",
      "Trial 46, Horizon h=4, Fold 3: RMSE=2.6650, R²=0.7232\n",
      "Trial 46, Horizon h=4, Fold 4: RMSE=2.5830, R²=0.7646\n",
      "Trial 46, Horizon h=5, Fold 1: RMSE=2.4346, R²=0.6917\n",
      "Trial 46, Horizon h=5, Fold 2: RMSE=2.7009, R²=0.6706\n",
      "Trial 46, Horizon h=5, Fold 3: RMSE=2.6589, R²=0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:22:24,455] Trial 46 finished with value: 2.3469371723649592 and parameters: {'learning_rate': 0.0267490920473585, 'max_depth': 3, 'gamma': 0.997259890586416, 'reg_lambda': 8.391681806118545, 'reg_alpha': 2.706800388178783, 'subsample': 0.5283141943607482, 'colsample_bytree': 0.9492038142295489, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46, Horizon h=5, Fold 4: RMSE=2.6379, R²=0.7549\n",
      "Trial 46 finished, overall mean RMSE across horizons=2.3469\n",
      "\n",
      "Trial 47, Horizon h=1, Fold 1: RMSE=1.7980, R²=0.8315\n",
      "Trial 47, Horizon h=1, Fold 2: RMSE=1.8459, R²=0.8478\n",
      "Trial 47, Horizon h=1, Fold 3: RMSE=1.6609, R²=0.8921\n",
      "Trial 47, Horizon h=1, Fold 4: RMSE=1.6774, R²=0.9005\n",
      "Trial 47, Horizon h=2, Fold 1: RMSE=2.2032, R²=0.7469\n",
      "Trial 47, Horizon h=2, Fold 2: RMSE=2.4164, R²=0.7384\n",
      "Trial 47, Horizon h=2, Fold 3: RMSE=2.2563, R²=0.8015\n",
      "Trial 47, Horizon h=2, Fold 4: RMSE=2.2570, R²=0.8202\n",
      "Trial 47, Horizon h=3, Fold 1: RMSE=2.3759, R²=0.7058\n",
      "Trial 47, Horizon h=3, Fold 2: RMSE=2.6616, R²=0.6815\n",
      "Trial 47, Horizon h=3, Fold 3: RMSE=2.5108, R²=0.7541\n",
      "Trial 47, Horizon h=3, Fold 4: RMSE=2.4845, R²=0.7822\n",
      "Trial 47, Horizon h=4, Fold 1: RMSE=2.3769, R²=0.7058\n",
      "Trial 47, Horizon h=4, Fold 2: RMSE=2.7287, R²=0.6643\n",
      "Trial 47, Horizon h=4, Fold 3: RMSE=2.5866, R²=0.7392\n",
      "Trial 47, Horizon h=4, Fold 4: RMSE=2.5639, R²=0.7681\n",
      "Trial 47, Horizon h=5, Fold 1: RMSE=2.4460, R²=0.6888\n",
      "Trial 47, Horizon h=5, Fold 2: RMSE=2.7695, R²=0.6537\n",
      "Trial 47, Horizon h=5, Fold 3: RMSE=2.6597, R²=0.7242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:22:44,807] Trial 47 finished with value: 2.343228064306595 and parameters: {'learning_rate': 0.011595695400263168, 'max_depth': 3, 'gamma': 0.850158629030485, 'reg_lambda': 5.046998258005548, 'reg_alpha': 3.7160831193839283, 'subsample': 0.6745857025576417, 'colsample_bytree': 0.52092360460401, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47, Horizon h=5, Fold 4: RMSE=2.5853, R²=0.7646\n",
      "Trial 47 finished, overall mean RMSE across horizons=2.3432\n",
      "\n",
      "Trial 48, Horizon h=1, Fold 1: RMSE=1.8169, R²=0.8279\n",
      "Trial 48, Horizon h=1, Fold 2: RMSE=1.8230, R²=0.8516\n",
      "Trial 48, Horizon h=1, Fold 3: RMSE=1.6975, R²=0.8873\n",
      "Trial 48, Horizon h=1, Fold 4: RMSE=1.7916, R²=0.8865\n",
      "Trial 48, Horizon h=2, Fold 1: RMSE=2.1992, R²=0.7478\n",
      "Trial 48, Horizon h=2, Fold 2: RMSE=2.3898, R²=0.7441\n",
      "Trial 48, Horizon h=2, Fold 3: RMSE=2.3592, R²=0.7829\n",
      "Trial 48, Horizon h=2, Fold 4: RMSE=2.3615, R²=0.8032\n",
      "Trial 48, Horizon h=3, Fold 1: RMSE=2.3782, R²=0.7053\n",
      "Trial 48, Horizon h=3, Fold 2: RMSE=2.6741, R²=0.6785\n",
      "Trial 48, Horizon h=3, Fold 3: RMSE=2.5874, R²=0.7388\n",
      "Trial 48, Horizon h=3, Fold 4: RMSE=2.5829, R²=0.7646\n",
      "Trial 48, Horizon h=4, Fold 1: RMSE=2.3958, R²=0.7011\n",
      "Trial 48, Horizon h=4, Fold 2: RMSE=2.6997, R²=0.6714\n",
      "Trial 48, Horizon h=4, Fold 3: RMSE=2.6631, R²=0.7236\n",
      "Trial 48, Horizon h=4, Fold 4: RMSE=2.7031, R²=0.7422\n",
      "Trial 48, Horizon h=5, Fold 1: RMSE=2.4847, R²=0.6789\n",
      "Trial 48, Horizon h=5, Fold 2: RMSE=2.7751, R²=0.6522\n",
      "Trial 48, Horizon h=5, Fold 3: RMSE=2.6785, R²=0.7203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:23:16,978] Trial 48 finished with value: 2.3910840514937357 and parameters: {'learning_rate': 0.019092306800685483, 'max_depth': 6, 'gamma': 0.6714528710010581, 'reg_lambda': 7.7929807304497345, 'reg_alpha': 9.762007617144212, 'subsample': 0.578154063733653, 'colsample_bytree': 0.5008264092316772, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48, Horizon h=5, Fold 4: RMSE=2.7603, R²=0.7316\n",
      "Trial 48 finished, overall mean RMSE across horizons=2.3911\n",
      "\n",
      "Trial 49, Horizon h=1, Fold 1: RMSE=1.8166, R²=0.8280\n",
      "Trial 49, Horizon h=1, Fold 2: RMSE=1.8437, R²=0.8482\n",
      "Trial 49, Horizon h=1, Fold 3: RMSE=1.6945, R²=0.8877\n",
      "Trial 49, Horizon h=1, Fold 4: RMSE=1.7149, R²=0.8960\n",
      "Trial 49, Horizon h=2, Fold 1: RMSE=2.1899, R²=0.7499\n",
      "Trial 49, Horizon h=2, Fold 2: RMSE=2.4312, R²=0.7352\n",
      "Trial 49, Horizon h=2, Fold 3: RMSE=2.3298, R²=0.7883\n",
      "Trial 49, Horizon h=2, Fold 4: RMSE=2.3027, R²=0.8129\n",
      "Trial 49, Horizon h=3, Fold 1: RMSE=2.4212, R²=0.6945\n",
      "Trial 49, Horizon h=3, Fold 2: RMSE=2.6460, R²=0.6852\n",
      "Trial 49, Horizon h=3, Fold 3: RMSE=2.5728, R²=0.7418\n",
      "Trial 49, Horizon h=3, Fold 4: RMSE=2.5261, R²=0.7748\n",
      "Trial 49, Horizon h=4, Fold 1: RMSE=2.4269, R²=0.6933\n",
      "Trial 49, Horizon h=4, Fold 2: RMSE=2.7017, R²=0.6709\n",
      "Trial 49, Horizon h=4, Fold 3: RMSE=2.6715, R²=0.7218\n",
      "Trial 49, Horizon h=4, Fold 4: RMSE=2.6199, R²=0.7578\n",
      "Trial 49, Horizon h=5, Fold 1: RMSE=2.5011, R²=0.6746\n",
      "Trial 49, Horizon h=5, Fold 2: RMSE=2.7874, R²=0.6492\n",
      "Trial 49, Horizon h=5, Fold 3: RMSE=2.7135, R²=0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:23:40,403] Trial 49 finished with value: 2.376274531767748 and parameters: {'learning_rate': 0.01590383849606273, 'max_depth': 4, 'gamma': 0.9495829445962424, 'reg_lambda': 9.238550120828812, 'reg_alpha': 4.825287000142929, 'subsample': 0.6236452419179241, 'colsample_bytree': 0.6486877525927397, 'min_child_weight': 7}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49, Horizon h=5, Fold 4: RMSE=2.6142, R²=0.7593\n",
      "Trial 49 finished, overall mean RMSE across horizons=2.3763\n",
      "\n",
      "Trial 50, Horizon h=1, Fold 1: RMSE=1.7986, R²=0.8314\n",
      "Trial 50, Horizon h=1, Fold 2: RMSE=1.8349, R²=0.8497\n",
      "Trial 50, Horizon h=1, Fold 3: RMSE=1.6612, R²=0.8921\n",
      "Trial 50, Horizon h=1, Fold 4: RMSE=1.6861, R²=0.8994\n",
      "Trial 50, Horizon h=2, Fold 1: RMSE=2.2119, R²=0.7449\n",
      "Trial 50, Horizon h=2, Fold 2: RMSE=2.3925, R²=0.7435\n",
      "Trial 50, Horizon h=2, Fold 3: RMSE=2.2469, R²=0.8031\n",
      "Trial 50, Horizon h=2, Fold 4: RMSE=2.2452, R²=0.8221\n",
      "Trial 50, Horizon h=3, Fold 1: RMSE=2.3694, R²=0.7074\n",
      "Trial 50, Horizon h=3, Fold 2: RMSE=2.6466, R²=0.6851\n",
      "Trial 50, Horizon h=3, Fold 3: RMSE=2.5289, R²=0.7505\n",
      "Trial 50, Horizon h=3, Fold 4: RMSE=2.4694, R²=0.7848\n",
      "Trial 50, Horizon h=4, Fold 1: RMSE=2.3790, R²=0.7053\n",
      "Trial 50, Horizon h=4, Fold 2: RMSE=2.7071, R²=0.6696\n",
      "Trial 50, Horizon h=4, Fold 3: RMSE=2.6032, R²=0.7359\n",
      "Trial 50, Horizon h=4, Fold 4: RMSE=2.5651, R²=0.7679\n",
      "Trial 50, Horizon h=5, Fold 1: RMSE=2.4217, R²=0.6949\n",
      "Trial 50, Horizon h=5, Fold 2: RMSE=2.7543, R²=0.6574\n",
      "Trial 50, Horizon h=5, Fold 3: RMSE=2.6566, R²=0.7249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:24:04,362] Trial 50 finished with value: 2.338615790246524 and parameters: {'learning_rate': 0.010650839687892745, 'max_depth': 3, 'gamma': 0.901040527933926, 'reg_lambda': 6.888702507718779, 'reg_alpha': 6.214649988654173, 'subsample': 0.6485945555420863, 'colsample_bytree': 0.5695541927545716, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50, Horizon h=5, Fold 4: RMSE=2.5939, R²=0.7630\n",
      "Trial 50 finished, overall mean RMSE across horizons=2.3386\n",
      "\n",
      "Trial 51, Horizon h=1, Fold 1: RMSE=1.8008, R²=0.8309\n",
      "Trial 51, Horizon h=1, Fold 2: RMSE=1.8126, R²=0.8533\n",
      "Trial 51, Horizon h=1, Fold 3: RMSE=1.6401, R²=0.8948\n",
      "Trial 51, Horizon h=1, Fold 4: RMSE=1.6883, R²=0.8992\n",
      "Trial 51, Horizon h=2, Fold 1: RMSE=2.1945, R²=0.7489\n",
      "Trial 51, Horizon h=2, Fold 2: RMSE=2.4066, R²=0.7405\n",
      "Trial 51, Horizon h=2, Fold 3: RMSE=2.2531, R²=0.8020\n",
      "Trial 51, Horizon h=2, Fold 4: RMSE=2.2427, R²=0.8225\n",
      "Trial 51, Horizon h=3, Fold 1: RMSE=2.3714, R²=0.7069\n",
      "Trial 51, Horizon h=3, Fold 2: RMSE=2.6370, R²=0.6874\n",
      "Trial 51, Horizon h=3, Fold 3: RMSE=2.5221, R²=0.7519\n",
      "Trial 51, Horizon h=3, Fold 4: RMSE=2.4812, R²=0.7828\n",
      "Trial 51, Horizon h=4, Fold 1: RMSE=2.3878, R²=0.7031\n",
      "Trial 51, Horizon h=4, Fold 2: RMSE=2.7157, R²=0.6675\n",
      "Trial 51, Horizon h=4, Fold 3: RMSE=2.5903, R²=0.7385\n",
      "Trial 51, Horizon h=4, Fold 4: RMSE=2.5745, R²=0.7662\n",
      "Trial 51, Horizon h=5, Fold 1: RMSE=2.4213, R²=0.6950\n",
      "Trial 51, Horizon h=5, Fold 2: RMSE=2.7351, R²=0.6622\n",
      "Trial 51, Horizon h=5, Fold 3: RMSE=2.6588, R²=0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:24:25,686] Trial 51 finished with value: 2.3349655657126487 and parameters: {'learning_rate': 0.013943966947130015, 'max_depth': 3, 'gamma': 0.8697237789958207, 'reg_lambda': 7.3434180978550545, 'reg_alpha': 3.6033802729859437, 'subsample': 0.6236755114785161, 'colsample_bytree': 0.5495204946306019, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51, Horizon h=5, Fold 4: RMSE=2.5655, R²=0.7681\n",
      "Trial 51 finished, overall mean RMSE across horizons=2.3350\n",
      "\n",
      "Trial 52, Horizon h=1, Fold 1: RMSE=1.8165, R²=0.8280\n",
      "Trial 52, Horizon h=1, Fold 2: RMSE=1.8657, R²=0.8446\n",
      "Trial 52, Horizon h=1, Fold 3: RMSE=1.6527, R²=0.8932\n",
      "Trial 52, Horizon h=1, Fold 4: RMSE=1.6759, R²=0.9007\n",
      "Trial 52, Horizon h=2, Fold 1: RMSE=2.2096, R²=0.7454\n",
      "Trial 52, Horizon h=2, Fold 2: RMSE=2.4058, R²=0.7407\n",
      "Trial 52, Horizon h=2, Fold 3: RMSE=2.2442, R²=0.8036\n",
      "Trial 52, Horizon h=2, Fold 4: RMSE=2.2569, R²=0.8202\n",
      "Trial 52, Horizon h=3, Fold 1: RMSE=2.3593, R²=0.7099\n",
      "Trial 52, Horizon h=3, Fold 2: RMSE=2.6647, R²=0.6808\n",
      "Trial 52, Horizon h=3, Fold 3: RMSE=2.5058, R²=0.7551\n",
      "Trial 52, Horizon h=3, Fold 4: RMSE=2.4796, R²=0.7831\n",
      "Trial 52, Horizon h=4, Fold 1: RMSE=2.3886, R²=0.7029\n",
      "Trial 52, Horizon h=4, Fold 2: RMSE=2.7284, R²=0.6644\n",
      "Trial 52, Horizon h=4, Fold 3: RMSE=2.5959, R²=0.7374\n",
      "Trial 52, Horizon h=4, Fold 4: RMSE=2.5748, R²=0.7661\n",
      "Trial 52, Horizon h=5, Fold 1: RMSE=2.4328, R²=0.6921\n",
      "Trial 52, Horizon h=5, Fold 2: RMSE=2.7577, R²=0.6566\n",
      "Trial 52, Horizon h=5, Fold 3: RMSE=2.6646, R²=0.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:24:44,709] Trial 52 finished with value: 2.3444616045693385 and parameters: {'learning_rate': 0.013403771872878304, 'max_depth': 3, 'gamma': 0.8279493664581712, 'reg_lambda': 6.413438856696314, 'reg_alpha': 4.138096946811678, 'subsample': 0.6936134733896462, 'colsample_bytree': 0.5206434156427656, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52, Horizon h=5, Fold 4: RMSE=2.6098, R²=0.7601\n",
      "Trial 52 finished, overall mean RMSE across horizons=2.3445\n",
      "\n",
      "Trial 53, Horizon h=1, Fold 1: RMSE=1.7928, R²=0.8325\n",
      "Trial 53, Horizon h=1, Fold 2: RMSE=1.8219, R²=0.8518\n",
      "Trial 53, Horizon h=1, Fold 3: RMSE=1.6418, R²=0.8946\n",
      "Trial 53, Horizon h=1, Fold 4: RMSE=1.6755, R²=0.9007\n",
      "Trial 53, Horizon h=2, Fold 1: RMSE=2.1887, R²=0.7502\n",
      "Trial 53, Horizon h=2, Fold 2: RMSE=2.4077, R²=0.7403\n",
      "Trial 53, Horizon h=2, Fold 3: RMSE=2.2561, R²=0.8015\n",
      "Trial 53, Horizon h=2, Fold 4: RMSE=2.2483, R²=0.8216\n",
      "Trial 53, Horizon h=3, Fold 1: RMSE=2.3711, R²=0.7070\n",
      "Trial 53, Horizon h=3, Fold 2: RMSE=2.6331, R²=0.6883\n",
      "Trial 53, Horizon h=3, Fold 3: RMSE=2.5257, R²=0.7511\n",
      "Trial 53, Horizon h=3, Fold 4: RMSE=2.4955, R²=0.7803\n",
      "Trial 53, Horizon h=4, Fold 1: RMSE=2.3737, R²=0.7066\n",
      "Trial 53, Horizon h=4, Fold 2: RMSE=2.7082, R²=0.6693\n",
      "Trial 53, Horizon h=4, Fold 3: RMSE=2.5958, R²=0.7374\n",
      "Trial 53, Horizon h=4, Fold 4: RMSE=2.5598, R²=0.7688\n",
      "Trial 53, Horizon h=5, Fold 1: RMSE=2.4505, R²=0.6876\n",
      "Trial 53, Horizon h=5, Fold 2: RMSE=2.7108, R²=0.6682\n",
      "Trial 53, Horizon h=5, Fold 3: RMSE=2.6729, R²=0.7215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:25:03,744] Trial 53 finished with value: 2.3346130974919963 and parameters: {'learning_rate': 0.014805760204808024, 'max_depth': 3, 'gamma': 0.7595363322953417, 'reg_lambda': 7.251859404818299, 'reg_alpha': 2.884026445795819, 'subsample': 0.6683744129745481, 'colsample_bytree': 0.5516960767436753, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53, Horizon h=5, Fold 4: RMSE=2.5623, R²=0.7687\n",
      "Trial 53 finished, overall mean RMSE across horizons=2.3346\n",
      "\n",
      "Trial 54, Horizon h=1, Fold 1: RMSE=1.8337, R²=0.8247\n",
      "Trial 54, Horizon h=1, Fold 2: RMSE=1.8229, R²=0.8516\n",
      "Trial 54, Horizon h=1, Fold 3: RMSE=1.6210, R²=0.8972\n",
      "Trial 54, Horizon h=1, Fold 4: RMSE=1.6848, R²=0.8996\n",
      "Trial 54, Horizon h=2, Fold 1: RMSE=2.2342, R²=0.7397\n",
      "Trial 54, Horizon h=2, Fold 2: RMSE=2.4351, R²=0.7343\n",
      "Trial 54, Horizon h=2, Fold 3: RMSE=2.2496, R²=0.8026\n",
      "Trial 54, Horizon h=2, Fold 4: RMSE=2.2716, R²=0.8179\n",
      "Trial 54, Horizon h=3, Fold 1: RMSE=2.3745, R²=0.7062\n",
      "Trial 54, Horizon h=3, Fold 2: RMSE=2.6961, R²=0.6732\n",
      "Trial 54, Horizon h=3, Fold 3: RMSE=2.5023, R²=0.7557\n",
      "Trial 54, Horizon h=3, Fold 4: RMSE=2.5071, R²=0.7782\n",
      "Trial 54, Horizon h=4, Fold 1: RMSE=2.4101, R²=0.6975\n",
      "Trial 54, Horizon h=4, Fold 2: RMSE=2.7310, R²=0.6637\n",
      "Trial 54, Horizon h=4, Fold 3: RMSE=2.6380, R²=0.7288\n",
      "Trial 54, Horizon h=4, Fold 4: RMSE=2.5961, R²=0.7622\n",
      "Trial 54, Horizon h=5, Fold 1: RMSE=2.4262, R²=0.6938\n",
      "Trial 54, Horizon h=5, Fold 2: RMSE=2.7816, R²=0.6506\n",
      "Trial 54, Horizon h=5, Fold 3: RMSE=2.6655, R²=0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:25:15,269] Trial 54 finished with value: 2.353449000397345 and parameters: {'learning_rate': 0.03414063650922665, 'max_depth': 3, 'gamma': 0.757711008854278, 'reg_lambda': 5.910157479325553, 'reg_alpha': 2.6558823793465915, 'subsample': 0.6588384945266847, 'colsample_bytree': 0.6058857438777501, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54, Horizon h=5, Fold 4: RMSE=2.5878, R²=0.7641\n",
      "Trial 54 finished, overall mean RMSE across horizons=2.3534\n",
      "\n",
      "Trial 55, Horizon h=1, Fold 1: RMSE=1.8060, R²=0.8300\n",
      "Trial 55, Horizon h=1, Fold 2: RMSE=1.8450, R²=0.8480\n",
      "Trial 55, Horizon h=1, Fold 3: RMSE=1.6499, R²=0.8935\n",
      "Trial 55, Horizon h=1, Fold 4: RMSE=1.6810, R²=0.9001\n",
      "Trial 55, Horizon h=2, Fold 1: RMSE=2.2186, R²=0.7433\n",
      "Trial 55, Horizon h=2, Fold 2: RMSE=2.3937, R²=0.7433\n",
      "Trial 55, Horizon h=2, Fold 3: RMSE=2.2595, R²=0.8009\n",
      "Trial 55, Horizon h=2, Fold 4: RMSE=2.2390, R²=0.8231\n",
      "Trial 55, Horizon h=3, Fold 1: RMSE=2.3834, R²=0.7040\n",
      "Trial 55, Horizon h=3, Fold 2: RMSE=2.6084, R²=0.6941\n",
      "Trial 55, Horizon h=3, Fold 3: RMSE=2.5331, R²=0.7497\n",
      "Trial 55, Horizon h=3, Fold 4: RMSE=2.4912, R²=0.7810\n",
      "Trial 55, Horizon h=4, Fold 1: RMSE=2.3834, R²=0.7042\n",
      "Trial 55, Horizon h=4, Fold 2: RMSE=2.7118, R²=0.6684\n",
      "Trial 55, Horizon h=4, Fold 3: RMSE=2.5925, R²=0.7380\n",
      "Trial 55, Horizon h=4, Fold 4: RMSE=2.5645, R²=0.7680\n",
      "Trial 55, Horizon h=5, Fold 1: RMSE=2.4391, R²=0.6905\n",
      "Trial 55, Horizon h=5, Fold 2: RMSE=2.7392, R²=0.6612\n",
      "Trial 55, Horizon h=5, Fold 3: RMSE=2.6681, R²=0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:25:32,239] Trial 55 finished with value: 2.341880821047888 and parameters: {'learning_rate': 0.019378430012344322, 'max_depth': 3, 'gamma': 0.9542570879910774, 'reg_lambda': 8.194053574962831, 'reg_alpha': 1.891349354042079, 'subsample': 0.6064545668510893, 'colsample_bytree': 0.5876089541847526, 'min_child_weight': 7}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55, Horizon h=5, Fold 4: RMSE=2.6303, R²=0.7563\n",
      "Trial 55 finished, overall mean RMSE across horizons=2.3419\n",
      "\n",
      "Trial 56, Horizon h=1, Fold 1: RMSE=1.8356, R²=0.8243\n",
      "Trial 56, Horizon h=1, Fold 2: RMSE=1.8547, R²=0.8464\n",
      "Trial 56, Horizon h=1, Fold 3: RMSE=1.6823, R²=0.8893\n",
      "Trial 56, Horizon h=1, Fold 4: RMSE=1.6876, R²=0.8993\n",
      "Trial 56, Horizon h=2, Fold 1: RMSE=2.1983, R²=0.7480\n",
      "Trial 56, Horizon h=2, Fold 2: RMSE=2.4201, R²=0.7376\n",
      "Trial 56, Horizon h=2, Fold 3: RMSE=2.2677, R²=0.7994\n",
      "Trial 56, Horizon h=2, Fold 4: RMSE=2.2459, R²=0.8220\n",
      "Trial 56, Horizon h=3, Fold 1: RMSE=2.3801, R²=0.7048\n",
      "Trial 56, Horizon h=3, Fold 2: RMSE=2.6628, R²=0.6812\n",
      "Trial 56, Horizon h=3, Fold 3: RMSE=2.5309, R²=0.7501\n",
      "Trial 56, Horizon h=3, Fold 4: RMSE=2.4996, R²=0.7796\n",
      "Trial 56, Horizon h=4, Fold 1: RMSE=2.3896, R²=0.7026\n",
      "Trial 56, Horizon h=4, Fold 2: RMSE=2.7154, R²=0.6676\n",
      "Trial 56, Horizon h=4, Fold 3: RMSE=2.6305, R²=0.7303\n",
      "Trial 56, Horizon h=4, Fold 4: RMSE=2.5686, R²=0.7672\n",
      "Trial 56, Horizon h=5, Fold 1: RMSE=2.4390, R²=0.6905\n",
      "Trial 56, Horizon h=5, Fold 2: RMSE=2.7348, R²=0.6623\n",
      "Trial 56, Horizon h=5, Fold 3: RMSE=2.6762, R²=0.7208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:25:54,437] Trial 56 finished with value: 2.350567351781618 and parameters: {'learning_rate': 0.011625264487918957, 'max_depth': 3, 'gamma': 0.6311843875889452, 'reg_lambda': 7.088117391216727, 'reg_alpha': 7.0316579232647225, 'subsample': 0.6670844852982927, 'colsample_bytree': 0.7082241440023814, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56, Horizon h=5, Fold 4: RMSE=2.5916, R²=0.7634\n",
      "Trial 56 finished, overall mean RMSE across horizons=2.3506\n",
      "\n",
      "Trial 57, Horizon h=1, Fold 1: RMSE=1.8701, R²=0.8177\n",
      "Trial 57, Horizon h=1, Fold 2: RMSE=1.8413, R²=0.8486\n",
      "Trial 57, Horizon h=1, Fold 3: RMSE=1.6850, R²=0.8889\n",
      "Trial 57, Horizon h=1, Fold 4: RMSE=1.7050, R²=0.8972\n",
      "Trial 57, Horizon h=2, Fold 1: RMSE=2.2816, R²=0.7285\n",
      "Trial 57, Horizon h=2, Fold 2: RMSE=2.4344, R²=0.7345\n",
      "Trial 57, Horizon h=2, Fold 3: RMSE=2.2725, R²=0.7986\n",
      "Trial 57, Horizon h=2, Fold 4: RMSE=2.3007, R²=0.8132\n",
      "Trial 57, Horizon h=3, Fold 1: RMSE=2.4563, R²=0.6856\n",
      "Trial 57, Horizon h=3, Fold 2: RMSE=2.6989, R²=0.6725\n",
      "Trial 57, Horizon h=3, Fold 3: RMSE=2.5898, R²=0.7383\n",
      "Trial 57, Horizon h=3, Fold 4: RMSE=2.5278, R²=0.7745\n",
      "Trial 57, Horizon h=4, Fold 1: RMSE=2.4085, R²=0.6979\n",
      "Trial 57, Horizon h=4, Fold 2: RMSE=2.7684, R²=0.6544\n",
      "Trial 57, Horizon h=4, Fold 3: RMSE=2.6489, R²=0.7265\n",
      "Trial 57, Horizon h=4, Fold 4: RMSE=2.5929, R²=0.7628\n",
      "Trial 57, Horizon h=5, Fold 1: RMSE=2.5215, R²=0.6693\n",
      "Trial 57, Horizon h=5, Fold 2: RMSE=2.8279, R²=0.6389\n",
      "Trial 57, Horizon h=5, Fold 3: RMSE=2.7092, R²=0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:26:19,072] Trial 57 finished with value: 2.3853743219906085 and parameters: {'learning_rate': 0.010149998167790922, 'max_depth': 3, 'gamma': 0.9136015873781199, 'reg_lambda': 6.556042182860796, 'reg_alpha': 2.8470538144703896, 'subsample': 0.9866547557322125, 'colsample_bytree': 0.9966321741455256, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57, Horizon h=5, Fold 4: RMSE=2.5667, R²=0.7679\n",
      "Trial 57 finished, overall mean RMSE across horizons=2.3854\n",
      "\n",
      "Trial 58, Horizon h=1, Fold 1: RMSE=1.8123, R²=0.8288\n",
      "Trial 58, Horizon h=1, Fold 2: RMSE=1.8491, R²=0.8473\n",
      "Trial 58, Horizon h=1, Fold 3: RMSE=1.7281, R²=0.8832\n",
      "Trial 58, Horizon h=1, Fold 4: RMSE=1.7337, R²=0.8937\n",
      "Trial 58, Horizon h=2, Fold 1: RMSE=2.2270, R²=0.7414\n",
      "Trial 58, Horizon h=2, Fold 2: RMSE=2.4515, R²=0.7307\n",
      "Trial 58, Horizon h=2, Fold 3: RMSE=2.3481, R²=0.7850\n",
      "Trial 58, Horizon h=2, Fold 4: RMSE=2.3130, R²=0.8112\n",
      "Trial 58, Horizon h=3, Fold 1: RMSE=2.4104, R²=0.6972\n",
      "Trial 58, Horizon h=3, Fold 2: RMSE=2.7141, R²=0.6688\n",
      "Trial 58, Horizon h=3, Fold 3: RMSE=2.5792, R²=0.7405\n",
      "Trial 58, Horizon h=3, Fold 4: RMSE=2.5271, R²=0.7747\n",
      "Trial 58, Horizon h=4, Fold 1: RMSE=2.4488, R²=0.6877\n",
      "Trial 58, Horizon h=4, Fold 2: RMSE=2.7408, R²=0.6613\n",
      "Trial 58, Horizon h=4, Fold 3: RMSE=2.7013, R²=0.7156\n",
      "Trial 58, Horizon h=4, Fold 4: RMSE=2.6003, R²=0.7615\n",
      "Trial 58, Horizon h=5, Fold 1: RMSE=2.5088, R²=0.6726\n",
      "Trial 58, Horizon h=5, Fold 2: RMSE=2.7681, R²=0.6540\n",
      "Trial 58, Horizon h=5, Fold 3: RMSE=2.7229, R²=0.7110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:26:44,426] Trial 58 finished with value: 2.3921959678727753 and parameters: {'learning_rate': 0.015197564855006193, 'max_depth': 4, 'gamma': 0.810673931913404, 'reg_lambda': 7.7407321999663985, 'reg_alpha': 2.0993255596359224, 'subsample': 0.7157869481515512, 'colsample_bytree': 0.9061186350114465, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58, Horizon h=5, Fold 4: RMSE=2.6595, R²=0.7508\n",
      "Trial 58 finished, overall mean RMSE across horizons=2.3922\n",
      "\n",
      "Trial 59, Horizon h=1, Fold 1: RMSE=1.7938, R²=0.8323\n",
      "Trial 59, Horizon h=1, Fold 2: RMSE=1.8056, R²=0.8544\n",
      "Trial 59, Horizon h=1, Fold 3: RMSE=1.6533, R²=0.8931\n",
      "Trial 59, Horizon h=1, Fold 4: RMSE=1.6766, R²=0.9006\n",
      "Trial 59, Horizon h=2, Fold 1: RMSE=2.2234, R²=0.7422\n",
      "Trial 59, Horizon h=2, Fold 2: RMSE=2.4013, R²=0.7416\n",
      "Trial 59, Horizon h=2, Fold 3: RMSE=2.2780, R²=0.7976\n",
      "Trial 59, Horizon h=2, Fold 4: RMSE=2.2724, R²=0.8178\n",
      "Trial 59, Horizon h=3, Fold 1: RMSE=2.3885, R²=0.7027\n",
      "Trial 59, Horizon h=3, Fold 2: RMSE=2.6174, R²=0.6920\n",
      "Trial 59, Horizon h=3, Fold 3: RMSE=2.5022, R²=0.7557\n",
      "Trial 59, Horizon h=3, Fold 4: RMSE=2.4694, R²=0.7848\n",
      "Trial 59, Horizon h=4, Fold 1: RMSE=2.3816, R²=0.7046\n",
      "Trial 59, Horizon h=4, Fold 2: RMSE=2.6841, R²=0.6752\n",
      "Trial 59, Horizon h=4, Fold 3: RMSE=2.6110, R²=0.7343\n",
      "Trial 59, Horizon h=4, Fold 4: RMSE=2.5667, R²=0.7676\n",
      "Trial 59, Horizon h=5, Fold 1: RMSE=2.4598, R²=0.6852\n",
      "Trial 59, Horizon h=5, Fold 2: RMSE=2.7445, R²=0.6599\n",
      "Trial 59, Horizon h=5, Fold 3: RMSE=2.6916, R²=0.7176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:26:58,819] Trial 59 finished with value: 2.340992408204145 and parameters: {'learning_rate': 0.027505357164275632, 'max_depth': 3, 'gamma': 0.9787947350522102, 'reg_lambda': 8.572362536817618, 'reg_alpha': 3.404876700109973, 'subsample': 0.5725585360017622, 'colsample_bytree': 0.7273579482316663, 'min_child_weight': 8}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59, Horizon h=5, Fold 4: RMSE=2.5984, R²=0.7622\n",
      "Trial 59 finished, overall mean RMSE across horizons=2.3410\n",
      "\n",
      "Trial 60, Horizon h=1, Fold 1: RMSE=1.8040, R²=0.8303\n",
      "Trial 60, Horizon h=1, Fold 2: RMSE=1.7923, R²=0.8566\n",
      "Trial 60, Horizon h=1, Fold 3: RMSE=1.6692, R²=0.8910\n",
      "Trial 60, Horizon h=1, Fold 4: RMSE=1.7858, R²=0.8872\n",
      "Trial 60, Horizon h=2, Fold 1: RMSE=2.2170, R²=0.7437\n",
      "Trial 60, Horizon h=2, Fold 2: RMSE=2.4269, R²=0.7361\n",
      "Trial 60, Horizon h=2, Fold 3: RMSE=2.3511, R²=0.7844\n",
      "Trial 60, Horizon h=2, Fold 4: RMSE=2.2595, R²=0.8198\n",
      "Trial 60, Horizon h=3, Fold 1: RMSE=2.3055, R²=0.7230\n",
      "Trial 60, Horizon h=3, Fold 2: RMSE=2.7010, R²=0.6720\n",
      "Trial 60, Horizon h=3, Fold 3: RMSE=2.5982, R²=0.7366\n",
      "Trial 60, Horizon h=3, Fold 4: RMSE=2.4897, R²=0.7813\n",
      "Trial 60, Horizon h=4, Fold 1: RMSE=2.4206, R²=0.6948\n",
      "Trial 60, Horizon h=4, Fold 2: RMSE=2.6773, R²=0.6768\n",
      "Trial 60, Horizon h=4, Fold 3: RMSE=2.7060, R²=0.7146\n",
      "Trial 60, Horizon h=4, Fold 4: RMSE=2.6204, R²=0.7578\n",
      "Trial 60, Horizon h=5, Fold 1: RMSE=2.4264, R²=0.6937\n",
      "Trial 60, Horizon h=5, Fold 2: RMSE=2.8061, R²=0.6444\n",
      "Trial 60, Horizon h=5, Fold 3: RMSE=2.7336, R²=0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:27:09,441] Trial 60 finished with value: 2.3729763511089983 and parameters: {'learning_rate': 0.06681267369272148, 'max_depth': 4, 'gamma': 0.9310905524297416, 'reg_lambda': 4.65209122517463, 'reg_alpha': 4.361716013388357, 'subsample': 0.5328545448065171, 'colsample_bytree': 0.5720022532913717, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60, Horizon h=5, Fold 4: RMSE=2.6688, R²=0.7491\n",
      "Trial 60 finished, overall mean RMSE across horizons=2.3730\n",
      "\n",
      "Trial 61, Horizon h=1, Fold 1: RMSE=1.8052, R²=0.8301\n",
      "Trial 61, Horizon h=1, Fold 2: RMSE=1.8200, R²=0.8521\n",
      "Trial 61, Horizon h=1, Fold 3: RMSE=1.6299, R²=0.8961\n",
      "Trial 61, Horizon h=1, Fold 4: RMSE=1.6744, R²=0.9008\n",
      "Trial 61, Horizon h=2, Fold 1: RMSE=2.1949, R²=0.7488\n",
      "Trial 61, Horizon h=2, Fold 2: RMSE=2.4116, R²=0.7394\n",
      "Trial 61, Horizon h=2, Fold 3: RMSE=2.2392, R²=0.8045\n",
      "Trial 61, Horizon h=2, Fold 4: RMSE=2.2490, R²=0.8215\n",
      "Trial 61, Horizon h=3, Fold 1: RMSE=2.3617, R²=0.7093\n",
      "Trial 61, Horizon h=3, Fold 2: RMSE=2.6542, R²=0.6833\n",
      "Trial 61, Horizon h=3, Fold 3: RMSE=2.5108, R²=0.7541\n",
      "Trial 61, Horizon h=3, Fold 4: RMSE=2.4836, R²=0.7824\n",
      "Trial 61, Horizon h=4, Fold 1: RMSE=2.3566, R²=0.7108\n",
      "Trial 61, Horizon h=4, Fold 2: RMSE=2.7186, R²=0.6668\n",
      "Trial 61, Horizon h=4, Fold 3: RMSE=2.5992, R²=0.7367\n",
      "Trial 61, Horizon h=4, Fold 4: RMSE=2.5995, R²=0.7616\n",
      "Trial 61, Horizon h=5, Fold 1: RMSE=2.4198, R²=0.6954\n",
      "Trial 61, Horizon h=5, Fold 2: RMSE=2.7465, R²=0.6594\n",
      "Trial 61, Horizon h=5, Fold 3: RMSE=2.6312, R²=0.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:27:26,635] Trial 61 finished with value: 2.3354413353993144 and parameters: {'learning_rate': 0.017803739565628023, 'max_depth': 3, 'gamma': 0.8829662494172031, 'reg_lambda': 7.299955165647945, 'reg_alpha': 3.8916602589988294, 'subsample': 0.6382669975194296, 'colsample_bytree': 0.5556755023483202, 'min_child_weight': 9}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61, Horizon h=5, Fold 4: RMSE=2.6029, R²=0.7613\n",
      "Trial 61 finished, overall mean RMSE across horizons=2.3354\n",
      "\n",
      "Trial 62, Horizon h=1, Fold 1: RMSE=1.8203, R²=0.8273\n",
      "Trial 62, Horizon h=1, Fold 2: RMSE=1.8333, R²=0.8499\n",
      "Trial 62, Horizon h=1, Fold 3: RMSE=1.6323, R²=0.8958\n",
      "Trial 62, Horizon h=1, Fold 4: RMSE=1.6536, R²=0.9033\n",
      "Trial 62, Horizon h=2, Fold 1: RMSE=2.1982, R²=0.7480\n",
      "Trial 62, Horizon h=2, Fold 2: RMSE=2.3955, R²=0.7429\n",
      "Trial 62, Horizon h=2, Fold 3: RMSE=2.2467, R²=0.8031\n",
      "Trial 62, Horizon h=2, Fold 4: RMSE=2.2357, R²=0.8236\n",
      "Trial 62, Horizon h=3, Fold 1: RMSE=2.3662, R²=0.7082\n",
      "Trial 62, Horizon h=3, Fold 2: RMSE=2.6364, R²=0.6875\n",
      "Trial 62, Horizon h=3, Fold 3: RMSE=2.5201, R²=0.7522\n",
      "Trial 62, Horizon h=3, Fold 4: RMSE=2.4864, R²=0.7819\n",
      "Trial 62, Horizon h=4, Fold 1: RMSE=2.3845, R²=0.7039\n",
      "Trial 62, Horizon h=4, Fold 2: RMSE=2.7194, R²=0.6666\n",
      "Trial 62, Horizon h=4, Fold 3: RMSE=2.5691, R²=0.7428\n",
      "Trial 62, Horizon h=4, Fold 4: RMSE=2.5729, R²=0.7664\n",
      "Trial 62, Horizon h=5, Fold 1: RMSE=2.4332, R²=0.6920\n",
      "Trial 62, Horizon h=5, Fold 2: RMSE=2.7405, R²=0.6609\n",
      "Trial 62, Horizon h=5, Fold 3: RMSE=2.6386, R²=0.7286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:27:45,639] Trial 62 finished with value: 2.3343003392090305 and parameters: {'learning_rate': 0.015331435595775786, 'max_depth': 3, 'gamma': 0.8349545680480259, 'reg_lambda': 6.2391915639134305, 'reg_alpha': 2.9073593405598013, 'subsample': 0.6171012373978771, 'colsample_bytree': 0.5156636250903147, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62, Horizon h=5, Fold 4: RMSE=2.6033, R²=0.7613\n",
      "Trial 62 finished, overall mean RMSE across horizons=2.3343\n",
      "\n",
      "Trial 63, Horizon h=1, Fold 1: RMSE=1.8138, R²=0.8285\n",
      "Trial 63, Horizon h=1, Fold 2: RMSE=1.8261, R²=0.8511\n",
      "Trial 63, Horizon h=1, Fold 3: RMSE=1.6381, R²=0.8950\n",
      "Trial 63, Horizon h=1, Fold 4: RMSE=1.6602, R²=0.9025\n",
      "Trial 63, Horizon h=2, Fold 1: RMSE=2.1928, R²=0.7492\n",
      "Trial 63, Horizon h=2, Fold 2: RMSE=2.3978, R²=0.7424\n",
      "Trial 63, Horizon h=2, Fold 3: RMSE=2.2484, R²=0.8028\n",
      "Trial 63, Horizon h=2, Fold 4: RMSE=2.2337, R²=0.8239\n",
      "Trial 63, Horizon h=3, Fold 1: RMSE=2.3666, R²=0.7081\n",
      "Trial 63, Horizon h=3, Fold 2: RMSE=2.6353, R²=0.6878\n",
      "Trial 63, Horizon h=3, Fold 3: RMSE=2.5030, R²=0.7556\n",
      "Trial 63, Horizon h=3, Fold 4: RMSE=2.4772, R²=0.7835\n",
      "Trial 63, Horizon h=4, Fold 1: RMSE=2.3800, R²=0.7050\n",
      "Trial 63, Horizon h=4, Fold 2: RMSE=2.7191, R²=0.6666\n",
      "Trial 63, Horizon h=4, Fold 3: RMSE=2.5690, R²=0.7428\n",
      "Trial 63, Horizon h=4, Fold 4: RMSE=2.5845, R²=0.7643\n",
      "Trial 63, Horizon h=5, Fold 1: RMSE=2.4428, R²=0.6896\n",
      "Trial 63, Horizon h=5, Fold 2: RMSE=2.7463, R²=0.6594\n",
      "Trial 63, Horizon h=5, Fold 3: RMSE=2.6333, R²=0.7297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:28:04,264] Trial 63 finished with value: 2.333462158084011 and parameters: {'learning_rate': 0.015846769105043623, 'max_depth': 3, 'gamma': 0.7508940935017386, 'reg_lambda': 6.234852695490815, 'reg_alpha': 2.8870884348773975, 'subsample': 0.613170945964676, 'colsample_bytree': 0.5149386591024506, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63, Horizon h=5, Fold 4: RMSE=2.6012, R²=0.7616\n",
      "Trial 63 finished, overall mean RMSE across horizons=2.3335\n",
      "\n",
      "Trial 64, Horizon h=1, Fold 1: RMSE=1.7956, R²=0.8319\n",
      "Trial 64, Horizon h=1, Fold 2: RMSE=1.8261, R²=0.8511\n",
      "Trial 64, Horizon h=1, Fold 3: RMSE=1.6260, R²=0.8966\n",
      "Trial 64, Horizon h=1, Fold 4: RMSE=1.6550, R²=0.9031\n",
      "Trial 64, Horizon h=2, Fold 1: RMSE=2.1948, R²=0.7488\n",
      "Trial 64, Horizon h=2, Fold 2: RMSE=2.4083, R²=0.7401\n",
      "Trial 64, Horizon h=2, Fold 3: RMSE=2.2338, R²=0.8054\n",
      "Trial 64, Horizon h=2, Fold 4: RMSE=2.2491, R²=0.8215\n",
      "Trial 64, Horizon h=3, Fold 1: RMSE=2.3853, R²=0.7035\n",
      "Trial 64, Horizon h=3, Fold 2: RMSE=2.6329, R²=0.6883\n",
      "Trial 64, Horizon h=3, Fold 3: RMSE=2.5004, R²=0.7561\n",
      "Trial 64, Horizon h=3, Fold 4: RMSE=2.4521, R²=0.7879\n",
      "Trial 64, Horizon h=4, Fold 1: RMSE=2.4047, R²=0.6988\n",
      "Trial 64, Horizon h=4, Fold 2: RMSE=2.7349, R²=0.6628\n",
      "Trial 64, Horizon h=4, Fold 3: RMSE=2.5654, R²=0.7435\n",
      "Trial 64, Horizon h=4, Fold 4: RMSE=2.5668, R²=0.7676\n",
      "Trial 64, Horizon h=5, Fold 1: RMSE=2.4142, R²=0.6968\n",
      "Trial 64, Horizon h=5, Fold 2: RMSE=2.7590, R²=0.6563\n",
      "Trial 64, Horizon h=5, Fold 3: RMSE=2.6273, R²=0.7309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:28:19,705] Trial 64 finished with value: 2.332268345663562 and parameters: {'learning_rate': 0.022047226514136792, 'max_depth': 3, 'gamma': 0.76089880555335, 'reg_lambda': 5.85273765448594, 'reg_alpha': 2.873280914425157, 'subsample': 0.5904745135434658, 'colsample_bytree': 0.5175688193894564, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64, Horizon h=5, Fold 4: RMSE=2.6140, R²=0.7593\n",
      "Trial 64 finished, overall mean RMSE across horizons=2.3323\n",
      "\n",
      "Trial 65, Horizon h=1, Fold 1: RMSE=1.8113, R²=0.8290\n",
      "Trial 65, Horizon h=1, Fold 2: RMSE=1.8343, R²=0.8498\n",
      "Trial 65, Horizon h=1, Fold 3: RMSE=1.6207, R²=0.8973\n",
      "Trial 65, Horizon h=1, Fold 4: RMSE=1.6633, R²=0.9021\n",
      "Trial 65, Horizon h=2, Fold 1: RMSE=2.1996, R²=0.7477\n",
      "Trial 65, Horizon h=2, Fold 2: RMSE=2.3886, R²=0.7444\n",
      "Trial 65, Horizon h=2, Fold 3: RMSE=2.2268, R²=0.8066\n",
      "Trial 65, Horizon h=2, Fold 4: RMSE=2.2467, R²=0.8219\n",
      "Trial 65, Horizon h=3, Fold 1: RMSE=2.3999, R²=0.6999\n",
      "Trial 65, Horizon h=3, Fold 2: RMSE=2.6551, R²=0.6831\n",
      "Trial 65, Horizon h=3, Fold 3: RMSE=2.5053, R²=0.7551\n",
      "Trial 65, Horizon h=3, Fold 4: RMSE=2.4626, R²=0.7860\n",
      "Trial 65, Horizon h=4, Fold 1: RMSE=2.4021, R²=0.6995\n",
      "Trial 65, Horizon h=4, Fold 2: RMSE=2.7416, R²=0.6611\n",
      "Trial 65, Horizon h=4, Fold 3: RMSE=2.5749, R²=0.7416\n",
      "Trial 65, Horizon h=4, Fold 4: RMSE=2.5763, R²=0.7658\n",
      "Trial 65, Horizon h=5, Fold 1: RMSE=2.4231, R²=0.6946\n",
      "Trial 65, Horizon h=5, Fold 2: RMSE=2.7619, R²=0.6555\n",
      "Trial 65, Horizon h=5, Fold 3: RMSE=2.6182, R²=0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:28:34,466] Trial 65 finished with value: 2.3354326472044336 and parameters: {'learning_rate': 0.02234198823402022, 'max_depth': 3, 'gamma': 0.6701221614548535, 'reg_lambda': 5.773697088280228, 'reg_alpha': 1.4536481418238467, 'subsample': 0.5943496885781385, 'colsample_bytree': 0.5154996391923702, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65, Horizon h=5, Fold 4: RMSE=2.5963, R²=0.7625\n",
      "Trial 65 finished, overall mean RMSE across horizons=2.3354\n",
      "\n",
      "Trial 66, Horizon h=1, Fold 1: RMSE=1.7944, R²=0.8321\n",
      "Trial 66, Horizon h=1, Fold 2: RMSE=1.8103, R²=0.8537\n",
      "Trial 66, Horizon h=1, Fold 3: RMSE=1.6385, R²=0.8950\n",
      "Trial 66, Horizon h=1, Fold 4: RMSE=1.6804, R²=0.9001\n",
      "Trial 66, Horizon h=2, Fold 1: RMSE=2.1836, R²=0.7513\n",
      "Trial 66, Horizon h=2, Fold 2: RMSE=2.4173, R²=0.7382\n",
      "Trial 66, Horizon h=2, Fold 3: RMSE=2.2382, R²=0.8046\n",
      "Trial 66, Horizon h=2, Fold 4: RMSE=2.2392, R²=0.8230\n",
      "Trial 66, Horizon h=3, Fold 1: RMSE=2.3648, R²=0.7086\n",
      "Trial 66, Horizon h=3, Fold 2: RMSE=2.6323, R²=0.6885\n",
      "Trial 66, Horizon h=3, Fold 3: RMSE=2.5092, R²=0.7544\n",
      "Trial 66, Horizon h=3, Fold 4: RMSE=2.4746, R²=0.7839\n",
      "Trial 66, Horizon h=4, Fold 1: RMSE=2.3848, R²=0.7038\n",
      "Trial 66, Horizon h=4, Fold 2: RMSE=2.7309, R²=0.6637\n",
      "Trial 66, Horizon h=4, Fold 3: RMSE=2.6063, R²=0.7352\n",
      "Trial 66, Horizon h=4, Fold 4: RMSE=2.5837, R²=0.7645\n",
      "Trial 66, Horizon h=5, Fold 1: RMSE=2.4305, R²=0.6927\n",
      "Trial 66, Horizon h=5, Fold 2: RMSE=2.7297, R²=0.6635\n",
      "Trial 66, Horizon h=5, Fold 3: RMSE=2.6499, R²=0.7263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:28:55,009] Trial 66 finished with value: 2.334712180177006 and parameters: {'learning_rate': 0.012629501367406586, 'max_depth': 3, 'gamma': 0.5882190366709091, 'reg_lambda': 6.15588962723117, 'reg_alpha': 3.0513161888442903, 'subsample': 0.5878348235652638, 'colsample_bytree': 0.534121844691208, 'min_child_weight': 10}. Best is trial 34 with value: 2.3312497613741066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66, Horizon h=5, Fold 4: RMSE=2.5957, R²=0.7627\n",
      "Trial 66 finished, overall mean RMSE across horizons=2.3347\n",
      "\n",
      "Trial 67, Horizon h=1, Fold 1: RMSE=1.7878, R²=0.8334\n",
      "Trial 67, Horizon h=1, Fold 2: RMSE=1.8093, R²=0.8538\n",
      "Trial 67, Horizon h=1, Fold 3: RMSE=1.6281, R²=0.8963\n",
      "Trial 67, Horizon h=1, Fold 4: RMSE=1.6464, R²=0.9041\n",
      "Trial 67, Horizon h=2, Fold 1: RMSE=2.2037, R²=0.7467\n",
      "Trial 67, Horizon h=2, Fold 2: RMSE=2.4093, R²=0.7399\n",
      "Trial 67, Horizon h=2, Fold 3: RMSE=2.2249, R²=0.8069\n",
      "Trial 67, Horizon h=2, Fold 4: RMSE=2.2473, R²=0.8218\n",
      "Trial 67, Horizon h=3, Fold 1: RMSE=2.3970, R²=0.7006\n",
      "Trial 67, Horizon h=3, Fold 2: RMSE=2.6211, R²=0.6911\n",
      "Trial 67, Horizon h=3, Fold 3: RMSE=2.5030, R²=0.7556\n",
      "Trial 67, Horizon h=3, Fold 4: RMSE=2.4427, R²=0.7895\n",
      "Trial 67, Horizon h=4, Fold 1: RMSE=2.3877, R²=0.7031\n",
      "Trial 67, Horizon h=4, Fold 2: RMSE=2.7327, R²=0.6633\n",
      "Trial 67, Horizon h=4, Fold 3: RMSE=2.5706, R²=0.7424\n",
      "Trial 67, Horizon h=4, Fold 4: RMSE=2.5747, R²=0.7661\n",
      "Trial 67, Horizon h=5, Fold 1: RMSE=2.4198, R²=0.6954\n",
      "Trial 67, Horizon h=5, Fold 2: RMSE=2.7628, R²=0.6553\n",
      "Trial 67, Horizon h=5, Fold 3: RMSE=2.6271, R²=0.7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:29:10,254] Trial 67 finished with value: 2.33043015703495 and parameters: {'learning_rate': 0.022448409603057124, 'max_depth': 3, 'gamma': 0.8335260043507018, 'reg_lambda': 5.093383509545403, 'reg_alpha': 2.4483196335549935, 'subsample': 0.5754945313467182, 'colsample_bytree': 0.515163085757474, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67, Horizon h=5, Fold 4: RMSE=2.6127, R²=0.7595\n",
      "Trial 67 finished, overall mean RMSE across horizons=2.3304\n",
      "\n",
      "Trial 68, Horizon h=1, Fold 1: RMSE=1.8011, R²=0.8309\n",
      "Trial 68, Horizon h=1, Fold 2: RMSE=1.8317, R²=0.8502\n",
      "Trial 68, Horizon h=1, Fold 3: RMSE=1.6344, R²=0.8955\n",
      "Trial 68, Horizon h=1, Fold 4: RMSE=1.6521, R²=0.9035\n",
      "Trial 68, Horizon h=2, Fold 1: RMSE=2.1943, R²=0.7489\n",
      "Trial 68, Horizon h=2, Fold 2: RMSE=2.4007, R²=0.7418\n",
      "Trial 68, Horizon h=2, Fold 3: RMSE=2.2532, R²=0.8020\n",
      "Trial 68, Horizon h=2, Fold 4: RMSE=2.2519, R²=0.8210\n",
      "Trial 68, Horizon h=3, Fold 1: RMSE=2.3865, R²=0.7032\n",
      "Trial 68, Horizon h=3, Fold 2: RMSE=2.6426, R²=0.6860\n",
      "Trial 68, Horizon h=3, Fold 3: RMSE=2.5170, R²=0.7529\n",
      "Trial 68, Horizon h=3, Fold 4: RMSE=2.5047, R²=0.7786\n",
      "Trial 68, Horizon h=4, Fold 1: RMSE=2.3940, R²=0.7015\n",
      "Trial 68, Horizon h=4, Fold 2: RMSE=2.7598, R²=0.6566\n",
      "Trial 68, Horizon h=4, Fold 3: RMSE=2.5792, R²=0.7407\n",
      "Trial 68, Horizon h=4, Fold 4: RMSE=2.5611, R²=0.7686\n",
      "Trial 68, Horizon h=5, Fold 1: RMSE=2.4854, R²=0.6787\n",
      "Trial 68, Horizon h=5, Fold 2: RMSE=2.7894, R²=0.6487\n",
      "Trial 68, Horizon h=5, Fold 3: RMSE=2.6200, R²=0.7324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:29:24,687] Trial 68 finished with value: 2.3432524166755644 and parameters: {'learning_rate': 0.0214980663171764, 'max_depth': 3, 'gamma': 0.4704014408414513, 'reg_lambda': 3.898697883671939, 'reg_alpha': 0.8177142790103948, 'subsample': 0.5391617635648596, 'colsample_bytree': 0.5342968271971721, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68, Horizon h=5, Fold 4: RMSE=2.6060, R²=0.7608\n",
      "Trial 68 finished, overall mean RMSE across horizons=2.3433\n",
      "\n",
      "Trial 69, Horizon h=1, Fold 1: RMSE=1.9167, R²=0.8085\n",
      "Trial 69, Horizon h=1, Fold 2: RMSE=1.9165, R²=0.8360\n",
      "Trial 69, Horizon h=1, Fold 3: RMSE=1.5830, R²=0.9020\n",
      "Trial 69, Horizon h=1, Fold 4: RMSE=1.6741, R²=0.9009\n",
      "Trial 69, Horizon h=2, Fold 1: RMSE=2.2296, R²=0.7407\n",
      "Trial 69, Horizon h=2, Fold 2: RMSE=2.4141, R²=0.7389\n",
      "Trial 69, Horizon h=2, Fold 3: RMSE=2.2267, R²=0.8066\n",
      "Trial 69, Horizon h=2, Fold 4: RMSE=2.2210, R²=0.8259\n",
      "Trial 69, Horizon h=3, Fold 1: RMSE=2.3922, R²=0.7018\n",
      "Trial 69, Horizon h=3, Fold 2: RMSE=2.6316, R²=0.6886\n",
      "Trial 69, Horizon h=3, Fold 3: RMSE=2.4869, R²=0.7587\n",
      "Trial 69, Horizon h=3, Fold 4: RMSE=2.4820, R²=0.7827\n",
      "Trial 69, Horizon h=4, Fold 1: RMSE=2.4051, R²=0.6987\n",
      "Trial 69, Horizon h=4, Fold 2: RMSE=2.7004, R²=0.6712\n",
      "Trial 69, Horizon h=4, Fold 3: RMSE=2.5373, R²=0.7491\n",
      "Trial 69, Horizon h=4, Fold 4: RMSE=2.5870, R²=0.7639\n",
      "Trial 69, Horizon h=5, Fold 1: RMSE=2.4958, R²=0.6760\n",
      "Trial 69, Horizon h=5, Fold 2: RMSE=2.8023, R²=0.6454\n",
      "Trial 69, Horizon h=5, Fold 3: RMSE=2.7003, R²=0.7158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:29:32,499] Trial 69 finished with value: 2.353221579437726 and parameters: {'learning_rate': 0.10132132228728696, 'max_depth': 3, 'gamma': 0.6881305473804856, 'reg_lambda': 5.252883360343558, 'reg_alpha': 2.190744718537964, 'subsample': 0.5713687758803997, 'colsample_bytree': 0.5130557694581129, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69, Horizon h=5, Fold 4: RMSE=2.6619, R²=0.7504\n",
      "Trial 69 finished, overall mean RMSE across horizons=2.3532\n",
      "\n",
      "Trial 70, Horizon h=1, Fold 1: RMSE=1.7696, R²=0.8368\n",
      "Trial 70, Horizon h=1, Fold 2: RMSE=1.8064, R²=0.8543\n",
      "Trial 70, Horizon h=1, Fold 3: RMSE=1.6848, R²=0.8890\n",
      "Trial 70, Horizon h=1, Fold 4: RMSE=1.7231, R²=0.8950\n",
      "Trial 70, Horizon h=2, Fold 1: RMSE=2.1928, R²=0.7492\n",
      "Trial 70, Horizon h=2, Fold 2: RMSE=2.4206, R²=0.7375\n",
      "Trial 70, Horizon h=2, Fold 3: RMSE=2.3043, R²=0.7929\n",
      "Trial 70, Horizon h=2, Fold 4: RMSE=2.3086, R²=0.8119\n",
      "Trial 70, Horizon h=3, Fold 1: RMSE=2.3611, R²=0.7095\n",
      "Trial 70, Horizon h=3, Fold 2: RMSE=2.6292, R²=0.6892\n",
      "Trial 70, Horizon h=3, Fold 3: RMSE=2.5638, R²=0.7436\n",
      "Trial 70, Horizon h=3, Fold 4: RMSE=2.5472, R²=0.7711\n",
      "Trial 70, Horizon h=4, Fold 1: RMSE=2.4238, R²=0.6940\n",
      "Trial 70, Horizon h=4, Fold 2: RMSE=2.6821, R²=0.6757\n",
      "Trial 70, Horizon h=4, Fold 3: RMSE=2.6006, R²=0.7364\n",
      "Trial 70, Horizon h=4, Fold 4: RMSE=2.6235, R²=0.7572\n",
      "Trial 70, Horizon h=5, Fold 1: RMSE=2.4891, R²=0.6777\n",
      "Trial 70, Horizon h=5, Fold 2: RMSE=2.7306, R²=0.6633\n",
      "Trial 70, Horizon h=5, Fold 3: RMSE=2.7152, R²=0.7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:29:53,130] Trial 70 finished with value: 2.365179976227074 and parameters: {'learning_rate': 0.0263968607047267, 'max_depth': 5, 'gamma': 0.7878279759513704, 'reg_lambda': 4.332901985046381, 'reg_alpha': 3.4851875385555093, 'subsample': 0.5163963836475098, 'colsample_bytree': 0.5785074488125936, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 70, Horizon h=5, Fold 4: RMSE=2.7271, R²=0.7380\n",
      "Trial 70 finished, overall mean RMSE across horizons=2.3652\n",
      "\n",
      "Trial 71, Horizon h=1, Fold 1: RMSE=1.8249, R²=0.8264\n",
      "Trial 71, Horizon h=1, Fold 2: RMSE=1.8528, R²=0.8467\n",
      "Trial 71, Horizon h=1, Fold 3: RMSE=1.6279, R²=0.8963\n",
      "Trial 71, Horizon h=1, Fold 4: RMSE=1.6564, R²=0.9030\n",
      "Trial 71, Horizon h=2, Fold 1: RMSE=2.2105, R²=0.7452\n",
      "Trial 71, Horizon h=2, Fold 2: RMSE=2.3936, R²=0.7433\n",
      "Trial 71, Horizon h=2, Fold 3: RMSE=2.2471, R²=0.8031\n",
      "Trial 71, Horizon h=2, Fold 4: RMSE=2.2376, R²=0.8233\n",
      "Trial 71, Horizon h=3, Fold 1: RMSE=2.3752, R²=0.7060\n",
      "Trial 71, Horizon h=3, Fold 2: RMSE=2.6569, R²=0.6826\n",
      "Trial 71, Horizon h=3, Fold 3: RMSE=2.4916, R²=0.7578\n",
      "Trial 71, Horizon h=3, Fold 4: RMSE=2.4691, R²=0.7849\n",
      "Trial 71, Horizon h=4, Fold 1: RMSE=2.3844, R²=0.7039\n",
      "Trial 71, Horizon h=4, Fold 2: RMSE=2.7182, R²=0.6669\n",
      "Trial 71, Horizon h=4, Fold 3: RMSE=2.5579, R²=0.7450\n",
      "Trial 71, Horizon h=4, Fold 4: RMSE=2.5959, R²=0.7622\n",
      "Trial 71, Horizon h=5, Fold 1: RMSE=2.4199, R²=0.6954\n",
      "Trial 71, Horizon h=5, Fold 2: RMSE=2.7511, R²=0.6582\n",
      "Trial 71, Horizon h=5, Fold 3: RMSE=2.6231, R²=0.7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:30:10,281] Trial 71 finished with value: 2.335600021021758 and parameters: {'learning_rate': 0.018688198988004424, 'max_depth': 3, 'gamma': 0.8368842250130735, 'reg_lambda': 5.522189341988906, 'reg_alpha': 2.438421482474838, 'subsample': 0.6149406890814703, 'colsample_bytree': 0.5148402550950774, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 71, Horizon h=5, Fold 4: RMSE=2.6180, R²=0.7586\n",
      "Trial 71 finished, overall mean RMSE across horizons=2.3356\n",
      "\n",
      "Trial 72, Horizon h=1, Fold 1: RMSE=1.8191, R²=0.8275\n",
      "Trial 72, Horizon h=1, Fold 2: RMSE=1.8827, R²=0.8417\n",
      "Trial 72, Horizon h=1, Fold 3: RMSE=1.6179, R²=0.8976\n",
      "Trial 72, Horizon h=1, Fold 4: RMSE=1.6961, R²=0.8983\n",
      "Trial 72, Horizon h=2, Fold 1: RMSE=2.2445, R²=0.7373\n",
      "Trial 72, Horizon h=2, Fold 2: RMSE=2.4523, R²=0.7306\n",
      "Trial 72, Horizon h=2, Fold 3: RMSE=2.2248, R²=0.8070\n",
      "Trial 72, Horizon h=2, Fold 4: RMSE=2.2629, R²=0.8193\n",
      "Trial 72, Horizon h=3, Fold 1: RMSE=2.3972, R²=0.7005\n",
      "Trial 72, Horizon h=3, Fold 2: RMSE=2.7135, R²=0.6690\n",
      "Trial 72, Horizon h=3, Fold 3: RMSE=2.5263, R²=0.7510\n",
      "Trial 72, Horizon h=3, Fold 4: RMSE=2.4782, R²=0.7833\n",
      "Trial 72, Horizon h=4, Fold 1: RMSE=2.4053, R²=0.6987\n",
      "Trial 72, Horizon h=4, Fold 2: RMSE=2.7606, R²=0.6564\n",
      "Trial 72, Horizon h=4, Fold 3: RMSE=2.5999, R²=0.7365\n",
      "Trial 72, Horizon h=4, Fold 4: RMSE=2.5643, R²=0.7680\n",
      "Trial 72, Horizon h=5, Fold 1: RMSE=2.4150, R²=0.6966\n",
      "Trial 72, Horizon h=5, Fold 2: RMSE=2.7522, R²=0.6580\n",
      "Trial 72, Horizon h=5, Fold 3: RMSE=2.6723, R²=0.7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:30:24,089] Trial 72 finished with value: 2.3537521535722528 and parameters: {'learning_rate': 0.02407223974840203, 'max_depth': 3, 'gamma': 0.7403800224000066, 'reg_lambda': 6.309434953301754, 'reg_alpha': 1.9472604262370063, 'subsample': 0.8839426080260153, 'colsample_bytree': 0.511245275964663, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 72, Horizon h=5, Fold 4: RMSE=2.5898, R²=0.7637\n",
      "Trial 72 finished, overall mean RMSE across horizons=2.3538\n",
      "\n",
      "Trial 73, Horizon h=1, Fold 1: RMSE=1.8131, R²=0.8286\n",
      "Trial 73, Horizon h=1, Fold 2: RMSE=1.8495, R²=0.8473\n",
      "Trial 73, Horizon h=1, Fold 3: RMSE=1.6204, R²=0.8973\n",
      "Trial 73, Horizon h=1, Fold 4: RMSE=1.6712, R²=0.9012\n",
      "Trial 73, Horizon h=2, Fold 1: RMSE=2.1975, R²=0.7482\n",
      "Trial 73, Horizon h=2, Fold 2: RMSE=2.4186, R²=0.7379\n",
      "Trial 73, Horizon h=2, Fold 3: RMSE=2.2372, R²=0.8048\n",
      "Trial 73, Horizon h=2, Fold 4: RMSE=2.2414, R²=0.8227\n",
      "Trial 73, Horizon h=3, Fold 1: RMSE=2.3594, R²=0.7099\n",
      "Trial 73, Horizon h=3, Fold 2: RMSE=2.6365, R²=0.6875\n",
      "Trial 73, Horizon h=3, Fold 3: RMSE=2.5176, R²=0.7527\n",
      "Trial 73, Horizon h=3, Fold 4: RMSE=2.4763, R²=0.7836\n",
      "Trial 73, Horizon h=4, Fold 1: RMSE=2.3879, R²=0.7030\n",
      "Trial 73, Horizon h=4, Fold 2: RMSE=2.7140, R²=0.6679\n",
      "Trial 73, Horizon h=4, Fold 3: RMSE=2.5904, R²=0.7385\n",
      "Trial 73, Horizon h=4, Fold 4: RMSE=2.5806, R²=0.7651\n",
      "Trial 73, Horizon h=5, Fold 1: RMSE=2.4302, R²=0.6928\n",
      "Trial 73, Horizon h=5, Fold 2: RMSE=2.7436, R²=0.6601\n",
      "Trial 73, Horizon h=5, Fold 3: RMSE=2.6404, R²=0.7282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:30:41,948] Trial 73 finished with value: 2.3356213770194714 and parameters: {'learning_rate': 0.016052529976979667, 'max_depth': 3, 'gamma': 0.7945368298311157, 'reg_lambda': 6.7132959468224005, 'reg_alpha': 2.5209340915444365, 'subsample': 0.6376340179835676, 'colsample_bytree': 0.5351793265687708, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 73, Horizon h=5, Fold 4: RMSE=2.5865, R²=0.7643\n",
      "Trial 73 finished, overall mean RMSE across horizons=2.3356\n",
      "\n",
      "Trial 74, Horizon h=1, Fold 1: RMSE=1.8138, R²=0.8285\n",
      "Trial 74, Horizon h=1, Fold 2: RMSE=1.8788, R²=0.8424\n",
      "Trial 74, Horizon h=1, Fold 3: RMSE=1.6418, R²=0.8946\n",
      "Trial 74, Horizon h=1, Fold 4: RMSE=1.6782, R²=0.9004\n",
      "Trial 74, Horizon h=2, Fold 1: RMSE=2.1844, R²=0.7512\n",
      "Trial 74, Horizon h=2, Fold 2: RMSE=2.4058, R²=0.7407\n",
      "Trial 74, Horizon h=2, Fold 3: RMSE=2.2352, R²=0.8052\n",
      "Trial 74, Horizon h=2, Fold 4: RMSE=2.2402, R²=0.8229\n",
      "Trial 74, Horizon h=3, Fold 1: RMSE=2.3741, R²=0.7063\n",
      "Trial 74, Horizon h=3, Fold 2: RMSE=2.6344, R²=0.6880\n",
      "Trial 74, Horizon h=3, Fold 3: RMSE=2.5011, R²=0.7560\n",
      "Trial 74, Horizon h=3, Fold 4: RMSE=2.4623, R²=0.7861\n",
      "Trial 74, Horizon h=4, Fold 1: RMSE=2.3839, R²=0.7040\n",
      "Trial 74, Horizon h=4, Fold 2: RMSE=2.7152, R²=0.6676\n",
      "Trial 74, Horizon h=4, Fold 3: RMSE=2.5756, R²=0.7414\n",
      "Trial 74, Horizon h=4, Fold 4: RMSE=2.5709, R²=0.7668\n",
      "Trial 74, Horizon h=5, Fold 1: RMSE=2.4130, R²=0.6971\n",
      "Trial 74, Horizon h=5, Fold 2: RMSE=2.7729, R²=0.6528\n",
      "Trial 74, Horizon h=5, Fold 3: RMSE=2.6312, R²=0.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:30:53,746] Trial 74 finished with value: 2.3357402594196603 and parameters: {'learning_rate': 0.03550861392510341, 'max_depth': 3, 'gamma': 0.817535467975585, 'reg_lambda': 5.272164019107117, 'reg_alpha': 4.771774477977567, 'subsample': 0.6091031177590075, 'colsample_bytree': 0.5249310592037207, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 74, Horizon h=5, Fold 4: RMSE=2.6021, R²=0.7615\n",
      "Trial 74 finished, overall mean RMSE across horizons=2.3357\n",
      "\n",
      "Trial 75, Horizon h=1, Fold 1: RMSE=1.8266, R²=0.8261\n",
      "Trial 75, Horizon h=1, Fold 2: RMSE=1.7936, R²=0.8563\n",
      "Trial 75, Horizon h=1, Fold 3: RMSE=1.6241, R²=0.8968\n",
      "Trial 75, Horizon h=1, Fold 4: RMSE=1.6497, R²=0.9037\n",
      "Trial 75, Horizon h=2, Fold 1: RMSE=2.2048, R²=0.7465\n",
      "Trial 75, Horizon h=2, Fold 2: RMSE=2.3934, R²=0.7433\n",
      "Trial 75, Horizon h=2, Fold 3: RMSE=2.2370, R²=0.8048\n",
      "Trial 75, Horizon h=2, Fold 4: RMSE=2.2323, R²=0.8241\n",
      "Trial 75, Horizon h=3, Fold 1: RMSE=2.3824, R²=0.7042\n",
      "Trial 75, Horizon h=3, Fold 2: RMSE=2.6206, R²=0.6912\n",
      "Trial 75, Horizon h=3, Fold 3: RMSE=2.5110, R²=0.7540\n",
      "Trial 75, Horizon h=3, Fold 4: RMSE=2.4898, R²=0.7813\n",
      "Trial 75, Horizon h=4, Fold 1: RMSE=2.3843, R²=0.7039\n",
      "Trial 75, Horizon h=4, Fold 2: RMSE=2.7366, R²=0.6623\n",
      "Trial 75, Horizon h=4, Fold 3: RMSE=2.5567, R²=0.7452\n",
      "Trial 75, Horizon h=4, Fold 4: RMSE=2.5958, R²=0.7623\n",
      "Trial 75, Horizon h=5, Fold 1: RMSE=2.4479, R²=0.6883\n",
      "Trial 75, Horizon h=5, Fold 2: RMSE=2.7480, R²=0.6590\n",
      "Trial 75, Horizon h=5, Fold 3: RMSE=2.6239, R²=0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:31:09,473] Trial 75 finished with value: 2.3343996895075847 and parameters: {'learning_rate': 0.020300905965772754, 'max_depth': 3, 'gamma': 0.8632184602542332, 'reg_lambda': 5.981464575028793, 'reg_alpha': 1.7178282307927564, 'subsample': 0.565042397163866, 'colsample_bytree': 0.5037546289710307, 'min_child_weight': 9}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 75, Horizon h=5, Fold 4: RMSE=2.6293, R²=0.7565\n",
      "Trial 75 finished, overall mean RMSE across horizons=2.3344\n",
      "\n",
      "Trial 76, Horizon h=1, Fold 1: RMSE=1.7993, R²=0.8312\n",
      "Trial 76, Horizon h=1, Fold 2: RMSE=1.8062, R²=0.8543\n",
      "Trial 76, Horizon h=1, Fold 3: RMSE=1.6358, R²=0.8953\n",
      "Trial 76, Horizon h=1, Fold 4: RMSE=1.6731, R²=0.9010\n",
      "Trial 76, Horizon h=2, Fold 1: RMSE=2.1931, R²=0.7492\n",
      "Trial 76, Horizon h=2, Fold 2: RMSE=2.4201, R²=0.7376\n",
      "Trial 76, Horizon h=2, Fold 3: RMSE=2.2546, R²=0.8017\n",
      "Trial 76, Horizon h=2, Fold 4: RMSE=2.2323, R²=0.8241\n",
      "Trial 76, Horizon h=3, Fold 1: RMSE=2.3786, R²=0.7052\n",
      "Trial 76, Horizon h=3, Fold 2: RMSE=2.6561, R²=0.6828\n",
      "Trial 76, Horizon h=3, Fold 3: RMSE=2.5137, R²=0.7535\n",
      "Trial 76, Horizon h=3, Fold 4: RMSE=2.4807, R²=0.7829\n",
      "Trial 76, Horizon h=4, Fold 1: RMSE=2.3951, R²=0.7012\n",
      "Trial 76, Horizon h=4, Fold 2: RMSE=2.7335, R²=0.6631\n",
      "Trial 76, Horizon h=4, Fold 3: RMSE=2.5851, R²=0.7395\n",
      "Trial 76, Horizon h=4, Fold 4: RMSE=2.5659, R²=0.7677\n",
      "Trial 76, Horizon h=5, Fold 1: RMSE=2.4441, R²=0.6893\n",
      "Trial 76, Horizon h=5, Fold 2: RMSE=2.7534, R²=0.6577\n",
      "Trial 76, Horizon h=5, Fold 3: RMSE=2.6481, R²=0.7266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:31:28,724] Trial 76 finished with value: 2.337613506755855 and parameters: {'learning_rate': 0.013278427409623718, 'max_depth': 3, 'gamma': 0.8926709305595404, 'reg_lambda': 4.851862093248823, 'reg_alpha': 3.081889032829919, 'subsample': 0.5955978176524797, 'colsample_bytree': 0.5392224950987344, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 76, Horizon h=5, Fold 4: RMSE=2.5836, R²=0.7649\n",
      "Trial 76 finished, overall mean RMSE across horizons=2.3376\n",
      "\n",
      "Trial 77, Horizon h=1, Fold 1: RMSE=1.8224, R²=0.8269\n",
      "Trial 77, Horizon h=1, Fold 2: RMSE=1.8554, R²=0.8463\n",
      "Trial 77, Horizon h=1, Fold 3: RMSE=1.6420, R²=0.8945\n",
      "Trial 77, Horizon h=1, Fold 4: RMSE=1.6809, R²=0.9001\n",
      "Trial 77, Horizon h=2, Fold 1: RMSE=2.1836, R²=0.7513\n",
      "Trial 77, Horizon h=2, Fold 2: RMSE=2.4142, R²=0.7389\n",
      "Trial 77, Horizon h=2, Fold 3: RMSE=2.2471, R²=0.8031\n",
      "Trial 77, Horizon h=2, Fold 4: RMSE=2.2550, R²=0.8205\n",
      "Trial 77, Horizon h=3, Fold 1: RMSE=2.3462, R²=0.7131\n",
      "Trial 77, Horizon h=3, Fold 2: RMSE=2.6415, R²=0.6863\n",
      "Trial 77, Horizon h=3, Fold 3: RMSE=2.5272, R²=0.7508\n",
      "Trial 77, Horizon h=3, Fold 4: RMSE=2.4843, R²=0.7823\n",
      "Trial 77, Horizon h=4, Fold 1: RMSE=2.3772, R²=0.7057\n",
      "Trial 77, Horizon h=4, Fold 2: RMSE=2.7252, R²=0.6652\n",
      "Trial 77, Horizon h=4, Fold 3: RMSE=2.6172, R²=0.7330\n",
      "Trial 77, Horizon h=4, Fold 4: RMSE=2.5922, R²=0.7629\n",
      "Trial 77, Horizon h=5, Fold 1: RMSE=2.3881, R²=0.7033\n",
      "Trial 77, Horizon h=5, Fold 2: RMSE=2.7523, R²=0.6579\n",
      "Trial 77, Horizon h=5, Fold 3: RMSE=2.6198, R²=0.7324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:31:41,425] Trial 77 finished with value: 2.3408215125627345 and parameters: {'learning_rate': 0.02955098701987774, 'max_depth': 3, 'gamma': 0.9676996022256954, 'reg_lambda': 6.908473249677816, 'reg_alpha': 4.203671673622303, 'subsample': 0.644089823433586, 'colsample_bytree': 0.5616623197622422, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 77, Horizon h=5, Fold 4: RMSE=2.6447, R²=0.7536\n",
      "Trial 77 finished, overall mean RMSE across horizons=2.3408\n",
      "\n",
      "Trial 78, Horizon h=1, Fold 1: RMSE=1.9411, R²=0.8036\n",
      "Trial 78, Horizon h=1, Fold 2: RMSE=1.8532, R²=0.8466\n",
      "Trial 78, Horizon h=1, Fold 3: RMSE=1.6967, R²=0.8874\n",
      "Trial 78, Horizon h=1, Fold 4: RMSE=1.7246, R²=0.8948\n",
      "Trial 78, Horizon h=2, Fold 1: RMSE=2.2662, R²=0.7322\n",
      "Trial 78, Horizon h=2, Fold 2: RMSE=2.3850, R²=0.7451\n",
      "Trial 78, Horizon h=2, Fold 3: RMSE=2.3295, R²=0.7884\n",
      "Trial 78, Horizon h=2, Fold 4: RMSE=2.2455, R²=0.8221\n",
      "Trial 78, Horizon h=3, Fold 1: RMSE=2.4554, R²=0.6858\n",
      "Trial 78, Horizon h=3, Fold 2: RMSE=2.6716, R²=0.6791\n",
      "Trial 78, Horizon h=3, Fold 3: RMSE=2.5892, R²=0.7385\n",
      "Trial 78, Horizon h=3, Fold 4: RMSE=2.4141, R²=0.7944\n",
      "Trial 78, Horizon h=4, Fold 1: RMSE=2.4900, R²=0.6771\n",
      "Trial 78, Horizon h=4, Fold 2: RMSE=2.8190, R²=0.6417\n",
      "Trial 78, Horizon h=4, Fold 3: RMSE=2.7162, R²=0.7125\n",
      "Trial 78, Horizon h=4, Fold 4: RMSE=2.5089, R²=0.7779\n",
      "Trial 78, Horizon h=5, Fold 1: RMSE=2.4480, R²=0.6883\n",
      "Trial 78, Horizon h=5, Fold 2: RMSE=2.6650, R²=0.6793\n",
      "Trial 78, Horizon h=5, Fold 3: RMSE=2.7607, R²=0.7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:31:48,529] Trial 78 finished with value: 2.381410660136188 and parameters: {'learning_rate': 0.20792176565315107, 'max_depth': 3, 'gamma': 0.021342338029004537, 'reg_lambda': 3.239926419485013, 'reg_alpha': 5.33517675260279, 'subsample': 0.5863974019363549, 'colsample_bytree': 0.7907385470296596, 'min_child_weight': 9}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 78, Horizon h=5, Fold 4: RMSE=2.6480, R²=0.7530\n",
      "Trial 78 finished, overall mean RMSE across horizons=2.3814\n",
      "\n",
      "Trial 79, Horizon h=1, Fold 1: RMSE=1.7817, R²=0.8345\n",
      "Trial 79, Horizon h=1, Fold 2: RMSE=1.8366, R²=0.8494\n",
      "Trial 79, Horizon h=1, Fold 3: RMSE=1.6886, R²=0.8885\n",
      "Trial 79, Horizon h=1, Fold 4: RMSE=1.7358, R²=0.8934\n",
      "Trial 79, Horizon h=2, Fold 1: RMSE=2.2130, R²=0.7446\n",
      "Trial 79, Horizon h=2, Fold 2: RMSE=2.4337, R²=0.7346\n",
      "Trial 79, Horizon h=2, Fold 3: RMSE=2.2987, R²=0.7939\n",
      "Trial 79, Horizon h=2, Fold 4: RMSE=2.2682, R²=0.8184\n",
      "Trial 79, Horizon h=3, Fold 1: RMSE=2.3978, R²=0.7004\n",
      "Trial 79, Horizon h=3, Fold 2: RMSE=2.6856, R²=0.6757\n",
      "Trial 79, Horizon h=3, Fold 3: RMSE=2.5698, R²=0.7424\n",
      "Trial 79, Horizon h=3, Fold 4: RMSE=2.5393, R²=0.7725\n",
      "Trial 79, Horizon h=4, Fold 1: RMSE=2.4277, R²=0.6931\n",
      "Trial 79, Horizon h=4, Fold 2: RMSE=2.7000, R²=0.6713\n",
      "Trial 79, Horizon h=4, Fold 3: RMSE=2.6585, R²=0.7245\n",
      "Trial 79, Horizon h=4, Fold 4: RMSE=2.6170, R²=0.7584\n",
      "Trial 79, Horizon h=5, Fold 1: RMSE=2.4821, R²=0.6795\n",
      "Trial 79, Horizon h=5, Fold 2: RMSE=2.7651, R²=0.6548\n",
      "Trial 79, Horizon h=5, Fold 3: RMSE=2.7199, R²=0.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:32:21,757] Trial 79 finished with value: 2.37341856256372 and parameters: {'learning_rate': 0.018073496584961712, 'max_depth': 6, 'gamma': 0.7650990604268094, 'reg_lambda': 5.7415225584246254, 'reg_alpha': 1.2158312017715915, 'subsample': 0.67626484135075, 'colsample_bytree': 0.5437329531085683, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 79, Horizon h=5, Fold 4: RMSE=2.6494, R²=0.7527\n",
      "Trial 79 finished, overall mean RMSE across horizons=2.3734\n",
      "\n",
      "Trial 80, Horizon h=1, Fold 1: RMSE=1.7707, R²=0.8365\n",
      "Trial 80, Horizon h=1, Fold 2: RMSE=1.7998, R²=0.8554\n",
      "Trial 80, Horizon h=1, Fold 3: RMSE=1.6456, R²=0.8941\n",
      "Trial 80, Horizon h=1, Fold 4: RMSE=1.6965, R²=0.8982\n",
      "Trial 80, Horizon h=2, Fold 1: RMSE=2.1984, R²=0.7479\n",
      "Trial 80, Horizon h=2, Fold 2: RMSE=2.3934, R²=0.7434\n",
      "Trial 80, Horizon h=2, Fold 3: RMSE=2.3024, R²=0.7933\n",
      "Trial 80, Horizon h=2, Fold 4: RMSE=2.2363, R²=0.8235\n",
      "Trial 80, Horizon h=3, Fold 1: RMSE=2.3782, R²=0.7053\n",
      "Trial 80, Horizon h=3, Fold 2: RMSE=2.6407, R²=0.6865\n",
      "Trial 80, Horizon h=3, Fold 3: RMSE=2.5464, R²=0.7471\n",
      "Trial 80, Horizon h=3, Fold 4: RMSE=2.4594, R²=0.7866\n",
      "Trial 80, Horizon h=4, Fold 1: RMSE=2.4255, R²=0.6936\n",
      "Trial 80, Horizon h=4, Fold 2: RMSE=2.7258, R²=0.6650\n",
      "Trial 80, Horizon h=4, Fold 3: RMSE=2.6314, R²=0.7301\n",
      "Trial 80, Horizon h=4, Fold 4: RMSE=2.5708, R²=0.7668\n",
      "Trial 80, Horizon h=5, Fold 1: RMSE=2.4931, R²=0.6767\n",
      "Trial 80, Horizon h=5, Fold 2: RMSE=2.7396, R²=0.6611\n",
      "Trial 80, Horizon h=5, Fold 3: RMSE=2.6872, R²=0.7185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:32:33,366] Trial 80 finished with value: 2.348629724949195 and parameters: {'learning_rate': 0.04274428064538858, 'max_depth': 3, 'gamma': 0.843993169580633, 'reg_lambda': 6.108144845433669, 'reg_alpha': 7.888002276293949, 'subsample': 0.5408733091675682, 'colsample_bytree': 0.6096037103722574, 'min_child_weight': 9}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 80, Horizon h=5, Fold 4: RMSE=2.6313, R²=0.7561\n",
      "Trial 80 finished, overall mean RMSE across horizons=2.3486\n",
      "\n",
      "Trial 81, Horizon h=1, Fold 1: RMSE=1.8089, R²=0.8294\n",
      "Trial 81, Horizon h=1, Fold 2: RMSE=1.8139, R²=0.8531\n",
      "Trial 81, Horizon h=1, Fold 3: RMSE=1.6255, R²=0.8966\n",
      "Trial 81, Horizon h=1, Fold 4: RMSE=1.6399, R²=0.9049\n",
      "Trial 81, Horizon h=2, Fold 1: RMSE=2.2030, R²=0.7469\n",
      "Trial 81, Horizon h=2, Fold 2: RMSE=2.4052, R²=0.7408\n",
      "Trial 81, Horizon h=2, Fold 3: RMSE=2.2354, R²=0.8051\n",
      "Trial 81, Horizon h=2, Fold 4: RMSE=2.2428, R²=0.8225\n",
      "Trial 81, Horizon h=3, Fold 1: RMSE=2.3758, R²=0.7059\n",
      "Trial 81, Horizon h=3, Fold 2: RMSE=2.6308, R²=0.6888\n",
      "Trial 81, Horizon h=3, Fold 3: RMSE=2.5032, R²=0.7556\n",
      "Trial 81, Horizon h=3, Fold 4: RMSE=2.4790, R²=0.7832\n",
      "Trial 81, Horizon h=4, Fold 1: RMSE=2.4009, R²=0.6998\n",
      "Trial 81, Horizon h=4, Fold 2: RMSE=2.7299, R²=0.6640\n",
      "Trial 81, Horizon h=4, Fold 3: RMSE=2.5770, R²=0.7412\n",
      "Trial 81, Horizon h=4, Fold 4: RMSE=2.6143, R²=0.7589\n",
      "Trial 81, Horizon h=5, Fold 1: RMSE=2.4386, R²=0.6906\n",
      "Trial 81, Horizon h=5, Fold 2: RMSE=2.7242, R²=0.6649\n",
      "Trial 81, Horizon h=5, Fold 3: RMSE=2.6254, R²=0.7313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:32:50,304] Trial 81 finished with value: 2.335102724819729 and parameters: {'learning_rate': 0.016605718055631203, 'max_depth': 3, 'gamma': 0.8532005777015574, 'reg_lambda': 5.898009995905153, 'reg_alpha': 1.8267516355059426, 'subsample': 0.5664734818468153, 'colsample_bytree': 0.5038828330749263, 'min_child_weight': 9}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 81, Horizon h=5, Fold 4: RMSE=2.6283, R²=0.7567\n",
      "Trial 81 finished, overall mean RMSE across horizons=2.3351\n",
      "\n",
      "Trial 82, Horizon h=1, Fold 1: RMSE=1.7954, R²=0.8320\n",
      "Trial 82, Horizon h=1, Fold 2: RMSE=1.8170, R²=0.8526\n",
      "Trial 82, Horizon h=1, Fold 3: RMSE=1.6503, R²=0.8935\n",
      "Trial 82, Horizon h=1, Fold 4: RMSE=1.6550, R²=0.9031\n",
      "Trial 82, Horizon h=2, Fold 1: RMSE=2.2059, R²=0.7462\n",
      "Trial 82, Horizon h=2, Fold 2: RMSE=2.4040, R²=0.7411\n",
      "Trial 82, Horizon h=2, Fold 3: RMSE=2.2401, R²=0.8043\n",
      "Trial 82, Horizon h=2, Fold 4: RMSE=2.2404, R²=0.8229\n",
      "Trial 82, Horizon h=3, Fold 1: RMSE=2.3811, R²=0.7045\n",
      "Trial 82, Horizon h=3, Fold 2: RMSE=2.6142, R²=0.6927\n",
      "Trial 82, Horizon h=3, Fold 3: RMSE=2.5032, R²=0.7555\n",
      "Trial 82, Horizon h=3, Fold 4: RMSE=2.4925, R²=0.7808\n",
      "Trial 82, Horizon h=4, Fold 1: RMSE=2.3882, R²=0.7030\n",
      "Trial 82, Horizon h=4, Fold 2: RMSE=2.7159, R²=0.6674\n",
      "Trial 82, Horizon h=4, Fold 3: RMSE=2.5660, R²=0.7434\n",
      "Trial 82, Horizon h=4, Fold 4: RMSE=2.5956, R²=0.7623\n",
      "Trial 82, Horizon h=5, Fold 1: RMSE=2.4458, R²=0.6888\n",
      "Trial 82, Horizon h=5, Fold 2: RMSE=2.7489, R²=0.6588\n",
      "Trial 82, Horizon h=5, Fold 3: RMSE=2.6266, R²=0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:33:06,239] Trial 82 finished with value: 2.3365502169625083 and parameters: {'learning_rate': 0.01994311841362933, 'max_depth': 3, 'gamma': 0.886566763511377, 'reg_lambda': 6.644636381202613, 'reg_alpha': 1.5605576424751184, 'subsample': 0.5586352560907758, 'colsample_bytree': 0.521643379352006, 'min_child_weight': 9}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82, Horizon h=5, Fold 4: RMSE=2.6449, R²=0.7536\n",
      "Trial 82 finished, overall mean RMSE across horizons=2.3366\n",
      "\n",
      "Trial 83, Horizon h=1, Fold 1: RMSE=1.8089, R²=0.8294\n",
      "Trial 83, Horizon h=1, Fold 2: RMSE=1.8069, R²=0.8542\n",
      "Trial 83, Horizon h=1, Fold 3: RMSE=1.6311, R²=0.8959\n",
      "Trial 83, Horizon h=1, Fold 4: RMSE=1.6756, R²=0.9007\n",
      "Trial 83, Horizon h=2, Fold 1: RMSE=2.2038, R²=0.7467\n",
      "Trial 83, Horizon h=2, Fold 2: RMSE=2.4089, R²=0.7400\n",
      "Trial 83, Horizon h=2, Fold 3: RMSE=2.2377, R²=0.8047\n",
      "Trial 83, Horizon h=2, Fold 4: RMSE=2.2550, R²=0.8205\n",
      "Trial 83, Horizon h=3, Fold 1: RMSE=2.3945, R²=0.7012\n",
      "Trial 83, Horizon h=3, Fold 2: RMSE=2.6524, R²=0.6837\n",
      "Trial 83, Horizon h=3, Fold 3: RMSE=2.5152, R²=0.7532\n",
      "Trial 83, Horizon h=3, Fold 4: RMSE=2.4702, R²=0.7847\n",
      "Trial 83, Horizon h=4, Fold 1: RMSE=2.3767, R²=0.7058\n",
      "Trial 83, Horizon h=4, Fold 2: RMSE=2.7147, R²=0.6677\n",
      "Trial 83, Horizon h=4, Fold 3: RMSE=2.5510, R²=0.7464\n",
      "Trial 83, Horizon h=4, Fold 4: RMSE=2.5824, R²=0.7647\n",
      "Trial 83, Horizon h=5, Fold 1: RMSE=2.4309, R²=0.6926\n",
      "Trial 83, Horizon h=5, Fold 2: RMSE=2.7649, R²=0.6548\n",
      "Trial 83, Horizon h=5, Fold 3: RMSE=2.6103, R²=0.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:33:21,907] Trial 83 finished with value: 2.3350347263147917 and parameters: {'learning_rate': 0.021189374852091398, 'max_depth': 3, 'gamma': 0.7356537549144347, 'reg_lambda': 5.335560745144206, 'reg_alpha': 2.8626986558296306, 'subsample': 0.616730080103672, 'colsample_bytree': 0.5009289940253425, 'min_child_weight': 6}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83, Horizon h=5, Fold 4: RMSE=2.6096, R²=0.7601\n",
      "Trial 83 finished, overall mean RMSE across horizons=2.3350\n",
      "\n",
      "Trial 84, Horizon h=1, Fold 1: RMSE=1.8179, R²=0.8277\n",
      "Trial 84, Horizon h=1, Fold 2: RMSE=1.8385, R²=0.8491\n",
      "Trial 84, Horizon h=1, Fold 3: RMSE=1.6237, R²=0.8969\n",
      "Trial 84, Horizon h=1, Fold 4: RMSE=1.6599, R²=0.9025\n",
      "Trial 84, Horizon h=2, Fold 1: RMSE=2.2043, R²=0.7466\n",
      "Trial 84, Horizon h=2, Fold 2: RMSE=2.3990, R²=0.7421\n",
      "Trial 84, Horizon h=2, Fold 3: RMSE=2.2245, R²=0.8070\n",
      "Trial 84, Horizon h=2, Fold 4: RMSE=2.2546, R²=0.8206\n",
      "Trial 84, Horizon h=3, Fold 1: RMSE=2.3852, R²=0.7035\n",
      "Trial 84, Horizon h=3, Fold 2: RMSE=2.6566, R²=0.6827\n",
      "Trial 84, Horizon h=3, Fold 3: RMSE=2.4814, R²=0.7598\n",
      "Trial 84, Horizon h=3, Fold 4: RMSE=2.4790, R²=0.7832\n",
      "Trial 84, Horizon h=4, Fold 1: RMSE=2.3842, R²=0.7040\n",
      "Trial 84, Horizon h=4, Fold 2: RMSE=2.7084, R²=0.6693\n",
      "Trial 84, Horizon h=4, Fold 3: RMSE=2.5639, R²=0.7438\n",
      "Trial 84, Horizon h=4, Fold 4: RMSE=2.5724, R²=0.7666\n",
      "Trial 84, Horizon h=5, Fold 1: RMSE=2.4199, R²=0.6954\n",
      "Trial 84, Horizon h=5, Fold 2: RMSE=2.7792, R²=0.6512\n",
      "Trial 84, Horizon h=5, Fold 3: RMSE=2.6028, R²=0.7359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:33:35,757] Trial 84 finished with value: 2.332449680826516 and parameters: {'learning_rate': 0.02394803524677013, 'max_depth': 3, 'gamma': 0.812773190359926, 'reg_lambda': 6.376926963242788, 'reg_alpha': 0.6797767541969721, 'subsample': 0.6044308873354679, 'colsample_bytree': 0.5134329047481794, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84, Horizon h=5, Fold 4: RMSE=2.5937, R²=0.7630\n",
      "Trial 84 finished, overall mean RMSE across horizons=2.3324\n",
      "\n",
      "Trial 85, Horizon h=1, Fold 1: RMSE=1.7996, R²=0.8312\n",
      "Trial 85, Horizon h=1, Fold 2: RMSE=1.8304, R²=0.8504\n",
      "Trial 85, Horizon h=1, Fold 3: RMSE=1.6347, R²=0.8955\n",
      "Trial 85, Horizon h=1, Fold 4: RMSE=1.6507, R²=0.9036\n",
      "Trial 85, Horizon h=2, Fold 1: RMSE=2.2111, R²=0.7450\n",
      "Trial 85, Horizon h=2, Fold 2: RMSE=2.4118, R²=0.7394\n",
      "Trial 85, Horizon h=2, Fold 3: RMSE=2.2310, R²=0.8059\n",
      "Trial 85, Horizon h=2, Fold 4: RMSE=2.2332, R²=0.8240\n",
      "Trial 85, Horizon h=3, Fold 1: RMSE=2.3853, R²=0.7035\n",
      "Trial 85, Horizon h=3, Fold 2: RMSE=2.6384, R²=0.6870\n",
      "Trial 85, Horizon h=3, Fold 3: RMSE=2.4959, R²=0.7570\n",
      "Trial 85, Horizon h=3, Fold 4: RMSE=2.4712, R²=0.7845\n",
      "Trial 85, Horizon h=4, Fold 1: RMSE=2.3794, R²=0.7051\n",
      "Trial 85, Horizon h=4, Fold 2: RMSE=2.7050, R²=0.6701\n",
      "Trial 85, Horizon h=4, Fold 3: RMSE=2.5726, R²=0.7420\n",
      "Trial 85, Horizon h=4, Fold 4: RMSE=2.5538, R²=0.7699\n",
      "Trial 85, Horizon h=5, Fold 1: RMSE=2.4248, R²=0.6941\n",
      "Trial 85, Horizon h=5, Fold 2: RMSE=2.7851, R²=0.6497\n",
      "Trial 85, Horizon h=5, Fold 3: RMSE=2.6052, R²=0.7354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:33:49,625] Trial 85 finished with value: 2.3306685104739184 and parameters: {'learning_rate': 0.023327949277457728, 'max_depth': 3, 'gamma': 0.9318467873366166, 'reg_lambda': 6.299690078981891, 'reg_alpha': 0.772046326206377, 'subsample': 0.6051801570402536, 'colsample_bytree': 0.5292438896862499, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 85, Horizon h=5, Fold 4: RMSE=2.5944, R²=0.7629\n",
      "Trial 85 finished, overall mean RMSE across horizons=2.3307\n",
      "\n",
      "Trial 86, Horizon h=1, Fold 1: RMSE=1.8161, R²=0.8281\n",
      "Trial 86, Horizon h=1, Fold 2: RMSE=1.8179, R²=0.8524\n",
      "Trial 86, Horizon h=1, Fold 3: RMSE=1.6219, R²=0.8971\n",
      "Trial 86, Horizon h=1, Fold 4: RMSE=1.6816, R²=0.9000\n",
      "Trial 86, Horizon h=2, Fold 1: RMSE=2.2112, R²=0.7450\n",
      "Trial 86, Horizon h=2, Fold 2: RMSE=2.3934, R²=0.7433\n",
      "Trial 86, Horizon h=2, Fold 3: RMSE=2.2385, R²=0.8046\n",
      "Trial 86, Horizon h=2, Fold 4: RMSE=2.2584, R²=0.8200\n",
      "Trial 86, Horizon h=3, Fold 1: RMSE=2.3808, R²=0.7046\n",
      "Trial 86, Horizon h=3, Fold 2: RMSE=2.6276, R²=0.6896\n",
      "Trial 86, Horizon h=3, Fold 3: RMSE=2.4922, R²=0.7577\n",
      "Trial 86, Horizon h=3, Fold 4: RMSE=2.4583, R²=0.7868\n",
      "Trial 86, Horizon h=4, Fold 1: RMSE=2.3917, R²=0.7021\n",
      "Trial 86, Horizon h=4, Fold 2: RMSE=2.7093, R²=0.6690\n",
      "Trial 86, Horizon h=4, Fold 3: RMSE=2.5838, R²=0.7398\n",
      "Trial 86, Horizon h=4, Fold 4: RMSE=2.5466, R²=0.7712\n",
      "Trial 86, Horizon h=5, Fold 1: RMSE=2.4349, R²=0.6916\n",
      "Trial 86, Horizon h=5, Fold 2: RMSE=2.7576, R²=0.6566\n",
      "Trial 86, Horizon h=5, Fold 3: RMSE=2.6250, R²=0.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:34:03,700] Trial 86 finished with value: 2.332206541172755 and parameters: {'learning_rate': 0.02344832040048234, 'max_depth': 3, 'gamma': 0.9155609398001503, 'reg_lambda': 7.564245308920301, 'reg_alpha': 0.5162649374089707, 'subsample': 0.6005542771335998, 'colsample_bytree': 0.5288908406204171, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 86, Horizon h=5, Fold 4: RMSE=2.5973, R²=0.7624\n",
      "Trial 86 finished, overall mean RMSE across horizons=2.3322\n",
      "\n",
      "Trial 87, Horizon h=1, Fold 1: RMSE=1.7998, R²=0.8311\n",
      "Trial 87, Horizon h=1, Fold 2: RMSE=1.8176, R²=0.8525\n",
      "Trial 87, Horizon h=1, Fold 3: RMSE=1.6372, R²=0.8951\n",
      "Trial 87, Horizon h=1, Fold 4: RMSE=1.6749, R²=0.9008\n",
      "Trial 87, Horizon h=2, Fold 1: RMSE=2.2244, R²=0.7420\n",
      "Trial 87, Horizon h=2, Fold 2: RMSE=2.4079, R²=0.7402\n",
      "Trial 87, Horizon h=2, Fold 3: RMSE=2.2547, R²=0.8017\n",
      "Trial 87, Horizon h=2, Fold 4: RMSE=2.2419, R²=0.8226\n",
      "Trial 87, Horizon h=3, Fold 1: RMSE=2.3643, R²=0.7087\n",
      "Trial 87, Horizon h=3, Fold 2: RMSE=2.6375, R²=0.6873\n",
      "Trial 87, Horizon h=3, Fold 3: RMSE=2.5140, R²=0.7534\n",
      "Trial 87, Horizon h=3, Fold 4: RMSE=2.4692, R²=0.7849\n",
      "Trial 87, Horizon h=4, Fold 1: RMSE=2.3991, R²=0.7002\n",
      "Trial 87, Horizon h=4, Fold 2: RMSE=2.7116, R²=0.6685\n",
      "Trial 87, Horizon h=4, Fold 3: RMSE=2.5999, R²=0.7365\n",
      "Trial 87, Horizon h=4, Fold 4: RMSE=2.5831, R²=0.7646\n",
      "Trial 87, Horizon h=5, Fold 1: RMSE=2.4556, R²=0.6863\n",
      "Trial 87, Horizon h=5, Fold 2: RMSE=2.7683, R²=0.6539\n",
      "Trial 87, Horizon h=5, Fold 3: RMSE=2.6319, R²=0.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:34:18,271] Trial 87 finished with value: 2.3386518387590995 and parameters: {'learning_rate': 0.024716417784229575, 'max_depth': 3, 'gamma': 0.934476047405679, 'reg_lambda': 7.862028469582865, 'reg_alpha': 0.2753488842941966, 'subsample': 0.600597808038844, 'colsample_bytree': 0.587155744419909, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 87, Horizon h=5, Fold 4: RMSE=2.5803, R²=0.7655\n",
      "Trial 87 finished, overall mean RMSE across horizons=2.3387\n",
      "\n",
      "Trial 88, Horizon h=1, Fold 1: RMSE=1.7399, R²=0.8422\n",
      "Trial 88, Horizon h=1, Fold 2: RMSE=1.8059, R²=0.8544\n",
      "Trial 88, Horizon h=1, Fold 3: RMSE=1.6283, R²=0.8963\n",
      "Trial 88, Horizon h=1, Fold 4: RMSE=1.6668, R²=0.9017\n",
      "Trial 88, Horizon h=2, Fold 1: RMSE=2.2511, R²=0.7357\n",
      "Trial 88, Horizon h=2, Fold 2: RMSE=2.4459, R²=0.7320\n",
      "Trial 88, Horizon h=2, Fold 3: RMSE=2.2405, R²=0.8042\n",
      "Trial 88, Horizon h=2, Fold 4: RMSE=2.2523, R²=0.8210\n",
      "Trial 88, Horizon h=3, Fold 1: RMSE=2.4196, R²=0.6949\n",
      "Trial 88, Horizon h=3, Fold 2: RMSE=2.6958, R²=0.6733\n",
      "Trial 88, Horizon h=3, Fold 3: RMSE=2.4966, R²=0.7568\n",
      "Trial 88, Horizon h=3, Fold 4: RMSE=2.4767, R²=0.7836\n",
      "Trial 88, Horizon h=4, Fold 1: RMSE=2.4289, R²=0.6928\n",
      "Trial 88, Horizon h=4, Fold 2: RMSE=2.8533, R²=0.6329\n",
      "Trial 88, Horizon h=4, Fold 3: RMSE=2.5447, R²=0.7476\n",
      "Trial 88, Horizon h=4, Fold 4: RMSE=2.5894, R²=0.7634\n",
      "Trial 88, Horizon h=5, Fold 1: RMSE=2.4273, R²=0.6935\n",
      "Trial 88, Horizon h=5, Fold 2: RMSE=2.8427, R²=0.6351\n",
      "Trial 88, Horizon h=5, Fold 3: RMSE=2.6591, R²=0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:34:32,611] Trial 88 finished with value: 2.3566968004410107 and parameters: {'learning_rate': 0.03048385325811652, 'max_depth': 4, 'gamma': 0.808484846233634, 'reg_lambda': 1.288368061634082, 'reg_alpha': 0.7185870093541095, 'subsample': 0.5806088028486078, 'colsample_bytree': 0.5623380042445777, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 88, Horizon h=5, Fold 4: RMSE=2.6693, R²=0.7490\n",
      "Trial 88 finished, overall mean RMSE across horizons=2.3567\n",
      "\n",
      "Trial 89, Horizon h=1, Fold 1: RMSE=1.8074, R²=0.8297\n",
      "Trial 89, Horizon h=1, Fold 2: RMSE=1.8442, R²=0.8481\n",
      "Trial 89, Horizon h=1, Fold 3: RMSE=1.6234, R²=0.8969\n",
      "Trial 89, Horizon h=1, Fold 4: RMSE=1.6791, R²=0.9003\n",
      "Trial 89, Horizon h=2, Fold 1: RMSE=2.1958, R²=0.7485\n",
      "Trial 89, Horizon h=2, Fold 2: RMSE=2.4076, R²=0.7403\n",
      "Trial 89, Horizon h=2, Fold 3: RMSE=2.2183, R²=0.8081\n",
      "Trial 89, Horizon h=2, Fold 4: RMSE=2.2645, R²=0.8190\n",
      "Trial 89, Horizon h=3, Fold 1: RMSE=2.3775, R²=0.7054\n",
      "Trial 89, Horizon h=3, Fold 2: RMSE=2.6429, R²=0.6860\n",
      "Trial 89, Horizon h=3, Fold 3: RMSE=2.4920, R²=0.7577\n",
      "Trial 89, Horizon h=3, Fold 4: RMSE=2.4698, R²=0.7848\n",
      "Trial 89, Horizon h=4, Fold 1: RMSE=2.3821, R²=0.7045\n",
      "Trial 89, Horizon h=4, Fold 2: RMSE=2.7279, R²=0.6645\n",
      "Trial 89, Horizon h=4, Fold 3: RMSE=2.5875, R²=0.7391\n",
      "Trial 89, Horizon h=4, Fold 4: RMSE=2.5499, R²=0.7706\n",
      "Trial 89, Horizon h=5, Fold 1: RMSE=2.4186, R²=0.6957\n",
      "Trial 89, Horizon h=5, Fold 2: RMSE=2.7707, R²=0.6533\n",
      "Trial 89, Horizon h=5, Fold 3: RMSE=2.6148, R²=0.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:34:47,454] Trial 89 finished with value: 2.3338608722975946 and parameters: {'learning_rate': 0.022600382968468006, 'max_depth': 3, 'gamma': 0.8908591520654119, 'reg_lambda': 7.458298305321703, 'reg_alpha': 0.5500293400890826, 'subsample': 0.6531838282330933, 'colsample_bytree': 0.5299434205759673, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 89, Horizon h=5, Fold 4: RMSE=2.6033, R²=0.7613\n",
      "Trial 89 finished, overall mean RMSE across horizons=2.3339\n",
      "\n",
      "Trial 90, Horizon h=1, Fold 1: RMSE=1.7997, R²=0.8311\n",
      "Trial 90, Horizon h=1, Fold 2: RMSE=1.8320, R²=0.8501\n",
      "Trial 90, Horizon h=1, Fold 3: RMSE=1.6297, R²=0.8961\n",
      "Trial 90, Horizon h=1, Fold 4: RMSE=1.6688, R²=0.9015\n",
      "Trial 90, Horizon h=2, Fold 1: RMSE=2.2231, R²=0.7423\n",
      "Trial 90, Horizon h=2, Fold 2: RMSE=2.4319, R²=0.7350\n",
      "Trial 90, Horizon h=2, Fold 3: RMSE=2.2434, R²=0.8037\n",
      "Trial 90, Horizon h=2, Fold 4: RMSE=2.2360, R²=0.8236\n",
      "Trial 90, Horizon h=3, Fold 1: RMSE=2.3886, R²=0.7027\n",
      "Trial 90, Horizon h=3, Fold 2: RMSE=2.6360, R²=0.6876\n",
      "Trial 90, Horizon h=3, Fold 3: RMSE=2.4908, R²=0.7580\n",
      "Trial 90, Horizon h=3, Fold 4: RMSE=2.4570, R²=0.7870\n",
      "Trial 90, Horizon h=4, Fold 1: RMSE=2.3933, R²=0.7017\n",
      "Trial 90, Horizon h=4, Fold 2: RMSE=2.7200, R²=0.6664\n",
      "Trial 90, Horizon h=4, Fold 3: RMSE=2.6040, R²=0.7357\n",
      "Trial 90, Horizon h=4, Fold 4: RMSE=2.5572, R²=0.7693\n",
      "Trial 90, Horizon h=5, Fold 1: RMSE=2.4296, R²=0.6929\n",
      "Trial 90, Horizon h=5, Fold 2: RMSE=2.7933, R²=0.6477\n",
      "Trial 90, Horizon h=5, Fold 3: RMSE=2.6277, R²=0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:34:58,903] Trial 90 finished with value: 2.3379546411329235 and parameters: {'learning_rate': 0.032855810619153956, 'max_depth': 3, 'gamma': 0.7062284737338191, 'reg_lambda': 6.910006985501271, 'reg_alpha': 0.35792421432986954, 'subsample': 0.604052434292645, 'colsample_bytree': 0.5441944337582381, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90, Horizon h=5, Fold 4: RMSE=2.5969, R²=0.7624\n",
      "Trial 90 finished, overall mean RMSE across horizons=2.3380\n",
      "\n",
      "Trial 91, Horizon h=1, Fold 1: RMSE=1.8153, R²=0.8282\n",
      "Trial 91, Horizon h=1, Fold 2: RMSE=1.8197, R²=0.8521\n",
      "Trial 91, Horizon h=1, Fold 3: RMSE=1.6280, R²=0.8963\n",
      "Trial 91, Horizon h=1, Fold 4: RMSE=1.6747, R²=0.9008\n",
      "Trial 91, Horizon h=2, Fold 1: RMSE=2.2038, R²=0.7467\n",
      "Trial 91, Horizon h=2, Fold 2: RMSE=2.4364, R²=0.7341\n",
      "Trial 91, Horizon h=2, Fold 3: RMSE=2.2219, R²=0.8075\n",
      "Trial 91, Horizon h=2, Fold 4: RMSE=2.2241, R²=0.8254\n",
      "Trial 91, Horizon h=3, Fold 1: RMSE=2.3547, R²=0.7111\n",
      "Trial 91, Horizon h=3, Fold 2: RMSE=2.6178, R²=0.6919\n",
      "Trial 91, Horizon h=3, Fold 3: RMSE=2.5064, R²=0.7549\n",
      "Trial 91, Horizon h=3, Fold 4: RMSE=2.4553, R²=0.7873\n",
      "Trial 91, Horizon h=4, Fold 1: RMSE=2.3808, R²=0.7048\n",
      "Trial 91, Horizon h=4, Fold 2: RMSE=2.7388, R²=0.6618\n",
      "Trial 91, Horizon h=4, Fold 3: RMSE=2.5799, R²=0.7406\n",
      "Trial 91, Horizon h=4, Fold 4: RMSE=2.5618, R²=0.7685\n",
      "Trial 91, Horizon h=5, Fold 1: RMSE=2.4217, R²=0.6949\n",
      "Trial 91, Horizon h=5, Fold 2: RMSE=2.7798, R²=0.6511\n",
      "Trial 91, Horizon h=5, Fold 3: RMSE=2.6061, R²=0.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:35:11,237] Trial 91 finished with value: 2.3307202580598014 and parameters: {'learning_rate': 0.027862210864235487, 'max_depth': 3, 'gamma': 0.4287063171701655, 'reg_lambda': 7.613034043503184, 'reg_alpha': 0.023285035127702247, 'subsample': 0.6304138285394655, 'colsample_bytree': 0.5289062329003575, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 91, Horizon h=5, Fold 4: RMSE=2.5874, R²=0.7642\n",
      "Trial 91 finished, overall mean RMSE across horizons=2.3307\n",
      "\n",
      "Trial 92, Horizon h=1, Fold 1: RMSE=1.8174, R²=0.8278\n",
      "Trial 92, Horizon h=1, Fold 2: RMSE=1.8256, R²=0.8512\n",
      "Trial 92, Horizon h=1, Fold 3: RMSE=1.5986, R²=0.9000\n",
      "Trial 92, Horizon h=1, Fold 4: RMSE=1.6556, R²=0.9031\n",
      "Trial 92, Horizon h=2, Fold 1: RMSE=2.2038, R²=0.7467\n",
      "Trial 92, Horizon h=2, Fold 2: RMSE=2.4301, R²=0.7354\n",
      "Trial 92, Horizon h=2, Fold 3: RMSE=2.2235, R²=0.8072\n",
      "Trial 92, Horizon h=2, Fold 4: RMSE=2.2365, R²=0.8235\n",
      "Trial 92, Horizon h=3, Fold 1: RMSE=2.3695, R²=0.7074\n",
      "Trial 92, Horizon h=3, Fold 2: RMSE=2.6248, R²=0.6902\n",
      "Trial 92, Horizon h=3, Fold 3: RMSE=2.5187, R²=0.7525\n",
      "Trial 92, Horizon h=3, Fold 4: RMSE=2.4652, R²=0.7856\n",
      "Trial 92, Horizon h=4, Fold 1: RMSE=2.3789, R²=0.7053\n",
      "Trial 92, Horizon h=4, Fold 2: RMSE=2.7308, R²=0.6638\n",
      "Trial 92, Horizon h=4, Fold 3: RMSE=2.5842, R²=0.7397\n",
      "Trial 92, Horizon h=4, Fold 4: RMSE=2.5532, R²=0.7700\n",
      "Trial 92, Horizon h=5, Fold 1: RMSE=2.4384, R²=0.6907\n",
      "Trial 92, Horizon h=5, Fold 2: RMSE=2.7718, R²=0.6531\n",
      "Trial 92, Horizon h=5, Fold 3: RMSE=2.6196, R²=0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:35:25,685] Trial 92 finished with value: 2.330976818560875 and parameters: {'learning_rate': 0.025007833985875978, 'max_depth': 3, 'gamma': 0.45697951408535864, 'reg_lambda': 6.52530336748241, 'reg_alpha': 0.09279661893779412, 'subsample': 0.6262719654274231, 'colsample_bytree': 0.526962228635972, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 92, Horizon h=5, Fold 4: RMSE=2.5733, R²=0.7667\n",
      "Trial 92 finished, overall mean RMSE across horizons=2.3310\n",
      "\n",
      "Trial 93, Horizon h=1, Fold 1: RMSE=1.8229, R²=0.8268\n",
      "Trial 93, Horizon h=1, Fold 2: RMSE=1.8378, R²=0.8492\n",
      "Trial 93, Horizon h=1, Fold 3: RMSE=1.6263, R²=0.8965\n",
      "Trial 93, Horizon h=1, Fold 4: RMSE=1.6844, R²=0.8997\n",
      "Trial 93, Horizon h=2, Fold 1: RMSE=2.2046, R²=0.7465\n",
      "Trial 93, Horizon h=2, Fold 2: RMSE=2.4168, R²=0.7383\n",
      "Trial 93, Horizon h=2, Fold 3: RMSE=2.2473, R²=0.8030\n",
      "Trial 93, Horizon h=2, Fold 4: RMSE=2.2730, R²=0.8177\n",
      "Trial 93, Horizon h=3, Fold 1: RMSE=2.4094, R²=0.6975\n",
      "Trial 93, Horizon h=3, Fold 2: RMSE=2.6389, R²=0.6869\n",
      "Trial 93, Horizon h=3, Fold 3: RMSE=2.4757, R²=0.7609\n",
      "Trial 93, Horizon h=3, Fold 4: RMSE=2.4560, R²=0.7872\n",
      "Trial 93, Horizon h=4, Fold 1: RMSE=2.4057, R²=0.6986\n",
      "Trial 93, Horizon h=4, Fold 2: RMSE=2.7314, R²=0.6636\n",
      "Trial 93, Horizon h=4, Fold 3: RMSE=2.5765, R²=0.7413\n",
      "Trial 93, Horizon h=4, Fold 4: RMSE=2.5504, R²=0.7705\n",
      "Trial 93, Horizon h=5, Fold 1: RMSE=2.4392, R²=0.6905\n",
      "Trial 93, Horizon h=5, Fold 2: RMSE=2.7707, R²=0.6534\n",
      "Trial 93, Horizon h=5, Fold 3: RMSE=2.6312, R²=0.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:35:38,426] Trial 93 finished with value: 2.340580879253957 and parameters: {'learning_rate': 0.02813178867360234, 'max_depth': 3, 'gamma': 0.3863528088205666, 'reg_lambda': 6.394647454750048, 'reg_alpha': 0.13237401654173997, 'subsample': 0.5925714153008396, 'colsample_bytree': 0.5291801773585058, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 93, Horizon h=5, Fold 4: RMSE=2.6133, R²=0.7594\n",
      "Trial 93 finished, overall mean RMSE across horizons=2.3406\n",
      "\n",
      "Trial 94, Horizon h=1, Fold 1: RMSE=1.8205, R²=0.8272\n",
      "Trial 94, Horizon h=1, Fold 2: RMSE=1.8365, R²=0.8494\n",
      "Trial 94, Horizon h=1, Fold 3: RMSE=1.6319, R²=0.8958\n",
      "Trial 94, Horizon h=1, Fold 4: RMSE=1.6646, R²=0.9020\n",
      "Trial 94, Horizon h=2, Fold 1: RMSE=2.2046, R²=0.7465\n",
      "Trial 94, Horizon h=2, Fold 2: RMSE=2.4411, R²=0.7330\n",
      "Trial 94, Horizon h=2, Fold 3: RMSE=2.2465, R²=0.8032\n",
      "Trial 94, Horizon h=2, Fold 4: RMSE=2.2533, R²=0.8208\n",
      "Trial 94, Horizon h=3, Fold 1: RMSE=2.3697, R²=0.7074\n",
      "Trial 94, Horizon h=3, Fold 2: RMSE=2.6333, R²=0.6882\n",
      "Trial 94, Horizon h=3, Fold 3: RMSE=2.4974, R²=0.7567\n",
      "Trial 94, Horizon h=3, Fold 4: RMSE=2.4554, R²=0.7873\n",
      "Trial 94, Horizon h=4, Fold 1: RMSE=2.3807, R²=0.7048\n",
      "Trial 94, Horizon h=4, Fold 2: RMSE=2.7357, R²=0.6626\n",
      "Trial 94, Horizon h=4, Fold 3: RMSE=2.6031, R²=0.7359\n",
      "Trial 94, Horizon h=4, Fold 4: RMSE=2.5564, R²=0.7694\n",
      "Trial 94, Horizon h=5, Fold 1: RMSE=2.4265, R²=0.6937\n",
      "Trial 94, Horizon h=5, Fold 2: RMSE=2.7828, R²=0.6503\n",
      "Trial 94, Horizon h=5, Fold 3: RMSE=2.6110, R²=0.7343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:35:51,173] Trial 94 finished with value: 2.3360697993140174 and parameters: {'learning_rate': 0.02576077936120065, 'max_depth': 3, 'gamma': 0.417373700210382, 'reg_lambda': 7.562022330325879, 'reg_alpha': 0.04128293475905722, 'subsample': 0.6260156837883297, 'colsample_bytree': 0.5481113095118615, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 94, Horizon h=5, Fold 4: RMSE=2.5705, R²=0.7672\n",
      "Trial 94 finished, overall mean RMSE across horizons=2.3361\n",
      "\n",
      "Trial 95, Horizon h=1, Fold 1: RMSE=1.8258, R²=0.8262\n",
      "Trial 95, Horizon h=1, Fold 2: RMSE=1.8519, R²=0.8469\n",
      "Trial 95, Horizon h=1, Fold 3: RMSE=1.6389, R²=0.8949\n",
      "Trial 95, Horizon h=1, Fold 4: RMSE=1.6819, R²=0.9000\n",
      "Trial 95, Horizon h=2, Fold 1: RMSE=2.1833, R²=0.7514\n",
      "Trial 95, Horizon h=2, Fold 2: RMSE=2.4356, R²=0.7342\n",
      "Trial 95, Horizon h=2, Fold 3: RMSE=2.2401, R²=0.8043\n",
      "Trial 95, Horizon h=2, Fold 4: RMSE=2.2518, R²=0.8211\n",
      "Trial 95, Horizon h=3, Fold 1: RMSE=2.3699, R²=0.7073\n",
      "Trial 95, Horizon h=3, Fold 2: RMSE=2.6492, R²=0.6845\n",
      "Trial 95, Horizon h=3, Fold 3: RMSE=2.5342, R²=0.7495\n",
      "Trial 95, Horizon h=3, Fold 4: RMSE=2.4612, R²=0.7863\n",
      "Trial 95, Horizon h=4, Fold 1: RMSE=2.3861, R²=0.7035\n",
      "Trial 95, Horizon h=4, Fold 2: RMSE=2.7430, R²=0.6608\n",
      "Trial 95, Horizon h=4, Fold 3: RMSE=2.6058, R²=0.7353\n",
      "Trial 95, Horizon h=4, Fold 4: RMSE=2.5514, R²=0.7703\n",
      "Trial 95, Horizon h=5, Fold 1: RMSE=2.4367, R²=0.6911\n",
      "Trial 95, Horizon h=5, Fold 2: RMSE=2.7627, R²=0.6553\n",
      "Trial 95, Horizon h=5, Fold 3: RMSE=2.6359, R²=0.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:36:05,394] Trial 95 finished with value: 2.340351033515856 and parameters: {'learning_rate': 0.023407057393498354, 'max_depth': 3, 'gamma': 0.4419790600181369, 'reg_lambda': 6.535172286810422, 'reg_alpha': 0.8988911031022851, 'subsample': 0.6317749274651543, 'colsample_bytree': 0.5789081367453799, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 95, Horizon h=5, Fold 4: RMSE=2.5615, R²=0.7689\n",
      "Trial 95 finished, overall mean RMSE across horizons=2.3404\n",
      "\n",
      "Trial 96, Horizon h=1, Fold 1: RMSE=1.8318, R²=0.8251\n",
      "Trial 96, Horizon h=1, Fold 2: RMSE=1.8576, R²=0.8459\n",
      "Trial 96, Horizon h=1, Fold 3: RMSE=1.6441, R²=0.8943\n",
      "Trial 96, Horizon h=1, Fold 4: RMSE=1.6818, R²=0.9000\n",
      "Trial 96, Horizon h=2, Fold 1: RMSE=2.2387, R²=0.7386\n",
      "Trial 96, Horizon h=2, Fold 2: RMSE=2.4517, R²=0.7307\n",
      "Trial 96, Horizon h=2, Fold 3: RMSE=2.2620, R²=0.8004\n",
      "Trial 96, Horizon h=2, Fold 4: RMSE=2.2871, R²=0.8154\n",
      "Trial 96, Horizon h=3, Fold 1: RMSE=2.3735, R²=0.7064\n",
      "Trial 96, Horizon h=3, Fold 2: RMSE=2.6782, R²=0.6775\n",
      "Trial 96, Horizon h=3, Fold 3: RMSE=2.5473, R²=0.7469\n",
      "Trial 96, Horizon h=3, Fold 4: RMSE=2.4948, R²=0.7804\n",
      "Trial 96, Horizon h=4, Fold 1: RMSE=2.3783, R²=0.7054\n",
      "Trial 96, Horizon h=4, Fold 2: RMSE=2.7571, R²=0.6573\n",
      "Trial 96, Horizon h=4, Fold 3: RMSE=2.6067, R²=0.7352\n",
      "Trial 96, Horizon h=4, Fold 4: RMSE=2.5900, R²=0.7633\n",
      "Trial 96, Horizon h=5, Fold 1: RMSE=2.4078, R²=0.6984\n",
      "Trial 96, Horizon h=5, Fold 2: RMSE=2.7837, R²=0.6501\n",
      "Trial 96, Horizon h=5, Fold 3: RMSE=2.6443, R²=0.7274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:36:18,604] Trial 96 finished with value: 2.3561565372955946 and parameters: {'learning_rate': 0.02770692182120949, 'max_depth': 3, 'gamma': 0.5338199019597516, 'reg_lambda': 7.947440520385229, 'reg_alpha': 0.46649909404020373, 'subsample': 0.8003186851471497, 'colsample_bytree': 0.5635120769549874, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 96, Horizon h=5, Fold 4: RMSE=2.6067, R²=0.7606\n",
      "Trial 96 finished, overall mean RMSE across horizons=2.3562\n",
      "\n",
      "Trial 97, Horizon h=1, Fold 1: RMSE=1.8348, R²=0.8245\n",
      "Trial 97, Horizon h=1, Fold 2: RMSE=1.8719, R²=0.8435\n",
      "Trial 97, Horizon h=1, Fold 3: RMSE=1.6409, R²=0.8947\n",
      "Trial 97, Horizon h=1, Fold 4: RMSE=1.6640, R²=0.9021\n",
      "Trial 97, Horizon h=2, Fold 1: RMSE=2.1958, R²=0.7486\n",
      "Trial 97, Horizon h=2, Fold 2: RMSE=2.4302, R²=0.7354\n",
      "Trial 97, Horizon h=2, Fold 3: RMSE=2.2475, R²=0.8030\n",
      "Trial 97, Horizon h=2, Fold 4: RMSE=2.2624, R²=0.8194\n",
      "Trial 97, Horizon h=3, Fold 1: RMSE=2.3893, R²=0.7025\n",
      "Trial 97, Horizon h=3, Fold 2: RMSE=2.6307, R²=0.6889\n",
      "Trial 97, Horizon h=3, Fold 3: RMSE=2.5014, R²=0.7559\n",
      "Trial 97, Horizon h=3, Fold 4: RMSE=2.4511, R²=0.7880\n",
      "Trial 97, Horizon h=4, Fold 1: RMSE=2.4135, R²=0.6966\n",
      "Trial 97, Horizon h=4, Fold 2: RMSE=2.7134, R²=0.6680\n",
      "Trial 97, Horizon h=4, Fold 3: RMSE=2.5818, R²=0.7402\n",
      "Trial 97, Horizon h=4, Fold 4: RMSE=2.5649, R²=0.7679\n",
      "Trial 97, Horizon h=5, Fold 1: RMSE=2.3906, R²=0.7027\n",
      "Trial 97, Horizon h=5, Fold 2: RMSE=2.7862, R²=0.6495\n",
      "Trial 97, Horizon h=5, Fold 3: RMSE=2.6154, R²=0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:36:29,877] Trial 97 finished with value: 2.3393999084230237 and parameters: {'learning_rate': 0.03662037439071134, 'max_depth': 3, 'gamma': 0.34218745585268645, 'reg_lambda': 6.8047197722808495, 'reg_alpha': 1.270639172507374, 'subsample': 0.6425669410033921, 'colsample_bytree': 0.5385272481785549, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 97, Horizon h=5, Fold 4: RMSE=2.6023, R²=0.7615\n",
      "Trial 97 finished, overall mean RMSE across horizons=2.3394\n",
      "\n",
      "Trial 98, Horizon h=1, Fold 1: RMSE=1.7993, R²=0.8312\n",
      "Trial 98, Horizon h=1, Fold 2: RMSE=1.8158, R²=0.8528\n",
      "Trial 98, Horizon h=1, Fold 3: RMSE=1.6310, R²=0.8959\n",
      "Trial 98, Horizon h=1, Fold 4: RMSE=1.6443, R²=0.9044\n",
      "Trial 98, Horizon h=2, Fold 1: RMSE=2.1964, R²=0.7484\n",
      "Trial 98, Horizon h=2, Fold 2: RMSE=2.4009, R²=0.7417\n",
      "Trial 98, Horizon h=2, Fold 3: RMSE=2.2414, R²=0.8041\n",
      "Trial 98, Horizon h=2, Fold 4: RMSE=2.2529, R²=0.8209\n",
      "Trial 98, Horizon h=3, Fold 1: RMSE=2.3782, R²=0.7052\n",
      "Trial 98, Horizon h=3, Fold 2: RMSE=2.6233, R²=0.6906\n",
      "Trial 98, Horizon h=3, Fold 3: RMSE=2.4922, R²=0.7577\n",
      "Trial 98, Horizon h=3, Fold 4: RMSE=2.4327, R²=0.7912\n",
      "Trial 98, Horizon h=4, Fold 1: RMSE=2.3793, R²=0.7052\n",
      "Trial 98, Horizon h=4, Fold 2: RMSE=2.7303, R²=0.6639\n",
      "Trial 98, Horizon h=4, Fold 3: RMSE=2.5836, R²=0.7398\n",
      "Trial 98, Horizon h=4, Fold 4: RMSE=2.5501, R²=0.7706\n",
      "Trial 98, Horizon h=5, Fold 1: RMSE=2.4363, R²=0.6912\n",
      "Trial 98, Horizon h=5, Fold 2: RMSE=2.7773, R²=0.6517\n",
      "Trial 98, Horizon h=5, Fold 3: RMSE=2.6120, R²=0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:36:44,248] Trial 98 finished with value: 2.33064448496772 and parameters: {'learning_rate': 0.024948035864040503, 'max_depth': 3, 'gamma': 0.5125985045484892, 'reg_lambda': 7.033856515113431, 'reg_alpha': 0.577011713671673, 'subsample': 0.5747850121407979, 'colsample_bytree': 0.5231067339158282, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 98, Horizon h=5, Fold 4: RMSE=2.6357, R²=0.7553\n",
      "Trial 98 finished, overall mean RMSE across horizons=2.3306\n",
      "\n",
      "Trial 99, Horizon h=1, Fold 1: RMSE=1.8058, R²=0.8300\n",
      "Trial 99, Horizon h=1, Fold 2: RMSE=1.8269, R²=0.8510\n",
      "Trial 99, Horizon h=1, Fold 3: RMSE=1.6333, R²=0.8957\n",
      "Trial 99, Horizon h=1, Fold 4: RMSE=1.6813, R²=0.9000\n",
      "Trial 99, Horizon h=2, Fold 1: RMSE=2.2040, R²=0.7467\n",
      "Trial 99, Horizon h=2, Fold 2: RMSE=2.4167, R²=0.7383\n",
      "Trial 99, Horizon h=2, Fold 3: RMSE=2.2348, R²=0.8052\n",
      "Trial 99, Horizon h=2, Fold 4: RMSE=2.2603, R²=0.8197\n",
      "Trial 99, Horizon h=3, Fold 1: RMSE=2.3826, R²=0.7042\n",
      "Trial 99, Horizon h=3, Fold 2: RMSE=2.6233, R²=0.6906\n",
      "Trial 99, Horizon h=3, Fold 3: RMSE=2.4770, R²=0.7606\n",
      "Trial 99, Horizon h=3, Fold 4: RMSE=2.4725, R²=0.7843\n",
      "Trial 99, Horizon h=4, Fold 1: RMSE=2.3753, R²=0.7062\n",
      "Trial 99, Horizon h=4, Fold 2: RMSE=2.7155, R²=0.6675\n",
      "Trial 99, Horizon h=4, Fold 3: RMSE=2.5645, R²=0.7437\n",
      "Trial 99, Horizon h=4, Fold 4: RMSE=2.5756, R²=0.7660\n",
      "Trial 99, Horizon h=5, Fold 1: RMSE=2.4433, R²=0.6895\n",
      "Trial 99, Horizon h=5, Fold 2: RMSE=2.7552, R²=0.6572\n",
      "Trial 99, Horizon h=5, Fold 3: RMSE=2.6133, R²=0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 02:36:56,444] Trial 99 finished with value: 2.3335175586943286 and parameters: {'learning_rate': 0.031227524168160357, 'max_depth': 3, 'gamma': 0.48350061617124873, 'reg_lambda': 7.181124352900384, 'reg_alpha': 1.0773652638902793, 'subsample': 0.5744024998598926, 'colsample_bytree': 0.525020478654193, 'min_child_weight': 10}. Best is trial 67 with value: 2.33043015703495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 99, Horizon h=5, Fold 4: RMSE=2.6092, R²=0.7602\n",
      "Trial 99 finished, overall mean RMSE across horizons=2.3335\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x19811979a10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost_pipeline.run_optuna(n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0b0a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model for horizon 1 trained.\n",
      "Final model for horizon 2 trained.\n",
      "Final model for horizon 3 trained.\n",
      "Final model for horizon 4 trained.\n",
      "Final model for horizon 5 trained.\n"
     ]
    }
   ],
   "source": [
    "XGBoost_pipeline.train_final_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcda6d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Horizon h=1 -> RMSE: 1.0788, R²: 0.9553\n",
      "[TRAIN] Horizon h=2 -> RMSE: 1.4325, R²: 0.9213\n",
      "[TRAIN] Horizon h=3 -> RMSE: 1.5088, R²: 0.9128\n",
      "[TRAIN] Horizon h=4 -> RMSE: 1.5107, R²: 0.9128\n",
      "[TRAIN] Horizon h=5 -> RMSE: 1.5134, R²: 0.9125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'rmse': np.float64(1.0788379517976316),\n",
       "  'mae': 0.8373182903759213,\n",
       "  'mape': np.float64(3.591224370775793),\n",
       "  'mse': 1.1638913262389088,\n",
       "  'r2': np.float64(0.9553090657523808)},\n",
       " 2: {'rmse': np.float64(1.4325019023468066),\n",
       "  'mae': 1.1142996782629293,\n",
       "  'mape': np.float64(4.8453293980888485),\n",
       "  'mse': 2.05206170022722,\n",
       "  'r2': np.float64(0.9213064448620136)},\n",
       " 3: {'rmse': np.float64(1.5088288048681475),\n",
       "  'mae': 1.1944102565166468,\n",
       "  'mape': np.float64(5.219128309926884),\n",
       "  'mse': 2.2765643623998426,\n",
       "  'r2': np.float64(0.912840717041869)},\n",
       " 4: {'rmse': np.float64(1.5106953746848146),\n",
       "  'mae': 1.2069675357203504,\n",
       "  'mape': np.float64(5.271946234517428),\n",
       "  'mse': 2.2822005150940923,\n",
       "  'r2': np.float64(0.91275122057154)},\n",
       " 5: {'rmse': np.float64(1.5133685685481173),\n",
       "  'mae': 1.2018135133524763,\n",
       "  'mape': np.float64(5.246266050264323),\n",
       "  'mse': 2.2902844242693776,\n",
       "  'r2': np.float64(0.9125448443356914)}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train metrics\n",
    "train_metrics = XGBoost_pipeline.evaluate_train_models()\n",
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442cbccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon h=1 -> RMSE: 1.6162, R²: 0.8925\n",
      "Horizon h=2 -> RMSE: 2.1263, R²: 0.8137\n",
      "Horizon h=3 -> RMSE: 2.3462, R²: 0.7731\n",
      "Horizon h=4 -> RMSE: 2.4071, R²: 0.7612\n",
      "Horizon h=5 -> RMSE: 2.4587, R²: 0.7509\n"
     ]
    }
   ],
   "source": [
    "# Test metrics\n",
    "test_df_shifted = XGBoost_pipeline.prepare_test_dataset(test_dataset)\n",
    "test_metrics = XGBoost_pipeline.evaluate_final_models(test_df_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "180ecd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>1.468970</td>\n",
       "      <td>2.046809</td>\n",
       "      <td>2.295129</td>\n",
       "      <td>2.390412</td>\n",
       "      <td>2.441394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>1.155537</td>\n",
       "      <td>1.612771</td>\n",
       "      <td>1.822410</td>\n",
       "      <td>1.883491</td>\n",
       "      <td>1.912807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>4.901593</td>\n",
       "      <td>6.924236</td>\n",
       "      <td>7.886138</td>\n",
       "      <td>8.165083</td>\n",
       "      <td>8.298942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>2.157872</td>\n",
       "      <td>4.189429</td>\n",
       "      <td>5.267615</td>\n",
       "      <td>5.714070</td>\n",
       "      <td>5.960403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.911156</td>\n",
       "      <td>0.827366</td>\n",
       "      <td>0.782903</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.754355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5\n",
       "rmse  1.468970  2.046809  2.295129  2.390412  2.441394\n",
       "mae   1.155537  1.612771  1.822410  1.883491  1.912807\n",
       "mape  4.901593  6.924236  7.886138  8.165083  8.298942\n",
       "mse   2.157872  4.189429  5.267615  5.714070  5.960403\n",
       "r2    0.911156  0.827366  0.782903  0.764505  0.754355"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "201fcc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Giả sử bạn đã import \"from pathlib import Path\" ở đầu file)\n",
    "# (Và \"PROJECT_ROOT\" đã được định nghĩa như code của bạn)\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55a9df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lưu các model (file .pkl) vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\models_pkl\n",
      "Model (Pickle) cho horizon 1 đã được lưu vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\models_pkl\\hanoi_temp_v1_20251117_024235_h1.pkl\n",
      "Model (Pickle) cho horizon 2 đã được lưu vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\models_pkl\\hanoi_temp_v1_20251117_024235_h2.pkl\n",
      "Model (Pickle) cho horizon 3 đã được lưu vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\models_pkl\\hanoi_temp_v1_20251117_024235_h3.pkl\n",
      "Model (Pickle) cho horizon 4 đã được lưu vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\models_pkl\\hanoi_temp_v1_20251117_024235_h4.pkl\n",
      "Model (Pickle) cho horizon 5 đã được lưu vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\models_pkl\\hanoi_temp_v1_20251117_024235_h5.pkl\n",
      "Lưu file tóm tắt (file .json) vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\results\n",
      "Kết quả tóm tắt đã được lưu vào: C:\\Assigment\\2025-2026\\Machine Learning\\machine_learning_project\\src\\config\\results\\hanoi_temp_v1_20251117_024235_summary.json\n",
      "\n",
      "--- HOÀN TẤT TOÀN BỘ FLOW ---\n",
      "Run name: hanoi_temp_v1_20251117_024235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 10. LƯU KẾT QUẢ (Phiên bản cập nhật có timestamp) ---\n",
    "\n",
    "# 0. Tạo timestamp theo thời gian chạy\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_name = f\"hanoi_temp_v1_{timestamp}\"\n",
    "\n",
    "# 1. Tái sử dụng biến PROJECT_ROOT để tạo đường dẫn lưu\n",
    "BASE_SAVE_DIR = Path(PROJECT_ROOT) / \"src\" / \"config\"\n",
    "\n",
    "# 2. Tạo thư mục con\n",
    "MODELS_DIR = BASE_SAVE_DIR / \"models_pkl\"\n",
    "RESULTS_DIR = BASE_SAVE_DIR / \"results\"\n",
    "\n",
    "# 3. Tự động tạo thư mục nếu chưa tồn tại\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nLưu các model (file .pkl) vào: {MODELS_DIR}\")\n",
    "\n",
    "# 4. Lưu file .pkl theo format có timestamp (không ghi đè file cũ)\n",
    "model_paths_pkl = XGBoost_pipeline.save_all_final_models_pkl(\n",
    "    base_filename_prefix=str(MODELS_DIR / run_name)\n",
    ")\n",
    "\n",
    "print(f\"Lưu file tóm tắt (file .json) vào: {RESULTS_DIR}\")\n",
    "\n",
    "# 5. Lưu JSON có timestamp\n",
    "XGBoost_pipeline.save_results_to_json(\n",
    "    filename=str(RESULTS_DIR / f\"{run_name}_summary.json\"),\n",
    "    model_name=\"Hanoi Temp Predictor v1.0 (XGBoost)\",\n",
    "    train_metrics=train_metrics,\n",
    "    test_metrics=test_metrics,\n",
    "    saved_model_paths=model_paths_pkl\n",
    ")\n",
    "\n",
    "print(\"\\n--- HOÀN TẤT TOÀN BỘ FLOW ---\")\n",
    "print(f\"Run name: {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f44c16",
   "metadata": {},
   "source": [
    "# Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime # Sửa lại import\n",
    "import pickle\n",
    "\n",
    "# ======================== JSON ENCODER (Giữ nguyên) ========================\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    \"\"\"\n",
    "    Custom JSON encoder để xử lý các kiểu dữ liệu của NumPy\n",
    "    (vd: np.float64, np.int64) mà thư viện json tiêu chuẩn không xử lý được.\n",
    "    \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "# ======================== HOURLY PIPELINE CLASS ========================\n",
    "\n",
    "class MultiHorizonHourly_WalkForwardOptuna_XGBoost_Pipeline:\n",
    "    \"\"\"\n",
    "    Pipeline chuyên dụng cho dự báo ĐA TẦM NHÌN (Multi-Horizon) HÀNG GIỜ.\n",
    "\n",
    "    Sử dụng Walk-Forward Cross-Validation (với cửa sổ Mở rộng hoặc Trượt)\n",
    "    kết hợp Optuna để tìm MỘT bộ siêu tham số (shared parameters) tối ưu\n",
    "    cho tất cả các tầm nhìn (horizons).\n",
    "\n",
    "    Sau đó, huấn luyện MỘT MÔ HÌNH CUỐI CÙNG (final model) riêng biệt\n",
    "    cho TỪNG TẦM NHÌN (ví dụ: model cho t+1h, model cho t+3h,...).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        date_col,\n",
    "        target_col,\n",
    "        feature_cols,\n",
    "        n_splits=5,\n",
    "        test_size=720,       # THAY ĐỔI: Mặc định 720 giờ (30 ngày)\n",
    "        gap_size_hours=24,    # THAY ĐỔI: Thêm Gap (giờ)\n",
    "        mode=\"expanding\",\n",
    "        horizons=(1, 2, 3, 4 , 5), # THAY ĐỔI: Mặc định (giờ)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Khởi tạo pipeline.\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame chứa toàn bộ dữ liệu (đã qua FE).\n",
    "            date_col (str): Tên cột datetime (đã sort).\n",
    "            target_col (str): Tên cột mục tiêu (ví dụ: 'temp').\n",
    "            feature_cols (list): Danh sách tất cả các cột feature.\n",
    "            n_splits (int): Số lượng Fold cho Walk-Forward CV.\n",
    "            test_size (int): Kích thước (số giờ) của mỗi tập test/validation.\n",
    "            gap_size_hours (int): Số giờ chừa trống (gap) giữa train và test.\n",
    "            mode (str): 'expanding' (cửa sổ mở rộng) hoặc 'rolling' (cửa sổ trượt).\n",
    "            horizons (tuple): Các tầm nhìn dự đoán (ví dụ: t+1h, t+3h...).\n",
    "        \"\"\"\n",
    "        self.df = df.copy().sort_values(date_col).reset_index(drop=True)\n",
    "        self.date_col = date_col\n",
    "        self.target_col = target_col\n",
    "        self.feature_cols = feature_cols\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.gap_size_hours = gap_size_hours # Đã thêm\n",
    "        self.mode = mode\n",
    "        self.horizons = tuple(horizons)\n",
    "\n",
    "        self.walkfolds = {h: [] for h in self.horizons}\n",
    "        self.walkfold_dates = {h: [] for h in self.horizons}\n",
    "\n",
    "        self.final_models = {h: None for h in self.horizons}\n",
    "\n",
    "        self.best_params = None\n",
    "        self.fold_history = [] # Lưu lịch sử các fold của Optuna\n",
    "\n",
    "        # Tự động lọc ra các cột X (features)\n",
    "        self.X_cols = [\n",
    "            c for c in self.feature_cols\n",
    "            if c not in [\n",
    "                self.date_col,\n",
    "                self.target_col,\n",
    "                # Loại bỏ các cột target/date đã shift (nếu có)\n",
    "                self.target_col + \"_next\",\n",
    "                self.date_col + \"_next\",\n",
    "            ]\n",
    "        ]\n",
    "        # Đảm bảo không có cột target_hX nào trong X_cols\n",
    "        for h in self.horizons:\n",
    "            target_h_name = f\"{self.target_col}_h{h}\"\n",
    "            date_h_name = f\"{self.date_col}_h{h}\"\n",
    "            if target_h_name in self.X_cols:\n",
    "                self.X_cols.remove(target_h_name)\n",
    "            if date_h_name in self.X_cols:\n",
    "                self.X_cols.remove(date_h_name)\n",
    "\n",
    "    # ======================== 1. TARGET SHIFT FOR ALL HORIZONS (TRAIN) ========================\n",
    "\n",
    "    def add_target_shifts(self):\n",
    "        \"\"\"\n",
    "        Tạo các cột target đã dịch chuyển (shifted) cho từng horizon.\n",
    "        Ví dụ: 'temp_h1' (temp 1 giờ sau), 'temp_h24' (temp 24 giờ sau).\n",
    "        \n",
    "        Xóa các hàng NaN ở cuối DataFrame (không có target).\n",
    "        \"\"\"\n",
    "        print(\"Đang tạo các cột target (shifted)...\")\n",
    "        for h in self.horizons:\n",
    "            # Dịch chuyển target (giá trị tương lai) về hàng hiện tại\n",
    "            self.df[f\"{self.target_col}_h{h}\"] = self.df[self.target_col].shift(-h)\n",
    "            # Dịch chuyển cả date của target (để dễ kiểm tra)\n",
    "            self.df[f\"{self.date_col}_h{h}\"] = self.df[self.date_col].shift(-h)\n",
    "\n",
    "        # Xóa các hàng ở cuối mà không có đủ target (ví dụ: 24h cuối)\n",
    "        target_cols = [f\"{self.target_col}_h{h}\" for h in self.horizons]\n",
    "        self.df = self.df.dropna(subset=target_cols).reset_index(drop=True)\n",
    "        print(f\"Hình dạng DF sau khi shift và dropna: {self.df.shape}\")\n",
    "\n",
    "    # ======================== 1b. TARGET SHIFT CHO TEST SET ========================\n",
    "\n",
    "    def prepare_test_dataset(self, test_df_raw):\n",
    "        \"\"\"\n",
    "        Chuẩn bị (shift target) cho một DataFrame test (hold-out) bên ngoài.\n",
    "        \"\"\"\n",
    "        test_df = test_df_raw.copy().sort_values(self.date_col).reset_index(drop=True)\n",
    "\n",
    "        for h in self.horizons:\n",
    "            test_df[f\"{self.target_col}_h{h}\"] = test_df[self.target_col].shift(-h)\n",
    "            test_df[f\"{self.date_col}_h{h}\"] = test_df[self.date_col].shift(-h)\n",
    "\n",
    "        target_cols = [f\"{self.target_col}_h{h}\" for h in self.horizons]\n",
    "        test_df = test_df.dropna(subset=target_cols).reset_index(drop=True)\n",
    "        return test_df\n",
    "\n",
    "    # ======================== 2. CREATE WALK-FORWARD FOLDS ========================\n",
    "\n",
    "    def create_walkforward_folds(self):\n",
    "        \"\"\"\n",
    "        Tạo ra các fold (cặp Train/Validation) theo chiến lược Walk-Forward.\n",
    "        Lưu các fold (data) và ngày (dates) vào self.walkfolds\n",
    "        \"\"\"\n",
    "        df_len = len(self.df)\n",
    "        \n",
    "        # Tính toán kích thước của mỗi 'bước' huấn luyện\n",
    "        total_test_gap_span = (self.test_size + self.gap_size_hours) * self.n_splits\n",
    "        train_span = df_len - total_test_gap_span\n",
    "        \n",
    "        if train_span <= 0:\n",
    "             raise ValueError(\n",
    "                 f\"Dữ liệu quá ngắn ({df_len} giờ) cho n_splits={self.n_splits}, \"\n",
    "                 f\"test_size={self.test_size}, gap={self.gap_size_hours}\"\n",
    "             )\n",
    "        \n",
    "        # 'step' là kích thước của block huấn luyện *ban đầu*\n",
    "        # và cũng là kích thước của mỗi \"bước nhảy\"\n",
    "        step = train_span // self.n_splits\n",
    "        if step <= 0:\n",
    "            raise ValueError(\n",
    "                f\"Không thể tạo Folds. 'step' (kích thước train) = {step}. \"\n",
    "                f\"Hãy giảm n_splits hoặc test_size.\"\n",
    "            )\n",
    "\n",
    "        print(f\"Đang tạo {self.n_splits} folds, mỗi fold test_size={self.test_size}h, gap={self.gap_size_hours}h...\")\n",
    "\n",
    "        self.walkfolds = {h: [] for h in self.horizons}\n",
    "        self.walkfold_dates = {h: [] for h in self.horizons}\n",
    "\n",
    "        # KHÔNG DÙNG 'initial_train_end' nữa\n",
    "        # initial_train_end = df_len - total_test_gap_span\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            \n",
    "            # ========== SỬA LOGIC Ở ĐÂY ==========\n",
    "            # train_end tăng thêm 'step' sau mỗi lần lặp\n",
    "            train_end = step * (i + 1)\n",
    "            \n",
    "            if self.mode == \"expanding\":\n",
    "                train_start = 0\n",
    "            else: # 'rolling'\n",
    "                # Cửa sổ trượt sẽ có kích thước bằng 'step'\n",
    "                train_start = max(0, train_end - step)\n",
    "            # ======================================\n",
    "            \n",
    "            test_start = train_end + self.gap_size_hours\n",
    "            test_end = test_start + self.test_size\n",
    "            \n",
    "            if test_end > df_len:\n",
    "                print(f\"Bỏ qua fold {i+1} vì test_end ({test_end}) vượt quá độ dài dữ liệu ({df_len})\")\n",
    "                break\n",
    "\n",
    "            train_df = self.df.iloc[train_start:train_end]\n",
    "            test_df = self.df.iloc[test_start:test_end]\n",
    "            \n",
    "            # ... (Phần còn lại của hàm giữ nguyên) ...\n",
    "            \n",
    "            if train_df.empty or test_df.empty:\n",
    "                print(f\"Bỏ qua fold {i+1} vì train hoặc test rỗng.\")\n",
    "                continue\n",
    "\n",
    "            # Tách X (features) và Y (targets)\n",
    "            X_train = train_df[self.X_cols].reset_index(drop=True)\n",
    "            X_val = test_df[self.X_cols].reset_index(drop=True)\n",
    "\n",
    "            X_train_dates = train_df[self.date_col].reset_index(drop=True)\n",
    "            X_val_dates = test_df[self.date_col].reset_index(drop=True)\n",
    "\n",
    "            # Tạo dữ liệu cho từng horizon\n",
    "            for h in self.horizons:\n",
    "                y_train_h = train_df[f\"{self.target_col}_h{h}\"].reset_index(drop=True)\n",
    "                y_val_h = test_df[f\"{self.target_col}_h{h}\"].reset_index(drop=True)\n",
    "\n",
    "                y_train_dates_h = train_df[f\"{self.date_col}_h{h}\"].reset_index(drop=True)\n",
    "                y_val_dates_h = test_df[f\"{self.date_col}_h{h}\"].reset_index(drop=True)\n",
    "\n",
    "                self.walkfolds[h].append(\n",
    "                    ((X_train, y_train_h), (X_val, y_val_h))\n",
    "                )\n",
    "\n",
    "                self.walkfold_dates[h].append(\n",
    "                    ((X_train_dates, y_train_dates_h),\n",
    "                     (X_val_dates, y_val_dates_h))\n",
    "                )\n",
    "        print(f\"Đã tạo thành công {len(self.walkfolds[self.horizons[0]])} folds.\")\n",
    "\n",
    "    # ======================== 3. OPTUNA OBJECTIVE (SHARED PARAMS) ========================\n",
    "\n",
    "    def create_objective(self):\n",
    "        \"\"\"\n",
    "        Tạo hàm objective cho Optuna.\n",
    "        Hàm này sẽ chạy Walk-Forward CV cho TẤT CẢ CÁC HORIZON\n",
    "        và trả về RMSE TRUNG BÌNH CHUNG (mean over all horizons)\n",
    "        \"\"\"\n",
    "        def objective(trial):\n",
    "            # Không gian tìm kiếm siêu tham số\n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'eval_metric': 'rmse',\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10), # Có thể tăng max_depth\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 10.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            }\n",
    "\n",
    "            horizon_results = {} # Lưu kết quả chi tiết của trial này\n",
    "            overall_rmse_list = [] # Lưu RMSE trung bình của MỖI horizon\n",
    "            global_step = 0 # Dùng cho Pruning\n",
    "\n",
    "            # Lặp qua các horizon (ví dụ: h=1, h=3, h=6...)\n",
    "            for h in self.horizons:\n",
    "                scores = []\n",
    "                fold_results = []\n",
    "\n",
    "                # Lặp qua các fold (ví dụ: 5 folds)\n",
    "                for i, ((X_train, y_train), (X_val, y_val)) in enumerate(self.walkfolds[h]):\n",
    "\n",
    "                    model = xgb.XGBRegressor(\n",
    "                        **params,\n",
    "                        n_estimators=1000, # Có thể tăng cho dữ liệu hourly\n",
    "                        random_state=42,\n",
    "                        tree_method='hist', # Dùng 'gpu_hist' nếu có GPU\n",
    "                        early_stopping_rounds=100 # Giữ nguyên\n",
    "                    )\n",
    "\n",
    "                    model.fit(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        verbose=False\n",
    "                    )\n",
    "\n",
    "                    preds = model.predict(X_val)\n",
    "                    \n",
    "                    # Tính toán các chỉ số\n",
    "                    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "\n",
    "                    ss_res = np.sum((y_val - preds) ** 2)\n",
    "                    ss_tot = np.sum((y_val - np.mean(y_val)) ** 2)\n",
    "                    r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "                    scores.append(rmse)\n",
    "                    fold_results.append({'rmse': rmse, 'r2': r2})\n",
    "\n",
    "                    # Báo cáo cho Optuna (Pruning)\n",
    "                    trial.report(rmse, step=global_step)\n",
    "                    if trial.should_prune():\n",
    "                        print(f\"Trial {trial.number} pruned tại global_step={global_step}\")\n",
    "                        raise optuna.TrialPruned()\n",
    "                    global_step += 1\n",
    "\n",
    "                # Tính RMSE trung bình cho horizon H\n",
    "                mean_rmse_h = float(np.mean(scores))\n",
    "                horizon_results[h] = {\n",
    "                    'mean_rmse': mean_rmse_h,\n",
    "                    'fold_scores': fold_results,\n",
    "                }\n",
    "                overall_rmse_list.append(mean_rmse_h) # Thêm vào danh sách chung\n",
    "\n",
    "            # Tính RMSE trung bình của các RMSE trung bình\n",
    "            overall_mean_rmse = float(np.mean(overall_rmse_list))\n",
    "            print(\n",
    "                f\"Trial {trial.number} finished, \"\n",
    "                f\"overall mean RMSE across horizons={overall_mean_rmse:.4f}\\n\"\n",
    "            )\n",
    "\n",
    "            # Lưu lại lịch sử để debug\n",
    "            self.fold_history.append({\n",
    "                'trial': trial.number,\n",
    "                'params': params,\n",
    "                'horizon_results': horizon_results,\n",
    "                'overall_mean_rmse': overall_mean_rmse,\n",
    "            })\n",
    "            \n",
    "            # Trả về 1 con số duy nhất để Optuna tối ưu\n",
    "            return overall_mean_rmse\n",
    "\n",
    "        return objective\n",
    "\n",
    "    # ======================== 4. RUN OPTUNA ========================\n",
    "\n",
    "    def run_optuna(self, n_trials=50):\n",
    "        \"\"\"\n",
    "        Chạy quá trình tối ưu hóa Optuna.\n",
    "        \"\"\"\n",
    "        if not self.walkfolds[self.horizons[0]]:\n",
    "            raise ValueError(\"Chưa tạo folds. Hãy gọi add_target_shifts() và create_walkforward_folds() trước.\")\n",
    "            \n",
    "        objective_fn = self.create_objective()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize', # Tối ưu (giảm) RMSE\n",
    "            pruner=optuna.pruners.MedianPruner(\n",
    "                n_warmup_steps=len(self.horizons) # Chờ ít nhất 1 horizon hoàn thành\n",
    "            )\n",
    "        )\n",
    "        study.optimize(objective_fn, n_trials=n_trials)\n",
    "        self.best_params = study.best_params\n",
    "        return study\n",
    "\n",
    "    # ======================== 5. TRAIN A FINAL MODEL PER HORIZON ========================\n",
    "\n",
    "    def train_final_models(self):\n",
    "        \"\"\"\n",
    "        Huấn luyện mô hình cuối cùng cho TỪNG horizon\n",
    "        sử dụng bộ tham số tốt nhất (best_params) tìm được từ Optuna\n",
    "        trên TOÀN BỘ self.df.\n",
    "        \"\"\"\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"Bạn phải chạy run_optuna() trước khi train_final_models().\")\n",
    "\n",
    "        final_params = self.best_params.copy()\n",
    "        final_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'n_estimators': 1500, # Có thể tăng n_estimators cho mô hình cuối cùng\n",
    "            'early_stopping_rounds': 150 # Dùng (X_full, y_full_h) làm eval_set\n",
    "        })\n",
    "\n",
    "        X_full = self.df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            print(f\"Đang huấn luyện mô hình cuối cùng cho horizon h={h}...\")\n",
    "            y_full_h = self.df[f\"{self.target_col}_h{h}\"]\n",
    "\n",
    "            model_h = xgb.XGBRegressor(\n",
    "                **final_params,\n",
    "                random_state=42,\n",
    "                tree_method='hist' # Dùng 'gpu_hist' nếu có GPU\n",
    "            )\n",
    "\n",
    "            # Sử dụng early stopping ngay cả trên mô hình cuối cùng\n",
    "            # bằng cách dùng chính tập full làm eval_set\n",
    "            model_h.fit(\n",
    "                X_full, \n",
    "                y_full_h, \n",
    "                eval_set=[(X_full, y_full_h)],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            self.final_models[h] = model_h\n",
    "            print(f\"Final model cho horizon {h} đã huấn luyện xong.\")\n",
    "\n",
    "    # ======================== 6. PREDICTION HELPERS ========================\n",
    "\n",
    "    def predict_horizon(self, X_today, h):\n",
    "        \"\"\"\n",
    "        Dự đoán cho MỘT horizon H, sử dụng MỘT dòng/nhiều dòng dữ liệu đầu vào.\n",
    "        \"\"\"\n",
    "        if h not in self.horizons:\n",
    "            raise ValueError(f\"Horizon {h} không nằm trong {self.horizons}.\")\n",
    "        if self.final_models[h] is None:\n",
    "            raise ValueError(f\"Model cho horizon {h} chưa được huấn luyện. Gọi train_final_models().\")\n",
    "\n",
    "        # Đảm bảo X_today là DataFrame và chỉ lấy các cột cần thiết\n",
    "        if isinstance(X_today, pd.Series):\n",
    "             X_input = X_today[self.X_cols].to_frame().T\n",
    "        else:\n",
    "             X_input = X_today[self.X_cols]\n",
    "             \n",
    "        return self.final_models[h].predict(X_input)\n",
    "\n",
    "    def predict_all_horizons(self, X_today):\n",
    "        \"\"\"\n",
    "        Dự đoán cho TẤT CẢ các horizon.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for h in self.horizons:\n",
    "            results[h] = self.predict_horizon(X_today, h)\n",
    "        return results\n",
    "\n",
    "    # ======================== 6b. BUILD PREDICTIONS FRAME (Plot) ========================\n",
    "\n",
    "    def get_predictions_frame(self, df_with_shift, h):\n",
    "        \"\"\"\n",
    "        Tạo một DataFrame chứa (y_true, y_pred, feature_time, target_time)\n",
    "        cho một horizon H cụ thể, dựa trên một DataFrame đầu vào.\n",
    "        \"\"\"\n",
    "        if h not in self.horizons:\n",
    "            raise ValueError(f\"Horizon {h} không nằm trong {self.horizons}.\")\n",
    "        if self.final_models[h] is None:\n",
    "            raise ValueError(f\"Model cho horizon {h} chưa được huấn luyện.\")\n",
    "\n",
    "        X = df_with_shift[self.X_cols]\n",
    "        y_true = df_with_shift[f\"{self.target_col}_h{h}\"]\n",
    "        y_pred = self.final_models[h].predict(X)\n",
    "\n",
    "        feature_time = df_with_shift[self.date_col]\n",
    "        \n",
    "        # Đảm bảo cột target_time tồn tại\n",
    "        if f\"{self.date_col}_h{h}\" in df_with_shift.columns:\n",
    "            target_time = df_with_shift[f\"{self.date_col}_h{h}\"]\n",
    "        else:\n",
    "            # Nếu không có, tự tính toán (chậm hơn)\n",
    "            target_time = pd.to_datetime(feature_time) + pd.to_timedelta(h, unit='h')\n",
    "\n",
    "        df_pred = pd.DataFrame({\n",
    "            \"feature_time\": feature_time.values,\n",
    "            \"target_time\": target_time.values,\n",
    "            \"y_true\": y_true.values,\n",
    "            \"y_pred\": y_pred,\n",
    "        })\n",
    "        return df_pred\n",
    "\n",
    "    def plot_predictions(self, df_with_shift, h, use_target_time=True, n_points=None):\n",
    "        \"\"\"\n",
    "        Vẽ biểu đồ so sánh True vs Predicted cho horizon H.\n",
    "        \"\"\"\n",
    "        df_pred = self.get_predictions_frame(df_with_shift, h)\n",
    "\n",
    "        df_plot = df_pred.copy()\n",
    "        if use_target_time and \"target_time\" in df_plot.columns:\n",
    "            df_plot[\"x_axis\"] = pd.to_datetime(df_plot[\"target_time\"])\n",
    "            xlabel = f\"Target Time (Dự đoán cho lúc...)\"\n",
    "        else:\n",
    "            df_plot[\"x_axis\"] = pd.to_datetime(df_plot[\"feature_time\"])\n",
    "            xlabel = f\"Feature Time (Dự đoán từ lúc...)\"\n",
    "\n",
    "        if n_points is not None:\n",
    "            df_plot = df_plot.iloc[-n_points:] # Lấy N điểm cuối cùng\n",
    "\n",
    "        plt.figure(figsize=(15, 5)) # Tăng kích thước\n",
    "        plt.plot(df_plot[\"x_axis\"], df_plot[\"y_true\"], label=\"True\", alpha=0.8)\n",
    "        plt.plot(df_plot[\"x_axis\"], df_plot[\"y_pred\"], label=\"Predicted\", linestyle='--')\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(self.target_col)\n",
    "        plt.title(f\"Dự báo cho tầm nhìn {h} giờ (Horizon h={h})\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=':', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # ======================== 7. EVAL ON TRAIN SET (CHECK OVERFIT) ========================\n",
    "\n",
    "    def evaluate_train_models(self):\n",
    "        \"\"\"\n",
    "        Đánh giá các mô hình cuối cùng trên TOÀN BỘ tập huấn luyện (self.df)\n",
    "        để kiểm tra overfitting.\n",
    "        \"\"\"\n",
    "        print(\"Đang đánh giá mô hình trên toàn bộ tập TRAIN (để kiểm tra overfit)...\")\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"Tất cả models phải được huấn luyện trước khi đánh giá.\")\n",
    "\n",
    "        metrics = {}\n",
    "        X_train_full = self.df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_train_h = self.df[f\"{self.target_col}_h{h}\"]\n",
    "            preds = self.final_models[h].predict(X_train_full)\n",
    "\n",
    "            mse = mean_squared_error(y_train_h, preds)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_train_h, preds)\n",
    "            eps = 1e-8\n",
    "            mape = np.mean(np.abs((y_train_h - preds) / (y_train_h + eps))) * 100\n",
    "\n",
    "            ss_res = np.sum((y_train_h - preds) ** 2)\n",
    "            ss_tot = np.sum((y_train_h - np.mean(y_train_h)) ** 2)\n",
    "            r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "            print(\n",
    "                f\"[TRAIN] Horizon h={h} -> \"\n",
    "                f\"RMSE: {rmse:.4f}, R²: {r2:.4f}, MAE: {mae:.4f}\"\n",
    "            )\n",
    "\n",
    "            metrics[h] = {\n",
    "                'rmse': rmse, 'mae': mae, 'mape': mape, 'mse': mse, 'r2': r2,\n",
    "            }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    # ======================== 8. EVALUATION ON A TEST SET ========================\n",
    "\n",
    "    def evaluate_final_models(self, test_df):\n",
    "        \"\"\"\n",
    "        Đánh giá các mô hình cuối cùng trên một tập TEST (hold-out) bên ngoài.\n",
    "        \"\"\"\n",
    "        print(\"Đang đánh giá mô hình trên tập TEST (hold-out)...\")\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"Tất cả models phải được huấn luyện trước khi đánh giá.\")\n",
    "\n",
    "        metrics = {}\n",
    "        X_test = test_df[self.X_cols]\n",
    "\n",
    "        for h in self.horizons:\n",
    "            y_test_h = test_df[f\"{self.target_col}_h{h}\"]\n",
    "            preds = self.final_models[h].predict(X_test)\n",
    "\n",
    "            mse = mean_squared_error(y_test_h, preds)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test_h, preds)\n",
    "            eps = 1e-8\n",
    "            mape = np.mean(np.abs((y_test_h - preds) / (y_test_h + eps))) * 100\n",
    "\n",
    "            ss_res = np.sum((y_test_h - preds) ** 2)\n",
    "            ss_tot = np.sum((y_test_h - np.mean(y_test_h)) ** 2)\n",
    "            r2 = 1 - ss_res / ss_tot if ss_tot != 0 else 0.0\n",
    "\n",
    "            print(\n",
    "                f\"[TEST] Horizon h={h} -> \"\n",
    "                f\"RMSE: {rmse:.4f}, R²: {r2:.4f}, MAE: {mae:.4f}\"\n",
    "            )\n",
    "\n",
    "            metrics[h] = {\n",
    "                'rmse': rmse, 'mae': mae, 'mape': mape, 'mse': mse, 'r2': r2,\n",
    "            }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    # ======================== 9. SAVE FINAL MODELS (PICKLE) ========================\n",
    "\n",
    "    def save_all_final_models_pkl(self, base_filename_prefix):\n",
    "        \"\"\"\n",
    "        Lưu tất cả các model cuối cùng (final_models) ra đĩa dùng PICKLE (.pkl).\n",
    "        \"\"\"\n",
    "        if any(self.final_models[h] is None for h in self.horizons):\n",
    "            raise ValueError(\"Phải train model trước khi lưu. Hãy gọi train_final_models().\")\n",
    "        \n",
    "        saved_paths = {}\n",
    "        for h in self.horizons:\n",
    "            model = self.final_models[h]\n",
    "            # Tên file sẽ là prefix + _h1.pkl, _h3.pkl ...\n",
    "            filename = f\"{base_filename_prefix}_h{h}.pkl\"\n",
    "            \n",
    "            try:\n",
    "                with open(filename, 'wb') as f: \n",
    "                    pickle.dump(model, f)\n",
    "                saved_paths[h] = filename\n",
    "                print(f\"Model (Pickle) cho horizon {h} đã được lưu vào: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi lưu file pickle {filename}: {e}\")\n",
    "        \n",
    "        return saved_paths\n",
    "\n",
    "    # ======================== 10. SAVE RESULTS SUMMARY (JSON) ========================\n",
    "    \n",
    "    def save_results_to_json(\n",
    "        self,\n",
    "        filename,\n",
    "        model_name,\n",
    "        train_metrics,\n",
    "        test_metrics,\n",
    "        saved_model_paths=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Lưu kết quả tóm tắt (best param, metrics, timestamp,...) vào 1 file JSON.\n",
    "        \"\"\"\n",
    "        \n",
    "        results_summary = {\n",
    "            \"model_name\": model_name,\n",
    "            \"run_timestamp_utc\": datetime.utcnow().isoformat(), # Đã sửa (xóa 1 .datetime)\n",
    "            \"target_column\": self.target_col,\n",
    "            \"feature_columns\": self.X_cols,\n",
    "            \"horizons_hours\": self.horizons, # Đổi tên cho rõ\n",
    "            \"cross_validation_setup\": {\n",
    "                \"n_splits\": self.n_splits,\n",
    "                \"test_size_per_fold_hours\": self.test_size, # Đổi tên\n",
    "                \"gap_size_hours\": self.gap_size_hours, # THÊM\n",
    "                \"mode\": self.mode,\n",
    "            },\n",
    "            \"optuna_best_params\": self.best_params,\n",
    "            \"evaluation_train_set\": train_metrics,\n",
    "            \"evaluation_test_set\": test_metrics,\n",
    "            \"saved_model_files\": saved_model_paths if saved_model_paths else {},\n",
    "            \"optuna_fold_history\": self.fold_history \n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results_summary, f, indent=4, cls=NpEncoder)\n",
    "            print(f\"Kết quả tóm tắt đã được lưu vào: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi lưu file JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdd34840",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_pipeline_hourly = MultiHorizonHourly_WalkForwardOptuna_XGBoost_Pipeline(\n",
    "    df=train_dataset_h,\n",
    "    date_col=\"datetime\",\n",
    "    target_col=\"temp\",\n",
    "    feature_cols=[col for col in train_dataset_h.columns if col not in [\"datetime\", \"temp\", \"temp_next\", \"datetime_next\"]],\n",
    "    n_splits=5,\n",
    "    test_size=365,\n",
    "    mode=\"expanding\",\n",
    "    horizons=(1, 2, 3, 4, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81a6aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo các cột target (shifted)...\n",
      "Hình dạng DF sau khi shift và dropna: (69176, 130)\n",
      "Đang tạo 5 folds, mỗi fold test_size=365h, gap=24h...\n",
      "Đã tạo thành công 5 folds.\n"
     ]
    }
   ],
   "source": [
    "XGBoost_pipeline_hourly.add_target_shifts()\n",
    "XGBoost_pipeline_hourly.create_walkforward_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f7152e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 03:56:45,095] A new study created in memory with name: no-name-66990aea-3443-474a-8317-dcf811da1cf2\n",
      "[I 2025-11-17 03:59:47,677] Trial 0 finished with value: 1.0326366206486297 and parameters: {'learning_rate': 0.024591455082855894, 'max_depth': 5, 'gamma': 0.6841974344303405, 'reg_lambda': 9.850590045406502, 'reg_alpha': 0.6972319899671586, 'subsample': 0.5086579172327925, 'colsample_bytree': 0.7315779926989582, 'min_child_weight': 2}. Best is trial 0 with value: 1.0326366206486297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished, overall mean RMSE across horizons=1.0326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 04:06:03,661] Trial 1 finished with value: 1.0378910830344381 and parameters: {'learning_rate': 0.010896748358799948, 'max_depth': 7, 'gamma': 0.9289916129638199, 'reg_lambda': 6.174018531061216, 'reg_alpha': 5.927658601625048, 'subsample': 0.7141180672699262, 'colsample_bytree': 0.7685013579789269, 'min_child_weight': 7}. Best is trial 0 with value: 1.0326366206486297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished, overall mean RMSE across horizons=1.0379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 04:14:25,829] Trial 2 finished with value: 1.0519385172182194 and parameters: {'learning_rate': 0.03690869237740869, 'max_depth': 10, 'gamma': 0.253942191399806, 'reg_lambda': 6.994355272352963, 'reg_alpha': 7.970487392983752, 'subsample': 0.6587798769110595, 'colsample_bytree': 0.6837316439184529, 'min_child_weight': 1}. Best is trial 0 with value: 1.0326366206486297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished, overall mean RMSE across horizons=1.0519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-11-17 04:23:36,559] Trial 3 failed with parameters: {'learning_rate': 0.014152240715301304, 'max_depth': 9, 'gamma': 0.5957862159075105, 'reg_lambda': 9.422952506105066, 'reg_alpha': 6.950303974168369, 'subsample': 0.9375311549150219, 'colsample_bytree': 0.5463644575658877, 'min_child_weight': 5} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_30928\\2100940939.py\", line 273, in objective\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1365, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py\", line 2430, in update\n",
      "    self._assign_dmatrix_features(dtrain)\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py\", line 3391, in _assign_dmatrix_features\n",
      "    if self.feature_names is None:\n",
      "       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py\", line 2351, in feature_names\n",
      "    return self._get_feature_info(\"feature_name\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py\", line 2301, in _get_feature_info\n",
      "    _LIB.XGBoosterGetStrFeatureInfo(\n",
      "KeyboardInterrupt\n",
      "[W 2025-11-17 04:23:36,562] Trial 3 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mXGBoost_pipeline_hourly\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 344\u001b[39m, in \u001b[36mMultiHorizonHourly_WalkForwardOptuna_XGBoost_Pipeline.run_optuna\u001b[39m\u001b[34m(self, n_trials)\u001b[39m\n\u001b[32m    336\u001b[39m objective_fn = \u001b[38;5;28mself\u001b[39m.create_objective()\n\u001b[32m    338\u001b[39m study = optuna.create_study(\n\u001b[32m    339\u001b[39m     direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# Tối ưu (giảm) RMSE\u001b[39;00m\n\u001b[32m    340\u001b[39m     pruner=optuna.pruners.MedianPruner(\n\u001b[32m    341\u001b[39m         n_warmup_steps=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.horizons) \u001b[38;5;66;03m# Chờ ít nhất 1 horizon hoàn thành\u001b[39;00m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m    343\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[38;5;28mself\u001b[39m.best_params = study.best_params\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 273\u001b[39m, in \u001b[36mMultiHorizonHourly_WalkForwardOptuna_XGBoost_Pipeline.create_objective.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, ((X_train, y_train), (X_val, y_val)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.walkfolds[h]):\n\u001b[32m    265\u001b[39m     model = xgb.XGBRegressor(\n\u001b[32m    266\u001b[39m         **params,\n\u001b[32m    267\u001b[39m         n_estimators=\u001b[32m1000\u001b[39m, \u001b[38;5;66;03m# Có thể tăng cho dữ liệu hourly\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         early_stopping_rounds=\u001b[32m100\u001b[39m \u001b[38;5;66;03m# Giữ nguyên\u001b[39;00m\n\u001b[32m    271\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m     preds = model.predict(X_val)\n\u001b[32m    282\u001b[39m     \u001b[38;5;66;03m# Tính toán các chỉ số\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\sklearn.py:1365\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1363\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py:2430\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtrain, DMatrix):\n\u001b[32m   2429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid training matrix: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dtrain).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2430\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_dmatrix_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m   2434\u001b[39m         _LIB.XGBoosterUpdateOneIter(\n\u001b[32m   2435\u001b[39m             \u001b[38;5;28mself\u001b[39m.handle, ctypes.c_int(iteration), dtrain.handle\n\u001b[32m   2436\u001b[39m         )\n\u001b[32m   2437\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py:3391\u001b[39m, in \u001b[36mBooster._assign_dmatrix_features\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   3388\u001b[39m fn = data.feature_names\n\u001b[32m   3389\u001b[39m ft = data.feature_types\n\u001b[32m-> \u001b[39m\u001b[32m3391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_names\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3392\u001b[39m     \u001b[38;5;28mself\u001b[39m.feature_names = fn\n\u001b[32m   3393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py:2351\u001b[39m, in \u001b[36mBooster.feature_names\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2345\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2346\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeature_names\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[FeatureNames]:\n\u001b[32m   2347\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Feature names for this booster.  Can be directly set by input data or by\u001b[39;00m\n\u001b[32m   2348\u001b[39m \u001b[33;03m    assignment.\u001b[39;00m\n\u001b[32m   2349\u001b[39m \n\u001b[32m   2350\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_feature_info\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeature_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\wp_env\\Lib\\site-packages\\xgboost\\core.py:2301\u001b[39m, in \u001b[36mBooster._get_feature_info\u001b[39m\u001b[34m(self, field)\u001b[39m\n\u001b[32m   2298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhandle\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2300\u001b[39m _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterGetStrFeatureInfo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2302\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43msarr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2306\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2307\u001b[39m )\n\u001b[32m   2308\u001b[39m feature_info = from_cstr_to_pystr(sarr, length)\n\u001b[32m   2309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feature_info \u001b[38;5;28;01mif\u001b[39;00m feature_info \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "XGBoost_pipeline_hourly.run_optuna(n_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
